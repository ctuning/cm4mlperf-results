[
  {
    "Accuracy": "ROUGE1: 45.3505  ROUGE2: 23.2113  ROUGEL: 30.312  TOKENS_PER_SAMPLE: 144.9  gsm8k_accuracy: 73.02  mbxp_accuracy: 59.82",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_PROLIANT_DL380A_H200_NVL_141GBX8_TRT/mixtral-8x7b/Offline",
    "MlperfModel": "mixtral-8x7b",
    "Model": "mixtral-8x7b",
    "Organization": "HPE",
    "Platform": "HPE_PROLIANT_DL380A_H200_NVL_141GBX8_TRT",
    "Result": 52205.9,
    "Result_Units": "Tokens/s",
    "Scenario": "Offline",
    "SystemName": "HPE ProLiant DL380a Compute Gen12 (8x H200-NVL-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-NVL-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 192,
    "host_processor_model_name": "Intel(R) Xeon(R) 6740E",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04.1 LTS",
    "uid": "4f18177c0aaa47b6",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/HPE/results/HPE_PROLIANT_DL380A_H200_NVL_141GBX8_TRT/mixtral-8x7b/Offline",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "ROUGE1: 45.2956  ROUGE2: 23.2043  ROUGEL: 30.3791  TOKENS_PER_SAMPLE: 144.9  gsm8k_accuracy: 73.0  mbxp_accuracy: 59.96",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/mixtral-8x7b/Offline",
    "MlperfModel": "mixtral-8x7b",
    "Model": "mixtral-8x7b",
    "Organization": "HPE",
    "Platform": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT",
    "Result": 8324.43,
    "Result_Units": "Tokens/s",
    "Scenario": "Offline",
    "SystemName": "HPE ProLiant Compute DL384 Gen12 (1x GH200-144GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "accelerators_per_node": 1,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.7",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA GH200 144GB HBM3e",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04.1 LTS",
    "uid": "99263e831be042be",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/HPE/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/mixtral-8x7b/Offline",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "ROUGE1: 45.4581  ROUGE2: 23.2422  ROUGEL: 30.2949  TOKENS_PER_SAMPLE: 145.4  gsm8k_accuracy: 73.22  mbxp_accuracy: 59.88",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x2_TRT/mixtral-8x7b/Offline",
    "MlperfModel": "mixtral-8x7b",
    "Model": "mixtral-8x7b",
    "Organization": "HPE",
    "Platform": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x2_TRT",
    "Result": 16703.4,
    "Result_Units": "Tokens/s",
    "Scenario": "Offline",
    "SystemName": "HPE ProLiant Compute DL384 Gen12 (2x GH200-144GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "accelerators_per_node": 2,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 144,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "NVIDIA GH200 144GB HBM3e",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04.1 LTS",
    "uid": "4d6cb2edcc5840cd",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/HPE/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x2_TRT/mixtral-8x7b/Offline",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "ROUGE1: 45.4064  ROUGE2: 23.1865  ROUGEL: 30.2546  TOKENS_PER_SAMPLE: 145.6  gsm8k_accuracy: 73.4  mbxp_accuracy: 60.14",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Sustainable_Metal_Cloud/results/H200-SXM-141GBx8_TRT/mixtral-8x7b/Offline",
    "MlperfModel": "mixtral-8x7b",
    "Model": "mixtral-8x7b",
    "Organization": "Sustainable_Metal_Cloud",
    "Platform": "H200-SXM-141GBx8_TRT",
    "Result": 60923.3,
    "Result_Units": "Tokens/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE9680 (8xH200-SXM-141GBx8, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8462Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "uid": "79cbe4bf6f914767",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Sustainable_Metal_Cloud/results/H200-SXM-141GBx8_TRT/mixtral-8x7b/Offline",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "ROUGEL: 22.092192082812325  exact_match: 90.10742885506286  TOKENS_PER_SAMPLE: 654.1",
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Google/results/B200-SXM-180GBx8_TRT/llama3_1-405b/Offline",
    "MlperfModel": "llama3.1-405b",
    "Model": "llama3_1-405b",
    "Organization": "Google",
    "Platform": "B200-SXM-180GBx8_TRT",
    "Result": 1498.56,
    "Result_Units": "Tokens/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX B200 (8x B200-SXM-180GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA B200-SXM-180GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8570",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "B200 TGP 1000W",
    "number_of_nodes": 1,
    "operating_system": "Debian 12",
    "uid": "d2c9bed6ae374aa8",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Google/results/B200-SXM-180GBx8_TRT/llama3_1-405b/Offline",
    "version": "v5.0",
    "weight_data_types": "fp4"
  },
  {
    "Accuracy": "ROUGE1: 45.4539  ROUGE2: 23.217  ROUGEL: 30.2997  TOKENS_PER_SAMPLE: 144.9  gsm8k_accuracy: 73.16  mbxp_accuracy: 60.5",
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Google/results/B200-SXM-180GBx8_TRT/mixtral-8x7b/Offline",
    "MlperfModel": "mixtral-8x7b",
    "Model": "mixtral-8x7b",
    "Organization": "Google",
    "Platform": "B200-SXM-180GBx8_TRT",
    "Result": 121489,
    "Result_Units": "Tokens/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX B200 (8x B200-SXM-180GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA B200-SXM-180GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8570",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "B200 TGP 1000W",
    "number_of_nodes": 1,
    "operating_system": "Debian 12",
    "uid": "05bfc6e6a8c44938",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Google/results/B200-SXM-180GBx8_TRT/mixtral-8x7b/Offline",
    "version": "v5.0",
    "weight_data_types": "fp4"
  },
  {
    "Accuracy": "ROUGEL: 21.688728239185064  exact_match: 89.9708041032429  TOKENS_PER_SAMPLE: 645.8",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Google/results/H200-SXM-141GBx8_TRT/llama3_1-405b/Offline",
    "MlperfModel": "llama3.1-405b",
    "Model": "llama3_1-405b",
    "Organization": "Google",
    "Platform": "H200-SXM-141GBx8_TRT",
    "Result": 552.592,
    "Result_Units": "Tokens/s",
    "Scenario": "Offline",
    "SystemName": "a3-ultragpu-8g (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8581C CPU",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W. TensorRT LLM",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "uid": "8e9f5155e376422d",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Google/results/H200-SXM-141GBx8_TRT/llama3_1-405b/Offline",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "ROUGE1: 45.4064  ROUGE2: 23.1865  ROUGEL: 30.2546  TOKENS_PER_SAMPLE: 145.6  gsm8k_accuracy: 73.4  mbxp_accuracy: 60.14",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Google/results/H200-SXM-141GBx8_TRT/mixtral-8x7b/Offline",
    "MlperfModel": "mixtral-8x7b",
    "Model": "mixtral-8x7b",
    "Organization": "Google",
    "Platform": "H200-SXM-141GBx8_TRT",
    "Result": 61614.5,
    "Result_Units": "Tokens/s",
    "Scenario": "Offline",
    "SystemName": "a3-ultragpu-8g (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8581C CPU",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W. TensorRT LLM",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "uid": "9797f599a86f4993",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Google/results/H200-SXM-141GBx8_TRT/mixtral-8x7b/Offline",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "ROUGE1: 45.4156  ROUGE2: 23.1543  ROUGEL: 30.2816  TOKENS_PER_SAMPLE: 145.2  gsm8k_accuracy: 72.94  mbxp_accuracy: 59.74",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/S74G_2U_GH200_96GB_aarch64x1_TRT/mixtral-8x7b/Offline",
    "MlperfModel": "mixtral-8x7b",
    "Model": "mixtral-8x7b",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "S74G_2U_GH200_96GB_aarch64x1_TRT",
    "Result": 7792.91,
    "Result_Units": "Tokens/s",
    "Scenario": "Offline",
    "SystemName": "QuantaGrid S74G-2U (1x GH200-96GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "accelerators_per_node": 1,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "QuantaGrid S74G-2U (1x NVIDIA GH200 96GB HBM3)",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.3",
    "uid": "1fc196d9e05141fe",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Quanta_Cloud_Technology/results/S74G_2U_GH200_96GB_aarch64x1_TRT/mixtral-8x7b/Offline",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "ROUGEL: 21.562456891920377  exact_match: 90.11248841826605  TOKENS_PER_SAMPLE: 638.5",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/D74U_7U_H100_SXM_80GBx8_TRT/llama3_1-405b/Offline",
    "MlperfModel": "llama3.1-405b",
    "Model": "llama3_1-405b",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "D74U_7U_H100_SXM_80GBx8_TRT",
    "Result": 436.218,
    "Result_Units": "Tokens/s",
    "Scenario": "Offline",
    "SystemName": "QuantaGrid D74H-7U (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.2",
    "uid": "f16b92f942934f15",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Quanta_Cloud_Technology/results/D74U_7U_H100_SXM_80GBx8_TRT/llama3_1-405b/Offline",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "ROUGE1: 45.4914  ROUGE2: 23.3009  ROUGEL: 30.3779  TOKENS_PER_SAMPLE: 145.2  gsm8k_accuracy: 73.1  mbxp_accuracy: 59.88",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/D74U_7U_H100_SXM_80GBx8_TRT/mixtral-8x7b/Offline",
    "MlperfModel": "mixtral-8x7b",
    "Model": "mixtral-8x7b",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "D74U_7U_H100_SXM_80GBx8_TRT",
    "Result": 51048.7,
    "Result_Units": "Tokens/s",
    "Scenario": "Offline",
    "SystemName": "QuantaGrid D74H-7U (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.2",
    "uid": "4c32b615b92a4b5b",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Quanta_Cloud_Technology/results/D74U_7U_H100_SXM_80GBx8_TRT/mixtral-8x7b/Offline",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "ROUGE1: 45.3734  ROUGE2: 23.2194  ROUGEL: 30.3241  TOKENS_PER_SAMPLE: 145.4  gsm8k_accuracy: 73.22  mbxp_accuracy: 59.86",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/D54U_3U_H100_PCIe_80GBx4_TRT/mixtral-8x7b/Offline",
    "MlperfModel": "mixtral-8x7b",
    "Model": "mixtral-8x7b",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "D54U_3U_H100_PCIe_80GBx4_TRT",
    "Result": 15843.3,
    "Result_Units": "Tokens/s",
    "Scenario": "Offline",
    "SystemName": "QuantaGrid D54U-3U (4x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8.0.43, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54U-3U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.2",
    "uid": "71b3dd6c8f814d78",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Quanta_Cloud_Technology/results/D54U_3U_H100_PCIe_80GBx4_TRT/mixtral-8x7b/Offline",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "ROUGE1: 45.485  ROUGE2: 23.27  ROUGEL: 30.3119  TOKENS_PER_SAMPLE: 145.1  gsm8k_accuracy: 73.48  mbxp_accuracy: 59.94",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/mixtral-8x7b/Offline",
    "MlperfModel": "mixtral-8x7b",
    "Model": "mixtral-8x7b",
    "Organization": "NVIDIA",
    "Platform": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT",
    "Result": 8345.73,
    "Result_Units": "Tokens/s",
    "Scenario": "Offline",
    "SystemName": "HPE ProLiant Compute DL384 Gen12 (1x GH200-144GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "accelerators_per_node": 1,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 144,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA GH200 144GB HBM3e",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "uid": "33340a83b9904678",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/mixtral-8x7b/Offline",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "ROUGEL: 21.985172700345778  exact_match: 90.12750165453342  TOKENS_PER_SAMPLE: 655.9",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/B200-SXM-180GBx8_TRT/llama3_1-405b/Offline",
    "MlperfModel": "llama3.1-405b",
    "Model": "llama3_1-405b",
    "Organization": "NVIDIA",
    "Platform": "B200-SXM-180GBx8_TRT",
    "Result": 1526.29,
    "Result_Units": "Tokens/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX B200 (8x B200-SXM-180GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA B200-SXM-180GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8570",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "B200 TGP 1000W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "uid": "0938f8264fe9427c",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/NVIDIA/results/B200-SXM-180GBx8_TRT/llama3_1-405b/Offline",
    "version": "v5.0",
    "weight_data_types": "fp4"
  },
  {
    "Accuracy": "ROUGE1: 45.5969  ROUGE2: 23.2676  ROUGEL: 30.3668  TOKENS_PER_SAMPLE: 143.9  gsm8k_accuracy: 73.08  mbxp_accuracy: 60.3",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/B200-SXM-180GBx8_TRT/mixtral-8x7b/Offline",
    "MlperfModel": "mixtral-8x7b",
    "Model": "mixtral-8x7b",
    "Organization": "NVIDIA",
    "Platform": "B200-SXM-180GBx8_TRT",
    "Result": 128148,
    "Result_Units": "Tokens/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX B200 (8x B200-SXM-180GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA B200-SXM-180GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8570",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "B200 TGP 1000W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "uid": "a9148195c83c43a2",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/NVIDIA/results/B200-SXM-180GBx8_TRT/mixtral-8x7b/Offline",
    "version": "v5.0",
    "weight_data_types": "fp4"
  },
  {
    "Accuracy": "ROUGEL: 21.93672502698354  exact_match: 90.12851091992057  TOKENS_PER_SAMPLE: 656.4",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/GB200-NVL72_GB200-186GB_aarch64x72_TRT_Triton/llama3_1-405b/Offline",
    "MlperfModel": "llama3.1-405b",
    "Model": "llama3_1-405b",
    "Organization": "NVIDIA",
    "Platform": "GB200-NVL72_GB200-186GB_aarch64x72_TRT_Triton",
    "Result": 13886.4,
    "Result_Units": "Tokens/s",
    "Scenario": "Offline",
    "SystemName": " (72x GB200-186GB_aarch64, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA GB200",
    "accelerators_per_node": 4,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 144,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "NVIDIA GB200 NVL72",
    "number_of_nodes": 18,
    "operating_system": "Ubuntu 24.04",
    "uid": "27a56e3885a64537",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/NVIDIA/results/GB200-NVL72_GB200-186GB_aarch64x72_TRT_Triton/llama3_1-405b/Offline",
    "version": "v5.0",
    "weight_data_types": "fp4"
  },
  {
    "Accuracy": "ROUGEL: 21.63486183033167  exact_match: 90.05081072137656  TOKENS_PER_SAMPLE: 648.6",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT/llama3_1-405b/Offline",
    "MlperfModel": "llama3.1-405b",
    "Model": "llama3_1-405b",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT",
    "Result": 560.651,
    "Result_Units": "Tokens/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "uid": "06f02438c9474bd7",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/NVIDIA/results/H200-SXM-141GBx8_TRT/llama3_1-405b/Offline",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "ROUGE1: 45.4064  ROUGE2: 23.1865  ROUGEL: 30.2546  TOKENS_PER_SAMPLE: 145.6  gsm8k_accuracy: 73.4  mbxp_accuracy: 60.14",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT/mixtral-8x7b/Offline",
    "MlperfModel": "mixtral-8x7b",
    "Model": "mixtral-8x7b",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT",
    "Result": 62629.6,
    "Result_Units": "Tokens/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "uid": "34c759674fb34025",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/NVIDIA/results/H200-SXM-141GBx8_TRT/mixtral-8x7b/Offline",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "ROUGE1: 45.4064  ROUGE2: 23.1865  ROUGEL: 30.2546  TOKENS_PER_SAMPLE: 145.6  gsm8k_accuracy: 73.4  mbxp_accuracy: 60.12",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Oracle/results/H200-SXM-141GBx8_TRT/mixtral-8x7b/Offline",
    "MlperfModel": "mixtral-8x7b",
    "Model": "mixtral-8x7b",
    "Organization": "Oracle",
    "Platform": "H200-SXM-141GBx8_TRT",
    "Result": 60708.6,
    "Result_Units": "Tokens/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.5 LT",
    "uid": "b2e12d4e6e7a445b",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Oracle/results/H200-SXM-141GBx8_TRT/mixtral-8x7b/Offline",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "ROUGEL: 21.697946695208735  exact_match: 90.06889808074122  TOKENS_PER_SAMPLE: 644.8",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/H200-SXM-141GBx8_TRT/llama3_1-405b/Offline",
    "MlperfModel": "llama3.1-405b",
    "Model": "llama3_1-405b",
    "Organization": "ASUSTeK",
    "Platform": "H200-SXM-141GBx8_TRT",
    "Result": 557.097,
    "Result_Units": "Tokens/s",
    "Scenario": "Offline",
    "SystemName": "ASUSTeK ESC N8 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8558",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Data bandwidth for GPU-PCIe: 504 GB/s; PCIe-NIC: 126 GB/s",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "uid": "1908fea94c1247da",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/ASUSTeK/results/H200-SXM-141GBx8_TRT/llama3_1-405b/Offline",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "ROUGEL: 21.6350817800776  exact_match: 90.03330906684316  TOKENS_PER_SAMPLE: 645.1",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/GigaComputing/results/G893-SD1_H200-SXM-141GBx8_TRT/llama3_1-405b/Offline",
    "MlperfModel": "llama3.1-405b",
    "Model": "llama3_1-405b",
    "Organization": "GigaComputing",
    "Platform": "G893-SD1_H200-SXM-141GBx8_TRT",
    "Result": 558.526,
    "Result_Units": "Tokens/s",
    "Scenario": "Offline",
    "SystemName": "G893-SD1",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "bdc87918ea934431",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/GigaComputing/results/G893-SD1_H200-SXM-141GBx8_TRT/llama3_1-405b/Offline",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "ROUGE1: 45.4064  ROUGE2: 23.1865  ROUGEL: 30.2546  TOKENS_PER_SAMPLE: 145.6  gsm8k_accuracy: 73.4  mbxp_accuracy: 60.12",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/GigaComputing/results/G893-SD1_H200-SXM-141GBx8_TRT/mixtral-8x7b/Offline",
    "MlperfModel": "mixtral-8x7b",
    "Model": "mixtral-8x7b",
    "Organization": "GigaComputing",
    "Platform": "G893-SD1_H200-SXM-141GBx8_TRT",
    "Result": 62386.2,
    "Result_Units": "Tokens/s",
    "Scenario": "Offline",
    "SystemName": "G893-SD1",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "d626282c2d644804",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/GigaComputing/results/G893-SD1_H200-SXM-141GBx8_TRT/mixtral-8x7b/Offline",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "ROUGEL: 22.02784417487302  exact_match: 90.10202845797485  TOKENS_PER_SAMPLE: 655.4",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/coreweave/results/GB200-NVL_GB200-NVL-186GB_aarch64x4_TRT/llama3_1-405b/Offline",
    "MlperfModel": "llama3.1-405b",
    "Model": "llama3_1-405b",
    "Organization": "coreweave",
    "Platform": "GB200-NVL_GB200-NVL-186GB_aarch64x4_TRT",
    "Result": 801.906,
    "Result_Units": "Tokens/s",
    "Scenario": "Offline",
    "SystemName": " (4 x GB200-186GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA GB200",
    "accelerators_per_node": 4,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 144,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "NVIDIA GB200 NVL72, 4-GPU node system",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "uid": "34e71412a79f44b5",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/coreweave/results/GB200-NVL_GB200-NVL-186GB_aarch64x4_TRT/llama3_1-405b/Offline",
    "version": "v5.0",
    "weight_data_types": "fp4"
  },
  {
    "Accuracy": "ROUGE1: 45.5315  ROUGE2: 23.3511  ROUGEL: 30.4188  TOKENS_PER_SAMPLE: 144.9  gsm8k_accuracy: 73.28  mbxp_accuracy: 60.06",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/C885A_H100_SXMx8_TRT/mixtral-8x7b/Offline",
    "MlperfModel": "mixtral-8x7b",
    "Model": "mixtral-8x7b",
    "Organization": "Cisco",
    "Platform": "C885A_H100_SXMx8_TRT",
    "Result": 52724.4,
    "Result_Units": "Tokens/s",
    "Scenario": "Offline",
    "SystemName": "Cisco UCS C885A M8 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 9554 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "uid": "aa3d9128a2a149c8",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Cisco/results/C885A_H100_SXMx8_TRT/mixtral-8x7b/Offline",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "ROUGEL: 21.792712875044835  exact_match: 90.00425876902713  TOKENS_PER_SAMPLE: 660.9",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/C885A_M8_H200_SXM_141GBx8_TRT/llama3_1-405b/Offline",
    "MlperfModel": "llama3.1-405b",
    "Model": "llama3_1-405b",
    "Organization": "Cisco",
    "Platform": "C885A_M8_H200_SXM_141GBx8_TRT",
    "Result": 573.573,
    "Result_Units": "Tokens/s",
    "Scenario": "Offline",
    "SystemName": "Cisco UCS C885A M8 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 128,
    "host_processor_model_name": "AMD EPYC 9575F",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "uid": "7d45c3dcda96466d",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Cisco/results/C885A_M8_H200_SXM_141GBx8_TRT/llama3_1-405b/Offline",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "ROUGEL: 22.092192082812325  exact_match: 90.10742885506286  TOKENS_PER_SAMPLE: 654.1",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_A21GE_NBRT_B200_SXM_180GBx8_TRT/llama3_1-405b/Offline",
    "MlperfModel": "llama3.1-405b",
    "Model": "llama3_1-405b",
    "Organization": "Supermicro",
    "Platform": "SYS_A21GE_NBRT_B200_SXM_180GBx8_TRT",
    "Result": 1521.74,
    "Result_Units": "Tokens/s",
    "Scenario": "Offline",
    "SystemName": "SYS-A21GE-NBRT (8x B200-SXM-180GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA B200-SXM-180GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8568Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "B200 TGP 1000W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.5 LTS",
    "uid": "955b6b87d57e4acd",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Supermicro/results/SYS_A21GE_NBRT_B200_SXM_180GBx8_TRT/llama3_1-405b/Offline",
    "version": "v5.0",
    "weight_data_types": "fp4"
  },
  {
    "Accuracy": "ROUGE1: 45.5759  ROUGE2: 23.2321  ROUGEL: 30.3362  TOKENS_PER_SAMPLE: 144.4  gsm8k_accuracy: 73.38  mbxp_accuracy: 60.3",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_A21GE_NBRT_B200_SXM_180GBx8_TRT/mixtral-8x7b/Offline",
    "MlperfModel": "mixtral-8x7b",
    "Model": "mixtral-8x7b",
    "Organization": "Supermicro",
    "Platform": "SYS_A21GE_NBRT_B200_SXM_180GBx8_TRT",
    "Result": 125534,
    "Result_Units": "Tokens/s",
    "Scenario": "Offline",
    "SystemName": "SYS-A21GE-NBRT (8x B200-SXM-180GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA B200-SXM-180GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8568Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "B200 TGP 1000W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.5 LTS",
    "uid": "dee9049b68d44cc7",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Supermicro/results/SYS_A21GE_NBRT_B200_SXM_180GBx8_TRT/mixtral-8x7b/Offline",
    "version": "v5.0",
    "weight_data_types": "fp4"
  },
  {
    "Accuracy": "ROUGE1: 45.4086  ROUGE2: 23.1851  ROUGEL: 30.262  TOKENS_PER_SAMPLE: 145.6  gsm8k_accuracy: 73.4  mbxp_accuracy: 60.12",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_821GE_TNHR_H200_SXM_141GBX8_TRT/mixtral-8x7b/Offline",
    "MlperfModel": "mixtral-8x7b",
    "Model": "mixtral-8x7b",
    "Organization": "Supermicro",
    "Platform": "SYS_821GE_TNHR_H200_SXM_141GBX8_TRT",
    "Result": 61964.1,
    "Result_Units": "Tokens/s",
    "Scenario": "Offline",
    "SystemName": "SYS-821GE-TNHR (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8568Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "uid": "0a0dbbb162564dd0",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Supermicro/results/SYS_821GE_TNHR_H200_SXM_141GBX8_TRT/mixtral-8x7b/Offline",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "ROUGE1: 45.4028  ROUGE2: 23.2139  ROUGEL: 30.3225  TOKENS_PER_SAMPLE: 145.1  gsm8k_accuracy: 73.14  mbxp_accuracy: 59.62",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/ARS_111GL_NHR_TRT/mixtral-8x7b/Offline",
    "MlperfModel": "mixtral-8x7b",
    "Model": "mixtral-8x7b",
    "Organization": "Supermicro",
    "Platform": "ARS_111GL_NHR_TRT",
    "Result": 7718.34,
    "Result_Units": "Tokens/s",
    "Scenario": "Offline",
    "SystemName": "ARS-111GL-NHR (1x GH200-96GB_aarch64)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "accelerators_per_node": 1,
    "compliance": 0,
    "errors": 0,
    "framework": "CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA GH200 96GB HBM3",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "uid": "1e4f71aee79f4f0e",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Supermicro/results/ARS_111GL_NHR_TRT/mixtral-8x7b/Offline",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "ROUGEL: 21.50967980348964  exact_match: 90.01451025810722  TOKENS_PER_SAMPLE: 632.9",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H200_SXM_141GBX8_TRT/llama3_1-405b/Offline",
    "MlperfModel": "llama3.1-405b",
    "Model": "llama3_1-405b",
    "Organization": "Supermicro",
    "Platform": "AS_4125GS_TNHR2_LCC_H200_SXM_141GBX8_TRT",
    "Result": 551.221,
    "Result_Units": "Tokens/s",
    "Scenario": "Offline",
    "SystemName": "AS-4125GS-TNHR2-LCC (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "uid": "2b78249fcc7d4fb7",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H200_SXM_141GBX8_TRT/llama3_1-405b/Offline",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "ROUGE1: 45.4192  ROUGE2: 23.1932  ROUGEL: 30.2622  TOKENS_PER_SAMPLE: 145.7  gsm8k_accuracy: 73.4  mbxp_accuracy: 60.12",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H200_SXM_141GBX8_TRT/mixtral-8x7b/Offline",
    "MlperfModel": "mixtral-8x7b",
    "Model": "mixtral-8x7b",
    "Organization": "Supermicro",
    "Platform": "AS_4125GS_TNHR2_LCC_H200_SXM_141GBX8_TRT",
    "Result": 62766.2,
    "Result_Units": "Tokens/s",
    "Scenario": "Offline",
    "SystemName": "AS-4125GS-TNHR2-LCC (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "uid": "6d5680a71f344598",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H200_SXM_141GBX8_TRT/mixtral-8x7b/Offline",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "ROUGEL: 22.092192082812325  exact_match: 90.10742885506288  TOKENS_PER_SAMPLE: 654.1",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_421GE_NBRT_LCC_B200_SXM_180GBx8_TRT/llama3_1-405b/Offline",
    "MlperfModel": "llama3.1-405b",
    "Model": "llama3_1-405b",
    "Organization": "Supermicro",
    "Platform": "SYS_421GE_NBRT_LCC_B200_SXM_180GBx8_TRT",
    "Result": 1538.17,
    "Result_Units": "Tokens/s",
    "Scenario": "Offline",
    "SystemName": "SYS-421GE-NBRT-LCC (8x B200-SXM-180GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA B200-SXM-180GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8562Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "B200 TGP 1000W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.5 LTS",
    "uid": "39f7034dd6d244f5",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Supermicro/results/SYS_421GE_NBRT_LCC_B200_SXM_180GBx8_TRT/llama3_1-405b/Offline",
    "version": "v5.0",
    "weight_data_types": "fp4"
  },
  {
    "Accuracy": "ROUGE1: 45.6325  ROUGE2: 23.3874  ROUGEL: 30.5099  TOKENS_PER_SAMPLE: 144.4  gsm8k_accuracy: 73.3  mbxp_accuracy: 60.18",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_421GE_NBRT_LCC_B200_SXM_180GBx8_TRT/mixtral-8x7b/Offline",
    "MlperfModel": "mixtral-8x7b",
    "Model": "mixtral-8x7b",
    "Organization": "Supermicro",
    "Platform": "SYS_421GE_NBRT_LCC_B200_SXM_180GBx8_TRT",
    "Result": 128795,
    "Result_Units": "Tokens/s",
    "Scenario": "Offline",
    "SystemName": "SYS-421GE-NBRT-LCC (8x B200-SXM-180GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA B200-SXM-180GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8562Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "B200 TGP 1000W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.5 LTS",
    "uid": "056200f3c26a43aa",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Supermicro/results/SYS_421GE_NBRT_LCC_B200_SXM_180GBx8_TRT/mixtral-8x7b/Offline",
    "version": "v5.0",
    "weight_data_types": "fp4"
  },
  {
    "Accuracy": "ROUGE1: 45.4435  ROUGE2: 23.2094  ROUGEL: 30.2857  TOKENS_PER_SAMPLE: 145.3  gsm8k_accuracy: 73.3  mbxp_accuracy: 59.86",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/SR675v3_H200_SXMx4_TRT/mixtral-8x7b/Offline",
    "MlperfModel": "mixtral-8x7b",
    "Model": "mixtral-8x7b",
    "Organization": "Lenovo",
    "Platform": "SR675v3_H200_SXMx4_TRT",
    "Result": 31503.7,
    "Result_Units": "Tokens/s",
    "Scenario": "Offline",
    "SystemName": "ThinkSystem SR675 V3 (4x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 4,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9655 96-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "uid": "8d2945f06a6c49bf",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Lenovo/results/SR675v3_H200_SXMx4_TRT/mixtral-8x7b/Offline",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "ROUGE1: 45.3468  ROUGE2: 23.202  ROUGEL: 30.3039  TOKENS_PER_SAMPLE: 145.4  gsm8k_accuracy: 73.34  mbxp_accuracy: 60.02",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/H100-NVL-94GBx4_TRT/mixtral-8x7b/Offline",
    "MlperfModel": "mixtral-8x7b",
    "Model": "mixtral-8x7b",
    "Organization": "Lenovo",
    "Platform": "H100-NVL-94GBx4_TRT",
    "Result": 19500.9,
    "Result_Units": "Tokens/s",
    "Scenario": "Offline",
    "SystemName": "ThinkSystem SR650a V4 (4x H100-NVL-94GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 4,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 86,
    "host_processor_model_name": "Intel(R) Xeon(R) 6787P",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "uid": "856388e3638e4bcc",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Lenovo/results/H100-NVL-94GBx4_TRT/mixtral-8x7b/Offline",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "ROUGE1: 45.4086  ROUGE2: 23.1851  ROUGEL: 30.262  TOKENS_PER_SAMPLE: 145.6  gsm8k_accuracy: 73.4  mbxp_accuracy: 60.12",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/SR780a_V3_H200SXMx8/mixtral-8x7b/Offline",
    "MlperfModel": "mixtral-8x7b",
    "Model": "mixtral-8x7b",
    "Organization": "Lenovo",
    "Platform": "SR780a_V3_H200SXMx8",
    "Result": 63514.7,
    "Result_Units": "Tokens/s",
    "Scenario": "Offline",
    "SystemName": "ThinkSystem SR780a V3(8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8568Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "uid": "b03a66d90b884149",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Lenovo/results/SR780a_V3_H200SXMx8/mixtral-8x7b/Offline",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "ROUGE1: 45.4074  ROUGE2: 23.2168  ROUGEL: 30.2703  TOKENS_PER_SAMPLE: 145.3  gsm8k_accuracy: 73.62  mbxp_accuracy: 60.24",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/H200-SXM-141GBx8_TRT/mixtral-8x7b/Offline",
    "MlperfModel": "mixtral-8x7b",
    "Model": "mixtral-8x7b",
    "Organization": "Lenovo",
    "Platform": "H200-SXM-141GBx8_TRT",
    "Result": 63446.7,
    "Result_Units": "Tokens/s",
    "Scenario": "Offline",
    "SystemName": "ThinkSystem SR680a V3(8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8568Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "uid": "705266d78f5848f6",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Lenovo/results/H200-SXM-141GBx8_TRT/mixtral-8x7b/Offline",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "ROUGE1: 45.3218  ROUGE2: 23.243  ROUGEL: 30.2997  TOKENS_PER_SAMPLE: 146.0  gsm8k_accuracy: 73.08  mbxp_accuracy: 59.9",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/vXE9680_H100_SXM_80GBx8_TRT/mixtral-8x7b/Offline",
    "MlperfModel": "mixtral-8x7b",
    "Model": "mixtral-8x7b",
    "Organization": "Dell",
    "Platform": "vXE9680_H100_SXM_80GBx8_TRT",
    "Result": 51514.5,
    "Result_Units": "Tokens/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE9680 (8x H100-SXM-80GB,VMware ESXi 8.0.3) ",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "Virtualized NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel Xeon Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "VM Specifications 64vCPU out of 96 and memory of 1TB GB out of 2TB",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04.1, VMware ESXi 8.0.3 2441450",
    "uid": "ac039e17b74341fa",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Dell/results/vXE9680_H100_SXM_80GBx8_TRT/mixtral-8x7b/Offline",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "ROUGEL: 21.618544328060732  exact_match: 89.99261085373924  TOKENS_PER_SAMPLE: 646.3",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680L_H200_SXM_141GBx8_TRT/llama3_1-405b/Offline",
    "MlperfModel": "llama3.1-405b",
    "Model": "llama3_1-405b",
    "Organization": "Dell",
    "Platform": "XE9680L_H200_SXM_141GBx8_TRT",
    "Result": 559.205,
    "Result_Units": "Tokens/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE9680L (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 120,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "uid": "0659c9ef9c294af7",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Dell/results/XE9680L_H200_SXM_141GBx8_TRT/llama3_1-405b/Offline",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "ROUGE1: 45.37  ROUGE2: 23.2496  ROUGEL: 30.2632  TOKENS_PER_SAMPLE: 145.6  gsm8k_accuracy: 73.3  mbxp_accuracy: 60.1",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680L_H200_SXM_141GBx8_TRT/mixtral-8x7b/Offline",
    "MlperfModel": "mixtral-8x7b",
    "Model": "mixtral-8x7b",
    "Organization": "Dell",
    "Platform": "XE9680L_H200_SXM_141GBx8_TRT",
    "Result": 62042.2,
    "Result_Units": "Tokens/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE9680L (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 120,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "uid": "3515fb65198d4a15",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Dell/results/XE9680L_H200_SXM_141GBx8_TRT/mixtral-8x7b/Offline",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "ROUGEL: 21.643467134956637  exact_match: 90.07990403706154  TOKENS_PER_SAMPLE: 645.6",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/llama3_1-405b/Offline",
    "MlperfModel": "llama3.1-405b",
    "Model": "llama3_1-405b",
    "Organization": "Dell",
    "Platform": "XE9680_H100_SXM_80GBx8_TRT",
    "Result": 397.31,
    "Result_Units": "Tokens/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE9680 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "268ca6362b1548cc",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/llama3_1-405b/Offline",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": 45.3721,
    "Accuracy_div_100": 0.45372,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/mixtral-8x7b/Offline",
    "MlperfModel": "mixtral-8x7b",
    "Model": "mixtral-8x7b",
    "Organization": "Dell",
    "Platform": "XE8640_H100_SXM_80GBx4_TRT",
    "Result": 26824.4,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE8640 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "uid": "2ed5edaf6c864390",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/mixtral-8x7b/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 45.3504,
    "Accuracy_div_100": 0.4535,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/mixtral-8x7b/Offline",
    "MlperfModel": "mixtral-8x7b",
    "Model": "mixtral-8x7b",
    "Organization": "Fujitsu",
    "Platform": "GX2560M7_H100_SXM_80GBx4_TRT",
    "Result": 26641.6,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GX2560M7_H100_SXM_80GBx4 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "2789780991d0469d",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/mixtral-8x7b/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 45.3568,
    "Accuracy_div_100": 0.45357,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/mixtral-8x7b/Offline",
    "MlperfModel": "mixtral-8x7b",
    "Model": "mixtral-8x7b",
    "Organization": "GigaComputing",
    "Platform": "GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT",
    "Result": 59334.8,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GIGABYTE G593-SD1",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "6e2829e46fca42e3",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/mixtral-8x7b/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 45.3671,
    "Accuracy_div_100": 0.45367,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Google/results/DGX-H100_H100-SXM-80GBx8_TRT/mixtral-8x7b/Offline",
    "MlperfModel": "mixtral-8x7b",
    "Model": "mixtral-8x7b",
    "Organization": "Google",
    "Platform": "DGX-H100_H100-SXM-80GBx8_TRT",
    "Result": 52524.4,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8481C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "923b2733c7214b42",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Google/results/DGX-H100_H100-SXM-80GBx8_TRT/mixtral-8x7b/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 45.3565,
    "Accuracy_div_100": 0.45356,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/HPE/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/mixtral-8x7b/Offline",
    "MlperfModel": "mixtral-8x7b",
    "Model": "mixtral-8x7b",
    "Organization": "HPE",
    "Platform": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT",
    "Result": 8063.02,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "HPE ProLiant Compute DL384 Gen12 (1x GH200-144GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "accelerators_per_node": 1,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA GH200 144GB HBM3e",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "uid": "bb7b7d7f917a460e",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/HPE/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/mixtral-8x7b/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 45.3566,
    "Accuracy_div_100": 0.45357,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT/mixtral-8x7b/Offline",
    "MlperfModel": "mixtral-8x7b",
    "Model": "mixtral-8x7b",
    "Organization": "HPE",
    "Platform": "HPE_Cray_XD670_H100_SXM_80GBx8_TRT",
    "Result": 52395.1,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "HPE Cray XD670 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "22.04.4 LTS",
    "uid": "17ca68b6854d4095",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT/mixtral-8x7b/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 45.3448,
    "Accuracy_div_100": 0.45345,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/mixtral-8x7b/Offline",
    "MlperfModel": "mixtral-8x7b",
    "Model": "mixtral-8x7b",
    "Organization": "NVIDIA",
    "Platform": "DGX-H100_H100-SXM-80GBx8_TRT",
    "Result": 52415.9,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "507cdae2111b489f",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/mixtral-8x7b/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 45.3572,
    "Accuracy_div_100": 0.45357,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/mixtral-8x7b/Offline",
    "MlperfModel": "mixtral-8x7b",
    "Model": "mixtral-8x7b",
    "Organization": "NVIDIA",
    "Platform": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT",
    "Result": 8021.46,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA GH200 NVL2 Platform (1x GH200-144GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "accelerators_per_node": 1,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA GH200 144GB HBM3e",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "uid": "ac83669af52b4eb0",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/mixtral-8x7b/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 45.3568,
    "Accuracy_div_100": 0.45357,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT/mixtral-8x7b/Offline",
    "MlperfModel": "mixtral-8x7b",
    "Model": "mixtral-8x7b",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT",
    "Result": 59022.3,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "69260b293ca74b39",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/NVIDIA/results/H200-SXM-141GBx8_TRT/mixtral-8x7b/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 45.3541,
    "Accuracy_div_100": 0.45354,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/mixtral-8x7b/Offline",
    "MlperfModel": "mixtral-8x7b",
    "Model": "mixtral-8x7b",
    "Organization": "Supermicro",
    "Platform": "AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT",
    "Result": 51269,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AS-4125GS-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "uid": "acd1cd0891614cef",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/mixtral-8x7b/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 45.3545,
    "Accuracy_div_100": 0.45355,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/mixtral-8x7b/Offline",
    "MlperfModel": "mixtral-8x7b",
    "Model": "mixtral-8x7b",
    "Organization": "Supermicro",
    "Platform": "AS_8125GS_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 50970.6,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AS-8125GS-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "AMD EPYC 9474F",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "uid": "84f73f6f743e408e",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/mixtral-8x7b/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 45.3632,
    "Accuracy_div_100": 0.45363,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/mixtral-8x7b/Offline",
    "MlperfModel": "mixtral-8x7b",
    "Model": "mixtral-8x7b",
    "Organization": "Supermicro",
    "Platform": "SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT",
    "Result": 52452,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "SYS-421GE-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8570",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "uid": "8703dd5a13a9487f",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/mixtral-8x7b/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 45.3558,
    "Accuracy_div_100": 0.45356,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/mixtral-8x7b/Offline",
    "MlperfModel": "mixtral-8x7b",
    "Model": "mixtral-8x7b",
    "Organization": "Supermicro",
    "Platform": "SYS_821GE_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 52353.8,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "SYS-821GE-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "uid": "ca8555986b92408f",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/mixtral-8x7b/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 45.3664,
    "Accuracy_div_100": 0.45366,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Sustainable_Metal_Cloud/results/SMC_H100_SXM_80GBX8_TRT/mixtral-8x7b/Offline",
    "MlperfModel": "mixtral-8x7b",
    "Model": "mixtral-8x7b",
    "Organization": "Sustainable_Metal_Cloud",
    "Platform": "SMC_H100_SXM_80GBX8_TRT",
    "Result": 52817.7,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "SMC H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8462Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "fce8db9d8dcf4dd3",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Sustainable_Metal_Cloud/results/SMC_H100_SXM_80GBX8_TRT/mixtral-8x7b/Offline",
    "version": "v4.1"
  }
]
