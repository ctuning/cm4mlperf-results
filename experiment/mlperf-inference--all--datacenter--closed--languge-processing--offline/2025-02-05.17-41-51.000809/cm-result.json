[
  {
    "Accuracy": 45.3721,
    "Accuracy_div_100": 0.45372,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/mixtral-8x7b/Offline",
    "MlperfModel": "mixtral-8x7b",
    "Model": "mixtral-8x7b",
    "Organization": "Dell",
    "Platform": "XE8640_H100_SXM_80GBx4_TRT",
    "Result": 26824.4,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE8640 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "uid": "2ed5edaf6c864390",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/mixtral-8x7b/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 45.3504,
    "Accuracy_div_100": 0.4535,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/mixtral-8x7b/Offline",
    "MlperfModel": "mixtral-8x7b",
    "Model": "mixtral-8x7b",
    "Organization": "Fujitsu",
    "Platform": "GX2560M7_H100_SXM_80GBx4_TRT",
    "Result": 26641.6,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GX2560M7_H100_SXM_80GBx4 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "2789780991d0469d",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/mixtral-8x7b/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 45.3568,
    "Accuracy_div_100": 0.45357,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/mixtral-8x7b/Offline",
    "MlperfModel": "mixtral-8x7b",
    "Model": "mixtral-8x7b",
    "Organization": "GigaComputing",
    "Platform": "GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT",
    "Result": 59334.8,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GIGABYTE G593-SD1",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "6e2829e46fca42e3",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/mixtral-8x7b/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 45.3671,
    "Accuracy_div_100": 0.45367,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Google/results/DGX-H100_H100-SXM-80GBx8_TRT/mixtral-8x7b/Offline",
    "MlperfModel": "mixtral-8x7b",
    "Model": "mixtral-8x7b",
    "Organization": "Google",
    "Platform": "DGX-H100_H100-SXM-80GBx8_TRT",
    "Result": 52524.4,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8481C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "923b2733c7214b42",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Google/results/DGX-H100_H100-SXM-80GBx8_TRT/mixtral-8x7b/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 45.3565,
    "Accuracy_div_100": 0.45356,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/HPE/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/mixtral-8x7b/Offline",
    "MlperfModel": "mixtral-8x7b",
    "Model": "mixtral-8x7b",
    "Organization": "HPE",
    "Platform": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT",
    "Result": 8063.02,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "HPE ProLiant Compute DL384 Gen12 (1x GH200-144GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "accelerators_per_node": 1,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA GH200 144GB HBM3e",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "uid": "bb7b7d7f917a460e",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/HPE/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/mixtral-8x7b/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 45.3566,
    "Accuracy_div_100": 0.45357,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT/mixtral-8x7b/Offline",
    "MlperfModel": "mixtral-8x7b",
    "Model": "mixtral-8x7b",
    "Organization": "HPE",
    "Platform": "HPE_Cray_XD670_H100_SXM_80GBx8_TRT",
    "Result": 52395.1,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "HPE Cray XD670 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "22.04.4 LTS",
    "uid": "17ca68b6854d4095",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT/mixtral-8x7b/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 45.3448,
    "Accuracy_div_100": 0.45345,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/mixtral-8x7b/Offline",
    "MlperfModel": "mixtral-8x7b",
    "Model": "mixtral-8x7b",
    "Organization": "NVIDIA",
    "Platform": "DGX-H100_H100-SXM-80GBx8_TRT",
    "Result": 52415.9,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "507cdae2111b489f",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/mixtral-8x7b/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 45.3572,
    "Accuracy_div_100": 0.45357,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/mixtral-8x7b/Offline",
    "MlperfModel": "mixtral-8x7b",
    "Model": "mixtral-8x7b",
    "Organization": "NVIDIA",
    "Platform": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT",
    "Result": 8021.46,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA GH200 NVL2 Platform (1x GH200-144GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "accelerators_per_node": 1,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA GH200 144GB HBM3e",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "uid": "ac83669af52b4eb0",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/mixtral-8x7b/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 45.3568,
    "Accuracy_div_100": 0.45357,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT/mixtral-8x7b/Offline",
    "MlperfModel": "mixtral-8x7b",
    "Model": "mixtral-8x7b",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT",
    "Result": 59022.3,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "69260b293ca74b39",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/NVIDIA/results/H200-SXM-141GBx8_TRT/mixtral-8x7b/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 45.3541,
    "Accuracy_div_100": 0.45354,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/mixtral-8x7b/Offline",
    "MlperfModel": "mixtral-8x7b",
    "Model": "mixtral-8x7b",
    "Organization": "Supermicro",
    "Platform": "AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT",
    "Result": 51269,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AS-4125GS-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "uid": "acd1cd0891614cef",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/mixtral-8x7b/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 45.3545,
    "Accuracy_div_100": 0.45355,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/mixtral-8x7b/Offline",
    "MlperfModel": "mixtral-8x7b",
    "Model": "mixtral-8x7b",
    "Organization": "Supermicro",
    "Platform": "AS_8125GS_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 50970.6,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AS-8125GS-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "AMD EPYC 9474F",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "uid": "84f73f6f743e408e",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/mixtral-8x7b/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 45.3632,
    "Accuracy_div_100": 0.45363,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/mixtral-8x7b/Offline",
    "MlperfModel": "mixtral-8x7b",
    "Model": "mixtral-8x7b",
    "Organization": "Supermicro",
    "Platform": "SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT",
    "Result": 52452,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "SYS-421GE-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8570",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "uid": "8703dd5a13a9487f",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/mixtral-8x7b/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 45.3558,
    "Accuracy_div_100": 0.45356,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/mixtral-8x7b/Offline",
    "MlperfModel": "mixtral-8x7b",
    "Model": "mixtral-8x7b",
    "Organization": "Supermicro",
    "Platform": "SYS_821GE_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 52353.8,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "SYS-821GE-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "uid": "ca8555986b92408f",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/mixtral-8x7b/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 45.3664,
    "Accuracy_div_100": 0.45366,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Sustainable_Metal_Cloud/results/SMC_H100_SXM_80GBX8_TRT/mixtral-8x7b/Offline",
    "MlperfModel": "mixtral-8x7b",
    "Model": "mixtral-8x7b",
    "Organization": "Sustainable_Metal_Cloud",
    "Platform": "SMC_H100_SXM_80GBX8_TRT",
    "Result": 52817.7,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "SMC H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8462Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "fce8db9d8dcf4dd3",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Sustainable_Metal_Cloud/results/SMC_H100_SXM_80GBX8_TRT/mixtral-8x7b/Offline",
    "version": "v4.1"
  }
]
