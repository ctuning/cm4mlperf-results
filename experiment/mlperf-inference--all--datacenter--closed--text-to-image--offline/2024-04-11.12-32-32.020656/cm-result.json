[
  {
    "Accuracy": 31.788790368437766,
    "Accuracy_div_100": 0.31789,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC4000A_E12_4XH100_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "ASUSTeK",
    "Platform": "ESC4000A_E12_4XH100_TRT",
    "Result": 5.89745,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ASUSTeK ESC4000A-E12 (4xH100-NVL-94GB)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 4,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "uid": "594433c53aab4614",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/ASUSTeK/results/ESC4000A_E12_4XH100_TRT/stable-diffusion-xl/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 31.791771094799042,
    "Accuracy_div_100": 0.31792,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC8000A_E12_H100x8_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "ASUSTeK",
    "Platform": "ESC8000A_E12_H100x8_TRT",
    "Result": 9.83763,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ESC8000A-E12 (8x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "AMD EPYC 9374F 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Data bandwidth for GPU-PCIe: 504 GB/s; PCIe-NIC: 126 GB/s",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "uid": "c74070c006bb461c",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/ASUSTeK/results/ESC8000A_E12_H100x8_TRT/stable-diffusion-xl/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 31.782806473374368,
    "Accuracy_div_100": 0.31783,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC_N8_E11_H100x8_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "ASUSTeK",
    "Platform": "ESC_N8_E11_H100x8_TRT",
    "Result": 16.4176,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ESC-N8-E11 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "6f15049b4af8428e",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/ASUSTeK/results/ESC_N8_E11_H100x8_TRT/stable-diffusion-xl/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 31.800232116281986,
    "Accuracy_div_100": 0.318,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/C240M7_L40Sx2_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Cisco",
    "Platform": "C240M7_L40Sx2_TRT",
    "Result": 1.36759,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Cisco UCS C240 M7 (2x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 2,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel Xeon Gold 6448H",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "a5589e6849fb4160",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Cisco/results/C240M7_L40Sx2_TRT/stable-diffusion-xl/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 31.77801339238882,
    "Accuracy_div_100": 0.31778,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/C245M8_H100_PCIe_80GBx2_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Cisco",
    "Platform": "C245M8_H100_PCIe_80GBx2_TRT",
    "Result": 2.4685,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Cisco UCS C245 M8 (2x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 2,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9684X 96-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "ae6486f4a01b4e79",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Cisco/results/C245M8_H100_PCIe_80GBx2_TRT/stable-diffusion-xl/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 31.79840782493353,
    "Accuracy_div_100": 0.31798,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/C245M8_L40Sx2_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Cisco",
    "Platform": "C245M8_L40Sx2_TRT",
    "Result": 1.35121,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Cisco UCS C245 M8 (2x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 2,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9684X 96-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "311dd252fbc544fc",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Cisco/results/C245M8_L40Sx2_TRT/stable-diffusion-xl/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 31.810964519679548,
    "Accuracy_div_100": 0.31811,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/X210c_L40SX2_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Cisco",
    "Platform": "X210c_L40SX2_TRT",
    "Result": 1.37501,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Cisco UCS X210c M7 (2x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 2,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8562Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "8a189c03d1e8497f",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Cisco/results/X210c_L40SX2_TRT/stable-diffusion-xl/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 31.77609215259552,
    "Accuracy_div_100": 0.31776,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760xa_H100NVL_PCIe_94GBx4_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Dell",
    "Platform": "R760xa_H100NVL_PCIe_94GBx4_TRT",
    "Result": 6.13275,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R760xa (4xH100 NVL, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 4,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 120,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "a21c56a44d8c48ae",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Dell/results/R760xa_H100NVL_PCIe_94GBx4_TRT/stable-diffusion-xl/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 31.774510281085966,
    "Accuracy_div_100": 0.31775,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Dell",
    "Platform": "XE8640_H100_SXM_80GBx4_TRT",
    "Result": 8.22546,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE8640 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "uid": "c88c96485608458f",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/stable-diffusion-xl/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 31.797761486172675,
    "Accuracy_div_100": 0.31798,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9640_H100_SXM_80GBx4_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Dell",
    "Platform": "XE9640_H100_SXM_80GBx4_TRT",
    "Result": 8.31658,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE9640 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "uid": "1a7a7424699045ce",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Dell/results/XE9640_H100_SXM_80GBx4_TRT/stable-diffusion-xl/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 31.773352163136007,
    "Accuracy_div_100": 0.31773,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_H200_SXM_141GBx8_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Dell",
    "Platform": "XE9680_H200_SXM_141GBx8_TRT",
    "Result": 17.6742,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE9680 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "2ad4e6d2cc9540b2",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Dell/results/XE9680_H200_SXM_141GBx8_TRT/stable-diffusion-xl/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 31.78535566031933,
    "Accuracy_div_100": 0.31785,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Fujitsu",
    "Platform": "GX2560M7_H100_SXM_80GBx4_TRT",
    "Result": 8.06901,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GX2560M7_H100_SXM_80GBx4 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "0e2186b0544e4a87",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/stable-diffusion-xl/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 31.779202078580855,
    "Accuracy_div_100": 0.31779,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "GigaComputing",
    "Platform": "GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT",
    "Result": 17.3717,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GIGABYTE G593-SD1",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "e49aed9d547e4826",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/stable-diffusion-xl/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 31.79170623779297,
    "Accuracy_div_100": 0.31792,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Google/results/DGX-H100_H100-SXM-80GBx8_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Google",
    "Platform": "DGX-H100_H100-SXM-80GBx8_TRT",
    "Result": 16.2613,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8481C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "946a51c013a3425e",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Google/results/DGX-H100_H100-SXM-80GBx8_TRT/stable-diffusion-xl/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 31.732986239790918,
    "Accuracy_div_100": 0.31733,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Google/results/tpu_v5e_x4_flax/stable-diffusion-xl/offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Google",
    "Platform": "tpu_v5e_x4_flax",
    "Result": 1.75335,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "tpu-v5e-4",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "TPU v5e",
    "accelerators_per_node": 4,
    "compliance": 0,
    "errors": 0,
    "framework": "flax",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 112,
    "host_processor_model_name": "AMD EPYC 7B13",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Linux version 5.19.0-1030-gcp (buildd@bos03-amd64-050) (x86_64-linux-gnu-gcc-12 (Ubuntu 12.1.0-2ubuntu1~22.04) 12.1.0, GNU ld (GNU Binutils for Ubuntu) 2.38) #32~22.04.1-Ubuntu SMP Thu Jul 13 09:36:23 UTC 2023",
    "uid": "927d66f0d37d4ad5",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Google/results/tpu_v5e_x4_flax/stable-diffusion-xl/offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 31.738648088574408,
    "Accuracy_div_100": 0.31739,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Google/results/tpu_v6_x4_flax/stable-diffusion-xl/offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Google",
    "Platform": "tpu_v6_x4_flax",
    "Result": 5.43896,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "tpu-v6-4",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "TPU v6",
    "accelerators_per_node": 4,
    "compliance": 0,
    "errors": 0,
    "framework": "flax",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 180,
    "host_processor_model_name": "AMD EPYC 9B14",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Linux version 6.2.0-1019-gcp (buildd@lcy02-amd64-032) (x86_64-linux-gnu-gcc-12 (Ubuntu 12.3.0-1ubuntu1~22.04) 12.3.0, GNU ld (GNU Binutils for Ubuntu) 2.38) #21~22.04.1-Ubuntu SMP Thu Nov 16 18:18:34 UTC 2023",
    "uid": "85d2f16f93fe423c",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Google/results/tpu_v6_x4_flax/stable-diffusion-xl/offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 31.776026719808577,
    "Accuracy_div_100": 0.31776,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/HPE/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "HPE",
    "Platform": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT",
    "Result": 2.30503,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "HPE ProLiant Compute DL384 Gen12 (1x GH200-144GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "accelerators_per_node": 1,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA GH200 144GB HBM3e",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "uid": "d83b3e1296c74349",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/HPE/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/stable-diffusion-xl/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 31.79560137182474,
    "Accuracy_div_100": 0.31796,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "HPE",
    "Platform": "HPE_Cray_XD670_H100_SXM_80GBx8_TRT",
    "Result": 16.202,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "HPE Cray XD670 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "22.04.4 LTS",
    "uid": "4a55fb8fdfde411b",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT/stable-diffusion-xl/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 31.785679597854614,
    "Accuracy_div_100": 0.31786,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "HPE",
    "Platform": "HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT",
    "Result": 5.80657,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "HPE ProLiant DL380a Gen11 (4x H100-NVL-94GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 4,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "INTEL(R) XEON(R) GOLD 6530",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "uid": "6d7d8618cba04555",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/HPE/results/HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT/stable-diffusion-xl/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 31.789565710127352,
    "Accuracy_div_100": 0.3179,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/H200_SXM_141GBx8_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Lenovo",
    "Platform": "H200_SXM_141GBx8_TRT",
    "Result": 17.1877,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ThinkSystem SR685a V3(8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.5",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "AMD EPYC 9454",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "81b7b9eccbeb4714",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Lenovo/results/H200_SXM_141GBx8_TRT/stable-diffusion-xl/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 31.79363980323076,
    "Accuracy_div_100": 0.31794,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/Lenovo_8xH200_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Lenovo",
    "Platform": "Lenovo_8xH200_TRT",
    "Result": 17.5975,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ThinkSystem SR680a V3 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8568Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "667e901e03fb4b52",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Lenovo/results/Lenovo_8xH200_TRT/stable-diffusion-xl/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 31.775710510313512,
    "Accuracy_div_100": 0.31776,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/SR675_V3_8xH100_NVL_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Lenovo",
    "Platform": "SR675_V3_8xH100_NVL_TRT",
    "Result": 11.827,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ThinkSystem SR675 V3 (8x H100-NVL-94GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.5",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 84,
    "host_processor_model_name": "AMD EPYC 9634 84-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "629afb94b2f8486d",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Lenovo/results/SR675_V3_8xH100_NVL_TRT/stable-diffusion-xl/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 31.78304835319519,
    "Accuracy_div_100": 0.31783,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "NVIDIA",
    "Platform": "DGX-H100_H100-SXM-80GBx8_TRT",
    "Result": 16.3484,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "ad3eeff8956f4d51",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/stable-diffusion-xl/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 31.780162643492222,
    "Accuracy_div_100": 0.3178,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "NVIDIA",
    "Platform": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT",
    "Result": 2.30033,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA GH200 NVL2 Platform (1x GH200-144GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "accelerators_per_node": 1,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA GH200 144GB HBM3e",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "uid": "8d87b9f189a6422e",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/stable-diffusion-xl/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 31.783374754488467,
    "Accuracy_div_100": 0.31783,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT",
    "Result": 17.4186,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "f21283c69d054163",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/NVIDIA/results/H200-SXM-141GBx8_TRT/stable-diffusion-xl/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 31.793397405743598,
    "Accuracy_div_100": 0.31793,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/D54U_3U_H100_PCIe_80GBx4_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "D54U_3U_H100_PCIe_80GBx4_TRT",
    "Result": 4.91259,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "D54U_3U_H100_PCIe_80GBx4_TRT",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54U-3U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.2",
    "uid": "f72935d33c844e7b",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Quanta_Cloud_Technology/results/D54U_3U_H100_PCIe_80GBx4_TRT/stable-diffusion-xl/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 31.784094333946705,
    "Accuracy_div_100": 0.31784,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "Result": 2.08805,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "accelerators_per_node": 1,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "QuantaGrid S74G-2U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.3",
    "uid": "44a655ecf34b4dca",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Quanta_Cloud_Technology/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/stable-diffusion-xl/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 31.79114451110363,
    "Accuracy_div_100": 0.31791,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Supermicro",
    "Platform": "AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT",
    "Result": 16.1466,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AS-4125GS-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "uid": "208a6d2d4f0a4aab",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/stable-diffusion-xl/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 31.795211831629278,
    "Accuracy_div_100": 0.31795,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Supermicro",
    "Platform": "AS_8125GS_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 16.0092,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AS-8125GS-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "AMD EPYC 9474F",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "uid": "e8ea7b48f5c540df",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/stable-diffusion-xl/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 31.797936390638352,
    "Accuracy_div_100": 0.31798,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Supermicro",
    "Platform": "SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT",
    "Result": 16.4933,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "SYS-421GE-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8570",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "uid": "107eacfa292e4361",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/stable-diffusion-xl/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 31.779239302873613,
    "Accuracy_div_100": 0.31779,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Supermicro",
    "Platform": "SYS_821GE_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 16.3778,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "SYS-821GE-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "uid": "97e8eb5575174c57",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/stable-diffusion-xl/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 31.77740065872669,
    "Accuracy_div_100": 0.31777,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC8000_E11P_H100x8_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "ASUSTeK",
    "Platform": "ESC8000_E11P_H100x8_TRT",
    "Result": 8.68324,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ESC8000-E11P (8x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Data bandwidth for GPU-PCIe: 504 GB/s; PCIe-NIC: 126 GB/s",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "4aaf4201c53f418c",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/ASUSTeK/results/ESC8000_E11P_H100x8_TRT/stable-diffusion-xl/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 31.78107699036598,
    "Accuracy_div_100": 0.31781,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC8000_E11_L40Sx8_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "ASUSTeK",
    "Platform": "ESC8000_E11_L40Sx8_TRT",
    "Result": 5.04255,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ESC8000-E11 (8x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6442Y",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Data bandwidth for GPU-PCIe: 252 GB/s; PCIe-NIC: 63 GB/s",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "cc549c8cb621424d",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/ASUSTeK/results/ESC8000_E11_L40Sx8_TRT/stable-diffusion-xl/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 31.764705021083355,
    "Accuracy_div_100": 0.31765,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760xa_L40Sx4_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Dell",
    "Platform": "R760xa_L40Sx4_TRT",
    "Result": 2.68759,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R760xa (4x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6338 CPU @ 2.00GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.1",
    "uid": "e760522d82e04581",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Dell/results/R760xa_L40Sx4_TRT/stable-diffusion-xl/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 31.76944550603628,
    "Accuracy_div_100": 0.31769,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R7615_L40Sx2_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Dell",
    "Platform": "R7615_L40Sx2_TRT",
    "Result": 1.33199,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R7615 (2x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 9354 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6 LTS",
    "uid": "8fc0ca85a25843a3",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Dell/results/R7615_L40Sx2_TRT/stable-diffusion-xl/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 31.779640387892723,
    "Accuracy_div_100": 0.3178,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/vR760_L40S_48Cx2_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Dell",
    "Platform": "vR760_L40S_48Cx2_TRT",
    "Result": 1.29077,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R760 (2x L40S, TensorRT, VMware ESXi 8.0.2)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "Virtualized NVIDIA L40S",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 60,
    "host_processor_model_name": "Intel Xeon Platinum 8580",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Broadcom VM Specifications 32vCPU out of 120 and memory of 128 GB out of 1.5TB",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4, VMware ESXi 8.0.2 22380479",
    "uid": "ef2a4eaeda0548d3",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Dell/results/vR760_L40S_48Cx2_TRT/stable-diffusion-xl/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 31.772421202063562,
    "Accuracy_div_100": 0.31772,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Dell",
    "Platform": "XE8640_H100_SXM_80GBx4_TRT",
    "Result": 6.30174,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE8640 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "uid": "b33b480be6f64006",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/stable-diffusion-xl/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 31.802004318535328,
    "Accuracy_div_100": 0.31802,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9640_H100_SXM_80GBX4_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Dell",
    "Platform": "XE9640_H100_SXM_80GBX4_TRT",
    "Result": 6.6036,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE9640 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "473b4a9a96bf4fef",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Dell/results/XE9640_H100_SXM_80GBX4_TRT/stable-diffusion-xl/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 31.786813072264195,
    "Accuracy_div_100": 0.31787,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Dell",
    "Platform": "XE9680_H100_SXM_80GBx8_TRT",
    "Result": 12.646,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE9680 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "7f170374ab6349d6",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/stable-diffusion-xl/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 31.78375532358885,
    "Accuracy_div_100": 0.31784,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_IntelXeon8480_NVIDIA_H100_SXM_80GBx8_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Dell",
    "Platform": "XE9680_IntelXeon8480_NVIDIA_H100_SXM_80GBx8_TRT",
    "Result": 13.1466,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE9680 (8x H100-SXM-80GB, TensorRT,VMware ESXi 8.0.2) ",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "Virtualized NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel Xeon Platinum 8480",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Broadcom VM Specifications 32vCPU out of 224 and memory of 128 GB out of 1TB",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4, VMware ESXi 8.0.2 22380479",
    "uid": "9747c93e9a274812",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Dell/results/XE9680_IntelXeon8480_NVIDIA_H100_SXM_80GBx8_TRT/stable-diffusion-xl/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 31.79328647792339,
    "Accuracy_div_100": 0.31793,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/CDI_L40Sx16_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Fujitsu",
    "Platform": "CDI_L40Sx16_TRT",
    "Result": 10.091,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "PRIMERGY CDI (16x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 16,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 36,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8452Y",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "abb5002379d94781",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Fujitsu/results/CDI_L40Sx16_TRT/stable-diffusion-xl/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 31.77854673177004,
    "Accuracy_div_100": 0.31779,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Fujitsu",
    "Platform": "GX2560M7_H100_SXM_80GBx4_TRT",
    "Result": 6.50872,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GX2560M7_H100_SXM_80GBx4 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "bebced6dbb58412b",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/stable-diffusion-xl/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 31.79849381059408,
    "Accuracy_div_100": 0.31798,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/GigaComputing/results/GIGABYTE-G593-SD1_DGX-H100_H100-SXM-80GBx8_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "GigaComputing",
    "Platform": "GIGABYTE-G593-SD1_DGX-H100_H100-SXM-80GBx8_TRT",
    "Result": 13.2017,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GIGABYTE G593-SD1",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Data bandwidth for GPU-PCIe: 504 GB/s; PCIe-NIC: 600GB/s",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "b94fed2aab43424e",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/GigaComputing/results/GIGABYTE-G593-SD1_DGX-H100_H100-SXM-80GBx8_TRT/stable-diffusion-xl/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 31.785929176211358,
    "Accuracy_div_100": 0.31786,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Google/results/H100-SXM-80GBx8_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Google",
    "Platform": "H100-SXM-80GBx8_TRT",
    "Result": 12.9149,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 208,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8481C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "be3a8480b444402b",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Google/results/H100-SXM-80GBx8_TRT/stable-diffusion-xl/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 31.774508028030397,
    "Accuracy_div_100": 0.31775,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "HPE",
    "Platform": "HPE_Cray_XD670_H100_SXM_80GBx8_TRT_TRT",
    "Result": 13.1554,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "HPE Cray XD670 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.3",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.3",
    "uid": "ab81fdc4faf948b8",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT_TRT/stable-diffusion-xl/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 31.793944376111032,
    "Accuracy_div_100": 0.31794,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "HPE",
    "Platform": "HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT",
    "Result": 2.56363,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "HPE ProLiant DL380a Gen11 (4x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 60,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8580",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "61f9b20d3aa54afb",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/HPE/results/HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT/stable-diffusion-xl/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 31.749508016109466,
    "Accuracy_div_100": 0.3175,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Intel-HabanaLabs/results/HLS-Gaudi2-PT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Intel-HabanaLabs",
    "Platform": "HLS-Gaudi2-PT",
    "Result": 6.25699,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "HLS-Gaudi2-PT",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "Intel\u00ae Gaudi\u00ae 2 AI Accelerator",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch 2.1.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "08a94a34a3014524",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Intel-HabanaLabs/results/HLS-Gaudi2-PT/stable-diffusion-xl/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 31.794219019412996,
    "Accuracy_div_100": 0.31794,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Krai/results/g292_q16_pro_pp/stable-diffusion-xl/offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Krai",
    "Platform": "g292_q16_pro_pp",
    "Result": 1.17942,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GIGABYTE G292-Z43 (16x QAIC100 Pro)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 Pro",
    "accelerators_per_node": 16,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.14.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7713 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS (6.2.0-37-generic #38~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov  2 18:01:13 UTC 2 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "a80e521565be46dd",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Krai/results/g292_q16_pro_pp/stable-diffusion-xl/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 31.78709009349346,
    "Accuracy_div_100": 0.31787,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx1_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "NVIDIA",
    "Platform": "DGX-H100_H100-SXM-80GBx1_TRT",
    "Result": 1.64178,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX H100 (1x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "2efff086b7994d0f",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx1_TRT/stable-diffusion-xl/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 31.789112366735935,
    "Accuracy_div_100": 0.31789,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "NVIDIA",
    "Platform": "DGX-H100_H100-SXM-80GBx8_TRT",
    "Result": 13.1263,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "75299432d5b742fb",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/stable-diffusion-xl/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 31.803725126981735,
    "Accuracy_div_100": 0.31804,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "NVIDIA",
    "Platform": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "Result": 1.76321,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA GH200-GraceHopper-Superchip (1x GH200-96GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GH200-GraceHopper-Superchip",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA MGX Reference Platform;",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "uid": "403351c4b03f4b0f",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/stable-diffusion-xl/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 31.80100793391466,
    "Accuracy_div_100": 0.31801,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT",
    "Result": 13.7059,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "3518129f21e549b6",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/NVIDIA/results/H200-SXM-141GBx8_TRT/stable-diffusion-xl/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 31.809893064796924,
    "Accuracy_div_100": 0.3181,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/L40Sx8_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "NVIDIA",
    "Platform": "L40Sx8_TRT",
    "Result": 5.01972,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ASROCKRACK 4U8G-ROME2/4E (8x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "f1cc5153966e42b3",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/NVIDIA/results/L40Sx8_TRT/stable-diffusion-xl/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 31.790665960609914,
    "Accuracy_div_100": 0.31791,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Oracle/results/OCI-H100_H100-SXM-80GBx8_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Oracle",
    "Platform": "OCI-H100_H100-SXM-80GBx8_TRT",
    "Result": 13.0611,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "BM.GPU.H100.8",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0.1, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "eb18f015224e4240",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Oracle/results/OCI-H100_H100-SXM-80GBx8_TRT/stable-diffusion-xl/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 31.791159887611865,
    "Accuracy_div_100": 0.31791,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/D54U_3U_H100_PCIe_80GBx4_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "D54U_3U_H100_PCIe_80GBx4_TRT",
    "Result": 4.41144,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "D54U_3U_H100_PCIe_80GBx4_TRT",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.3",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54U-3U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.2",
    "uid": "5d04a83b2d484d9f",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Quanta_Cloud_Technology/results/D54U_3U_H100_PCIe_80GBx4_TRT/stable-diffusion-xl/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 31.78787018895149,
    "Accuracy_div_100": 0.31788,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/D54U_3U_L40S_PCIe_48GBx4_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "D54U_3U_L40S_PCIe_48GBx4_TRT",
    "Result": 2.63032,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "D54U_3U_L40S_PCIe_48GBx4_TRT",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.3",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54U-3U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.2",
    "uid": "628268556f544973",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Quanta_Cloud_Technology/results/D54U_3U_L40S_PCIe_48GBx4_TRT/stable-diffusion-xl/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 31.803020991683006,
    "Accuracy_div_100": 0.31803,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "Result": 1.79701,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GH200-GraceHopper-Superchip",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "QuantaGrid S74G-2U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.1",
    "uid": "89f5a23d77bf419e",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Quanta_Cloud_Technology/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/stable-diffusion-xl/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 31.79720392405987,
    "Accuracy_div_100": 0.31797,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Supermicro",
    "Platform": "SYS_821GE_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 13.1896,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "SYS-821GE-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8568Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3 LTS",
    "uid": "885cfd8017964155",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/stable-diffusion-xl/Offline",
    "version": "v4.0"
  }
]
