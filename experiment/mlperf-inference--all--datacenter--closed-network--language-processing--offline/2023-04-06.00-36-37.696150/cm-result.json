[
  {
    "Accuracy": 90.28408874066913,
    "Accuracy_div_100": 0.90284,
    "Availability": "available",
    "Division": "network",
    "Location": "network/Krai/results/dl385_q8_std/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Krai",
    "Platform": "dl385_q8_std",
    "Result": 5700.92,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "HPE ProLiant DL385 Gen10 Plus v2 (8x QAIC100 Standard) [NETWORK]",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 Standard",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "AMD EPYC 7543 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Powered by the KRAI X and KILT technologies over the network",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6 LTS (Linux kernel 5.15.0-91-generic #101~20.04.1-Ubuntu SMP Thu Nov 16 14:22:28 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "e7c0c89d0c214781",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/network/Krai/results/dl385_q8_std/bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.8666333229796,
    "Accuracy_div_100": 0.90867,
    "Availability": "available",
    "Division": "network",
    "Location": "network/Krai/results/dl385_q8_std/bert-99.9/offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Krai",
    "Platform": "dl385_q8_std",
    "Result": 2926.61,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "HPE ProLiant DL385 Gen10 Plus v2 (8x QAIC100 Standard) [NETWORK]",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 Standard",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "AMD EPYC 7543 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Powered by the KRAI X and KILT technologies over the network",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6 LTS (Linux kernel 5.15.0-91-generic #101~20.04.1-Ubuntu SMP Thu Nov 16 14:22:28 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "505b5b5946af47aa",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/network/Krai/results/dl385_q8_std/bert-99.9/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.28408874066913,
    "Accuracy_div_100": 0.90284,
    "Availability": "available",
    "Division": "network",
    "Location": "network/Qualcomm/results/g292_z43_q16/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Qualcomm",
    "Platform": "g292_z43_q16",
    "Result": 12541.2,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G292-Z43 (16x QAIC100)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 16,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.9.1",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7713 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6 LTS (Linux kernel: 5.4.0-139-generic #156-Ubuntu SMP Fri Jan 20 17:27:18 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "2d50fdbfff7b4f32",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/network/Qualcomm/results/g292_z43_q16/bert-99/offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.8666333229796,
    "Accuracy_div_100": 0.90867,
    "Availability": "available",
    "Division": "network",
    "Location": "network/Qualcomm/results/g292_z43_q16/bert-99.9/offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Qualcomm",
    "Platform": "g292_z43_q16",
    "Result": 6313.36,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G292-Z43 (16x QAIC100)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 16,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.9.1",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7713 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6 LTS (Linux kernel: 5.4.0-139-generic #156-Ubuntu SMP Fri Jan 20 17:27:18 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "5087a28523964689",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/network/Qualcomm/results/g292_z43_q16/bert-99.9/offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.28408874066913,
    "Accuracy_div_100": 0.90284,
    "Availability": "available",
    "Division": "network",
    "Location": "network/HPE/results/dl385_q8_std/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "HPE",
    "Platform": "dl385_q8_std",
    "Result": 5906.87,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "HPE ProLiant DL385 Gen10 Plus v2 (8x QAIC100 Standard)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Standard",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.9.1",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "AMD EPYC 7543 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6 LTS (Linux kernel 5.15.0-75-generic #82~20.04.1-Ubuntu SMP Wed Jun 7 19:37:37 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "572d87f51cc840ce",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/network/HPE/results/dl385_q8_std/bert-99/offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.8666333229796,
    "Accuracy_div_100": 0.90867,
    "Availability": "available",
    "Division": "network",
    "Location": "network/HPE/results/dl385_q8_std/bert-99.9/offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "HPE",
    "Platform": "dl385_q8_std",
    "Result": 2956.35,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "HPE ProLiant DL385 Gen10 Plus v2 (8x QAIC100 Standard)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Standard",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.9.1",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "AMD EPYC 7543 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6 LTS (Linux kernel 5.15.0-75-generic #82~20.04.1-Ubuntu SMP Wed Jun 7 19:37:37 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "80a833f952fd4434",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/network/HPE/results/dl385_q8_std/bert-99.9/offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.38529083707651,
    "Accuracy_div_100": 0.90385,
    "Availability": "available",
    "Division": "network",
    "Location": "network/Alibaba/results/SINIAN_VODLA_EFLO_A100x16_A30x16/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Alibaba",
    "Platform": "SINIAN_VODLA_EFLO_A100x16_A30x16",
    "Result": 79486.9,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Alibaba Cloud Server Sinian Platform (vODLA-EFLO, A100x16_A30x16)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "2 Nodes: NVIDIA A100-SXM-80GBx8, 4 Nodes: NVIDIA A30x4",
    "accelerators_per_node": "(8,4)",
    "compliance": 1,
    "errors": 0,
    "framework": "SINIAN VODLA",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8369B CPU (A100), Intel(R) Xeon(R) Silver 4314 (A30)",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 6,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "57e07d7591124983",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/network/Alibaba/results/SINIAN_VODLA_EFLO_A100x16_A30x16/bert-99/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.38087866142499,
    "Accuracy_div_100": 0.90381,
    "Availability": "available",
    "Division": "network",
    "Location": "network/Alibaba/results/SINIAN_VODLA_EFLO_A100x32/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Alibaba",
    "Platform": "SINIAN_VODLA_EFLO_A100x32",
    "Result": 107060,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Alibaba Cloud Server Sinian Platform (vODLA-EFLO, A100x32)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "SINIAN VODLA",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8369B CPU",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 4,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "a41a9b578a4547f6",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/network/Alibaba/results/SINIAN_VODLA_EFLO_A100x32/bert-99/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.87595439490713,
    "Accuracy_div_100": 0.90876,
    "Availability": "available",
    "Division": "network",
    "Location": "network/Alibaba/results/SINIAN_VODLA_EFLO_A100x32/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Alibaba",
    "Platform": "SINIAN_VODLA_EFLO_A100x32",
    "Result": 53957.9,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Alibaba Cloud Server Sinian Platform (vODLA-EFLO, A100x32)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "SINIAN VODLA",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8369B CPU",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 4,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "260e5474ce1a4bb4",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/network/Alibaba/results/SINIAN_VODLA_EFLO_A100x32/bert-99.9/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.38087866142499,
    "Accuracy_div_100": 0.90381,
    "Availability": "available",
    "Division": "network",
    "Location": "network/Alibaba/results/SINIAN_VODLA_EFLO_A100x16/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Alibaba",
    "Platform": "SINIAN_VODLA_EFLO_A100x16",
    "Result": 53322.6,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Alibaba Cloud Server Sinian Platform (vODLA-EFLO, A100x16)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "SINIAN VODLA",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8369B CPU",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 2,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "6e71f42162b649fd",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/network/Alibaba/results/SINIAN_VODLA_EFLO_A100x16/bert-99/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.87595439490713,
    "Accuracy_div_100": 0.90876,
    "Availability": "available",
    "Division": "network",
    "Location": "network/Alibaba/results/SINIAN_VODLA_EFLO_A100x16/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Alibaba",
    "Platform": "SINIAN_VODLA_EFLO_A100x16",
    "Result": 27233.8,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Alibaba Cloud Server Sinian Platform (vODLA-EFLO, A100x16)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "SINIAN VODLA",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8369B CPU",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 2,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "9898f930a4eb41a4",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/network/Alibaba/results/SINIAN_VODLA_EFLO_A100x16/bert-99.9/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.38529083707651,
    "Accuracy_div_100": 0.90385,
    "Availability": "available",
    "Division": "network",
    "Location": "network/Alibaba/results/SINIAN_VODLA_EFLO_A100x8_A30x8/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Alibaba",
    "Platform": "SINIAN_VODLA_EFLO_A100x8_A30x8",
    "Result": 40175.9,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Alibaba Cloud Server Sinian Platform (vODLA-EFLO, A100x8_A30x8)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "1 Node: NVIDIA A100-SXM-80GBx8, 2 Nodes: NVIDIA A30x4",
    "accelerators_per_node": "(8,4)",
    "compliance": 1,
    "errors": 0,
    "framework": "SINIAN VODLA",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8369B CPU (A100), Intel(R) Xeon(R) Silver 4314 (A30)",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 3,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "737491b200ee486a",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/network/Alibaba/results/SINIAN_VODLA_EFLO_A100x8_A30x8/bert-99/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.38529083707651,
    "Accuracy_div_100": 0.90385,
    "Availability": "available",
    "Division": "network",
    "Location": "network/Alibaba/results/SINIAN_VODLA_EFLO_A30x16/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Alibaba",
    "Platform": "SINIAN_VODLA_EFLO_A30x16",
    "Result": 26289.5,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Alibaba Cloud Server Sinian Platform (vODLA-EFLO, A30x16)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "SINIAN VODLA",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Silver 4314",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 4,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "518d7957439c4c40",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/network/Alibaba/results/SINIAN_VODLA_EFLO_A30x16/bert-99/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.87595439490713,
    "Accuracy_div_100": 0.90876,
    "Availability": "available",
    "Division": "network",
    "Location": "network/Alibaba/results/SINIAN_VODLA_EFLO_A30x16/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Alibaba",
    "Platform": "SINIAN_VODLA_EFLO_A30x16",
    "Result": 12901.4,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Alibaba Cloud Server Sinian Platform (vODLA-EFLO, A30x16)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "SINIAN VODLA",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Silver 4314",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 4,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "02747dff0cff48de",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/network/Alibaba/results/SINIAN_VODLA_EFLO_A30x16/bert-99.9/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.38590173403216,
    "Accuracy_div_100": 0.90386,
    "Availability": "available",
    "Division": "network",
    "Location": "network/NVIDIA/results/SUT_DGX_A100-SXM-80GBx8_CX6x8_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "SUT_DGX_A100-SXM-80GBx8_CX6x8_TRT",
    "Result": 26536.5,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX A100 (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.5.3, CUDA 11.8",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "SUT node with A100 SXM x8 and CX6 x8. MOFED 5.7-1.0.2.0",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "08b65e1439d74610",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/network/NVIDIA/results/SUT_DGX_A100-SXM-80GBx8_CX6x8_TRT/bert-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.88462035425279,
    "Accuracy_div_100": 0.90885,
    "Availability": "available",
    "Division": "network",
    "Location": "network/NVIDIA/results/SUT_DGX_A100-SXM-80GBx8_CX6x8_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "SUT_DGX_A100-SXM-80GBx8_CX6x8_TRT",
    "Result": 13173.1,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX A100 (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.5.3, CUDA 11.8",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "SUT node with A100 SXM x8 and CX6 x8. MOFED 5.7-1.0.2.0",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "b0eaa51cce704ab7",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/network/NVIDIA/results/SUT_DGX_A100-SXM-80GBx8_CX6x8_TRT/bert-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.2426510242233,
    "Accuracy_div_100": 0.90243,
    "Availability": "available",
    "Division": "network",
    "Location": "network/Qualcomm/results/g292_z43_q18-qaic-v1.8.3.7-aic100/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Qualcomm",
    "Platform": "g292_z43_q18-qaic-v1.8.3.7-aic100",
    "Result": 14026,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GIGABYTE G292-Z43 (18x QAIC100 Pro)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 18,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.8.3",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7713 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5 LTS (Linux kernel: 5.4.0-135-generic #152-Ubuntu SMP Wed Nov 23 20:19:22 UTC 2022)",
    "uid": "1800ace1bda94ee0",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/network/Qualcomm/results/g292_z43_q18-qaic-v1.8.3.7-aic100/bert-99/offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.8666333229796,
    "Accuracy_div_100": 0.90867,
    "Availability": "available",
    "Division": "network",
    "Location": "network/Qualcomm/results/g292_z43_q18-qaic-v1.8.3.7-aic100/bert-99.9/offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Qualcomm",
    "Platform": "g292_z43_q18-qaic-v1.8.3.7-aic100",
    "Result": 7186.02,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GIGABYTE G292-Z43 (18x QAIC100 Pro)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 18,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.8.3",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7713 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5 LTS (Linux kernel: 5.4.0-135-generic #152-Ubuntu SMP Wed Nov 23 20:19:22 UTC 2022)",
    "uid": "380265788cd64542",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/network/Qualcomm/results/g292_z43_q18-qaic-v1.8.3.7-aic100/bert-99.9/offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.2426510242233,
    "Accuracy_div_100": 0.90243,
    "Availability": "available",
    "Division": "network",
    "Location": "network/HPE/results/dl385_q8_std-qaic-v1.8.3.7-aic100/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "HPE",
    "Platform": "dl385_q8_std-qaic-v1.8.3.7-aic100",
    "Result": 5871.11,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "HPE ProLiant DL385 Gen10 Plus v2 (8x QAIC100 Standard)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Standard",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.8.3",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "AMD EPYC 7543 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5 LTS (Linux kernel: 5.15.0-60-generic #66~20.04.1-Ubuntu SMP Wed Jan 25 09:41:30 UTC 2023)",
    "uid": "e4e1cfb999034197",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/network/HPE/results/dl385_q8_std-qaic-v1.8.3.7-aic100/bert-99/offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.8666333229796,
    "Accuracy_div_100": 0.90867,
    "Availability": "available",
    "Division": "network",
    "Location": "network/HPE/results/dl385_q8_std-qaic-v1.8.3.7-aic100/bert-99.9/offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "HPE",
    "Platform": "dl385_q8_std-qaic-v1.8.3.7-aic100",
    "Result": 2694.57,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "HPE ProLiant DL385 Gen10 Plus v2 (8x QAIC100 Standard)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Standard",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.8.3",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "AMD EPYC 7543 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5 LTS (Linux kernel: 5.15.0-60-generic #66~20.04.1-Ubuntu SMP Wed Jan 25 09:41:30 UTC 2023)",
    "uid": "58e67d6e130a4b11",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/network/HPE/results/dl385_q8_std-qaic-v1.8.3.7-aic100/bert-99.9/offline",
    "version": "v3.0"
  }
]
