[
  {
    "Accuracy": 90.21494616303566,
    "Accuracy_div_100": 0.90215,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/cm-demo-gfursin-aws-g4dn.4xlarge-nvidia_original-gpu-tensorrt-vdefault-default_config/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "CTuning",
    "Platform": "cm-demo-gfursin-aws-g4dn.4xlarge-nvidia_original-gpu-tensorrt-vdefault-default_config",
    "Result": 381.124,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "aws-g4dn-4xlarge",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "Tesla T4",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 8,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "cTuning.org/ae: Collective Mind demo for our reproducibility initiatives and artifact evaluation at ACM, IEEE and MLCommons ; automated by MLCommons CM v2.3.4 ; taken by Grigori Fursin",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04 (linux-6.5.0-1023-aws-glibc2.31)",
    "uid": "89a196b600704740",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/open/CTuning/results/cm-demo-gfursin-aws-g4dn.4xlarge-nvidia_original-gpu-tensorrt-vdefault-default_config/bert-99/offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 43.0343,
    "Accuracy_div_100": 0.43034,
    "Availability": "available",
    "Division": "open",
    "Location": "open/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "HPE",
    "Platform": "HPE_Cray_XD670_H100_SXM_80GBx8_TRT",
    "Result": 19889.7,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "HPE Cray XD670 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "22.04.4 LTS",
    "uid": "9dfa504b06ff4975",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/open/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT/gptj-99.9/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 44.2003,
    "Accuracy_div_100": 0.442,
    "Availability": "available",
    "Division": "open",
    "Location": "open/NeuralMagic/results/4xH100-SXM-80GB_vLLM_GPTQ-reference-cpu-pytorch-v2.3.1-default_config/llama2-70b-99/offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "NeuralMagic",
    "Platform": "4xH100-SXM-80GB_vLLM_GPTQ-reference-cpu-pytorch-v2.3.1-default_config",
    "Result": 1577.11,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "SYS-821GE-TNHR H100 'beaker' (4x H100-SXM-80GB, vLLM, GPTQ)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "vLLM 0.5.2",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8462Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.3.4. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.5.0-35-generic-glibc2.35)",
    "uid": "4ee49c03413c434c",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/open/NeuralMagic/results/4xH100-SXM-80GB_vLLM_GPTQ-reference-cpu-pytorch-v2.3.1-default_config/llama2-70b-99/offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 44.0047,
    "Accuracy_div_100": 0.44005,
    "Availability": "available",
    "Division": "open",
    "Location": "open/NeuralMagic/results/GO_2xRTX4090-reference-cpu-pytorch-v2.2.1-default_config/llama2-70b-99/offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "NeuralMagic",
    "Platform": "GO_2xRTX4090-reference-cpu-pytorch-v2.2.1-default_config",
    "Result": 424.895,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GATE Overflow Intel Sapphire Rapids RTX 4090 (2x RTX 4090, vLLM, FP8)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "vLLM 0.5.2",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.3.1. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.04 (linux-6.2.0-39-generic-glibc2.37)",
    "uid": "cbd279324f46453b",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/open/NeuralMagic/results/GO_2xRTX4090-reference-cpu-pytorch-v2.2.1-default_config/llama2-70b-99/offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 44.0047,
    "Accuracy_div_100": 0.44005,
    "Availability": "available",
    "Division": "open",
    "Location": "open/NeuralMagic/results/GO_2xRTX4090-reference-cpu-pytorch-v2.2.1-default_config/llama2-70b-99.9/offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "NeuralMagic",
    "Platform": "GO_2xRTX4090-reference-cpu-pytorch-v2.2.1-default_config",
    "Result": 424.895,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GATE Overflow Intel Sapphire Rapids RTX 4090 (2x RTX 4090, vLLM, FP8)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "vLLM 0.5.2",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.3.1. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.04 (linux-6.2.0-39-generic-glibc2.37)",
    "uid": "9d0bcdd1a3474779",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/open/NeuralMagic/results/GO_2xRTX4090-reference-cpu-pytorch-v2.2.1-default_config/llama2-70b-99.9/offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 41.6468,
    "Accuracy_div_100": 0.41647,
    "Availability": "available",
    "Division": "open",
    "Location": "open/NeuralMagic/results/GO_2xRTX4090-reference-cpu-pytorch-v2.2.1-default_config/neuralmagic_Llama-2-7b-chat-hf-FP8/offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "neuralmagic_Llama-2-7b-chat-hf-FP8",
    "Organization": "NeuralMagic",
    "Platform": "GO_2xRTX4090-reference-cpu-pytorch-v2.2.1-default_config",
    "Result": 1871.84,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GATE Overflow Intel Sapphire Rapids RTX 4090 (2x RTX 4090, vLLM, FP8)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "vLLM 0.5.2",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.3.1. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.04 (linux-6.2.0-39-generic-glibc2.37)",
    "uid": "a16951d3cc9d4443",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/open/NeuralMagic/results/GO_2xRTX4090-reference-cpu-pytorch-v2.2.1-default_config/neuralmagic_Llama-2-7b-chat-hf-FP8/offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 41.7123,
    "Accuracy_div_100": 0.41712,
    "Availability": "available",
    "Division": "open",
    "Location": "open/NeuralMagic/results/pcspecialist_amd_am5-reference-gpu-pytorch-v2.2.1-default_config/neuralmagic_Llama-2-7b-chat-hf-FP8/offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "neuralmagic_Llama-2-7b-chat-hf-FP8",
    "Organization": "NeuralMagic",
    "Platform": "pcspecialist_amd_am5-reference-gpu-pytorch-v2.2.1-default_config",
    "Result": 1337.46,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "PCSPECIALIST AMD AM5 (1x RTX 4090)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "deepsparse v1.5.2",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.3.1. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.5.0-41-generic-glibc2.35)",
    "uid": "3820f70b0f9148a5",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/open/NeuralMagic/results/pcspecialist_amd_am5-reference-gpu-pytorch-v2.2.1-default_config/neuralmagic_Llama-2-7b-chat-hf-FP8/offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 88.42042174998099,
    "Accuracy_div_100": 0.8842,
    "Availability": "available",
    "Division": "open",
    "Location": "open/NeuralMagic/results/phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config/bert-base-pruned90-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-base-pruned90-none-bert-99",
    "Organization": "NeuralMagic",
    "Platform": "phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 98.963,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "PCSPECIALIST AMD AM5",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "deepsparse v1.5.2",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.3.1. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.5.0-41-generic-glibc2.35)",
    "uid": "915f1bb6d1754838",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/open/NeuralMagic/results/phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config/bert-base-pruned90-none-bert-99/offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 89.65191480026783,
    "Accuracy_div_100": 0.89652,
    "Availability": "available",
    "Division": "open",
    "Location": "open/NeuralMagic/results/phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config/bert-large-base-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-large-base-none-bert-99",
    "Organization": "NeuralMagic",
    "Platform": "phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 11.974,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "PCSPECIALIST AMD AM5",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "deepsparse v1.5.2",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.3.1. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.5.0-41-generic-glibc2.35)",
    "uid": "e0ff5b962f4e49cf",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/open/NeuralMagic/results/phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config/bert-large-base-none-bert-99/offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.26839357448662,
    "Accuracy_div_100": 0.90268,
    "Availability": "available",
    "Division": "open",
    "Location": "open/NeuralMagic/results/phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config/bert-large-pruned80_quant-none-vnni-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-large-pruned80_quant-none-vnni-bert-99",
    "Organization": "NeuralMagic",
    "Platform": "phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 91.7981,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "PCSPECIALIST AMD AM5",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "deepsparse v1.5.2",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.3.1. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.5.0-41-generic-glibc2.35)",
    "uid": "68adeb78728142b3",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/open/NeuralMagic/results/phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config/bert-large-pruned80_quant-none-vnni-bert-99/offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.4308347276475,
    "Accuracy_div_100": 0.90431,
    "Availability": "available",
    "Division": "open",
    "Location": "open/NeuralMagic/results/phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config/mobilebert-14layer_pruned50-none-vnni-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-14layer_pruned50-none-vnni-bert-99",
    "Organization": "NeuralMagic",
    "Platform": "phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 214.937,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "PCSPECIALIST AMD AM5",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "deepsparse v1.5.2",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.3.1. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.5.0-41-generic-glibc2.35)",
    "uid": "b125d7e0404f4395",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/open/NeuralMagic/results/phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config/mobilebert-14layer_pruned50-none-vnni-bert-99/offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.40462194474198,
    "Accuracy_div_100": 0.90405,
    "Availability": "available",
    "Division": "open",
    "Location": "open/NeuralMagic/results/phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config/mobilebert-14layer_pruned50_quant-none-vnni-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-14layer_pruned50_quant-none-vnni-bert-99",
    "Organization": "NeuralMagic",
    "Platform": "phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 360.571,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "PCSPECIALIST AMD AM5",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "deepsparse v1.5.2",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.3.1. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.5.0-41-generic-glibc2.35)",
    "uid": "4894d64917a14117",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/open/NeuralMagic/results/phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config/mobilebert-14layer_pruned50_quant-none-vnni-bert-99/offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.7887526723603,
    "Accuracy_div_100": 0.90789,
    "Availability": "available",
    "Division": "open",
    "Location": "open/NeuralMagic/results/phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config/mobilebert-base_quant-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-base_quant-none-bert-99",
    "Organization": "NeuralMagic",
    "Platform": "phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 213.347,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "PCSPECIALIST AMD AM5",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "deepsparse v1.5.2",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.3.1. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.5.0-41-generic-glibc2.35)",
    "uid": "99e6ec09e1da45b5",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/open/NeuralMagic/results/phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config/mobilebert-base_quant-none-bert-99/offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.89066465550044,
    "Accuracy_div_100": 0.90891,
    "Availability": "available",
    "Division": "open",
    "Location": "open/NeuralMagic/results/phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config/mobilebert-none-base-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-none-base-none-bert-99",
    "Organization": "NeuralMagic",
    "Platform": "phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 114.492,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "PCSPECIALIST AMD AM5",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "deepsparse v1.5.2",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.3.1. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.5.0-41-generic-glibc2.35)",
    "uid": "f6b3da1d2c9545df",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/open/NeuralMagic/results/phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config/mobilebert-none-base-none-bert-99/offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 88.31078542237867,
    "Accuracy_div_100": 0.88311,
    "Availability": "available",
    "Division": "open",
    "Location": "open/NeuralMagic/results/phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config/obert-base-pruned90-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-base-pruned90-none-bert-99",
    "Organization": "NeuralMagic",
    "Platform": "phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 97.3622,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "PCSPECIALIST AMD AM5",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "deepsparse v1.5.2",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.3.1. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.5.0-41-generic-glibc2.35)",
    "uid": "e26c6d224e7746ff",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/open/NeuralMagic/results/phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config/obert-base-pruned90-none-bert-99/offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 89.65191480026783,
    "Accuracy_div_100": 0.89652,
    "Availability": "available",
    "Division": "open",
    "Location": "open/NeuralMagic/results/phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config/obert-large-base-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-large-base-none-bert-99",
    "Organization": "NeuralMagic",
    "Platform": "phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 11.9721,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "PCSPECIALIST AMD AM5",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "deepsparse v1.5.2",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.3.1. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.5.0-41-generic-glibc2.35)",
    "uid": "6aac6c5b72b047f5",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/open/NeuralMagic/results/phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config/obert-large-base-none-bert-99/offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.17832662822171,
    "Accuracy_div_100": 0.90178,
    "Availability": "available",
    "Division": "open",
    "Location": "open/NeuralMagic/results/phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned95-none-vnni-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-large-pruned95-none-vnni-bert-99",
    "Organization": "NeuralMagic",
    "Platform": "phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 38.4994,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "PCSPECIALIST AMD AM5",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "deepsparse v1.5.2",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.3.1. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.5.0-41-generic-glibc2.35)",
    "uid": "af0721271a5f46ef",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/open/NeuralMagic/results/phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned95-none-vnni-bert-99/offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.0299132434367,
    "Accuracy_div_100": 0.9003,
    "Availability": "available",
    "Division": "open",
    "Location": "open/NeuralMagic/results/phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned95_quant-none-vnni-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-large-pruned95_quant-none-vnni-bert-99",
    "Organization": "NeuralMagic",
    "Platform": "phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 104.14,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "PCSPECIALIST AMD AM5",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "deepsparse v1.5.2",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.3.1. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.5.0-41-generic-glibc2.35)",
    "uid": "a43f461f26214c9d",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/open/NeuralMagic/results/phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned95_quant-none-vnni-bert-99/offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.1356467730578,
    "Accuracy_div_100": 0.90136,
    "Availability": "available",
    "Division": "open",
    "Location": "open/NeuralMagic/results/phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned97-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-large-pruned97-none-bert-99",
    "Organization": "NeuralMagic",
    "Platform": "phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 40.0699,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "PCSPECIALIST AMD AM5",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "deepsparse v1.5.2",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.3.1. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.5.0-41-generic-glibc2.35)",
    "uid": "cd1254a145474dea",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/open/NeuralMagic/results/phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned97-none-bert-99/offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.17969189468576,
    "Accuracy_div_100": 0.9018,
    "Availability": "available",
    "Division": "open",
    "Location": "open/NeuralMagic/results/phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned97-quant-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-large-pruned97-quant-none-bert-99",
    "Organization": "NeuralMagic",
    "Platform": "phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 105.626,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "PCSPECIALIST AMD AM5",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "deepsparse v1.5.2",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.3.1. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.5.0-41-generic-glibc2.35)",
    "uid": "e21a95bf3c0a4cb1",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/open/NeuralMagic/results/phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned97-quant-none-bert-99/offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 44.1411,
    "Accuracy_div_100": 0.44141,
    "Availability": "available",
    "Division": "open",
    "Location": "open/NeuralMagic/results/vLLM_8xL40S-reference-cpu-pytorch-v2.3.1-default_config/llama2-70b-99/offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "NeuralMagic",
    "Platform": "vLLM_8xL40S-reference-cpu-pytorch-v2.3.1-default_config",
    "Result": 923.333,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Crusoe Cloud L40S (8x L40S PCIe, vLLM)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "vLLM 0.5.2",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "AMD EPYC 9254 24-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.3.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.15.0-94-generic-glibc2.35)",
    "uid": "1b30dda6bdb54b65",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/open/NeuralMagic/results/vLLM_8xL40S-reference-cpu-pytorch-v2.3.1-default_config/llama2-70b-99/offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 44.1411,
    "Accuracy_div_100": 0.44141,
    "Availability": "available",
    "Division": "open",
    "Location": "open/NeuralMagic/results/vLLM_8xL40S-reference-cpu-pytorch-v2.3.1-default_config/llama2-70b-99.9/offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "NeuralMagic",
    "Platform": "vLLM_8xL40S-reference-cpu-pytorch-v2.3.1-default_config",
    "Result": 923.333,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Crusoe Cloud L40S (8x L40S PCIe, vLLM)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "vLLM 0.5.2",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "AMD EPYC 9254 24-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.3.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.15.0-94-generic-glibc2.35)",
    "uid": "0360f9cea9904c59",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/open/NeuralMagic/results/vLLM_8xL40S-reference-cpu-pytorch-v2.3.1-default_config/llama2-70b-99.9/offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 41.6143,
    "Accuracy_div_100": 0.41614,
    "Availability": "available",
    "Division": "open",
    "Location": "open/NeuralMagic/results/vLLM_8xL40S-reference-cpu-pytorch-v2.3.1-default_config/neuralmagic_Llama-2-7b-chat-hf-FP8/offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "neuralmagic_Llama-2-7b-chat-hf-FP8",
    "Organization": "NeuralMagic",
    "Platform": "vLLM_8xL40S-reference-cpu-pytorch-v2.3.1-default_config",
    "Result": 1989.1,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Crusoe Cloud L40S (8x L40S PCIe, vLLM)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "vLLM 0.5.2",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "AMD EPYC 9254 24-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.3.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.15.0-94-generic-glibc2.35)",
    "uid": "0f9c3a879e4049a6",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/open/NeuralMagic/results/vLLM_8xL40S-reference-cpu-pytorch-v2.3.1-default_config/neuralmagic_Llama-2-7b-chat-hf-FP8/offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 42.9783,
    "Accuracy_div_100": 0.42978,
    "Availability": "available",
    "Division": "open",
    "Location": "open/NVIDIA/results/H200-SXM-141GBx1_TRT_DepthPruned/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx1_TRT_DepthPruned",
    "Result": 11189.1,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA H200 (1x H200-SXM-141GB)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "e429a0f146894011",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/open/NVIDIA/results/H200-SXM-141GBx1_TRT_DepthPruned/llama2-70b-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 44.46,
    "Accuracy_div_100": 0.4446,
    "Availability": "available",
    "Division": "open",
    "Location": "open/NVIDIA/results/H200-SXM-141GBx1_TRT_Sparse/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx1_TRT_Sparse",
    "Result": 4575.06,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA H200 (1x H200-SXM-141GB)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "f5004ba4853b4419",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/open/NVIDIA/results/H200-SXM-141GBx1_TRT_Sparse/llama2-70b-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 43.2263,
    "Accuracy_div_100": 0.43226,
    "Availability": "available",
    "Division": "open",
    "Location": "open/NVIDIA/results/Orin_TRT_DepthPruned/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "NVIDIA",
    "Platform": "Orin_TRT_DepthPruned",
    "Result": 184.893,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA Jetson AGX Orin Developer Kit 64G (TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA Jetson AGX Orin 64G",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Jetpack 6.0, TensorRT 10.1, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 12,
    "host_processor_model_name": "12-core ARM Cortex-A78AE CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "GPU and both DLAs are used in resnet50 and Retinanet, in Offline scenario",
    "number_of_nodes": 1,
    "operating_system": "Jetson r36.3.1 L4T",
    "uid": "58c4fba40d31415e",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/open/NVIDIA/results/Orin_TRT_DepthPruned/llama2-70b-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.87487229720105,
    "Accuracy_div_100": 0.90875,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/arjun_spr-reference-cpu-pytorch-v2.1.0-default_config/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "CTuning",
    "Platform": "arjun_spr-reference-cpu-pytorch-v2.1.0-default_config",
    "Result": 145.36,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Network SUT GATE Overflow Intel Sapphire Rapids (1x RTX 4090)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "MLCommons python reference implementation with CM API, Onnxruntime v1.16.3",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.6.2. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.04 (linux-6.2.0-39-generic-glibc2.37)",
    "uid": "5f8fd7c7ab404d96",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/arjun_spr-reference-cpu-pytorch-v2.1.0-default_config/bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 42.0595,
    "Accuracy_div_100": 0.42059,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-gpu-pytorch-v2.1.1-default_config/llama2-70b-99/offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "CTuning",
    "Platform": "GATE_Overflow_Intel_Sapphire_Rapids-reference-gpu-pytorch-v2.1.1-default_config",
    "Result": 199.333,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GATEOverflow Intel Sapphire Rapids (2x RTX 4090)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "MLCommons python reference implementation with CM API, Pytorch v2.1.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.6.2. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.04 (linux-6.2.0-39-generic-glibc2.37)",
    "uid": "6cf57fc26b5a4dfd",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-gpu-pytorch-v2.1.1-default_config/llama2-70b-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.87487229720105,
    "Accuracy_div_100": 0.90875,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/PCSPECIALIST_AMD_AM5_PC_with_Nvidia_RTX_4090-reference-cpu-pytorch-v2.2.0-network_loadgen/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "CTuning",
    "Platform": "PCSPECIALIST_AMD_AM5_PC_with_Nvidia_RTX_4090-reference-cpu-pytorch-v2.2.0-network_loadgen",
    "Result": 3.0418,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Network SUT PCSPECIALIST AMD AM5 PC",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "MLCommons python reference implementation with CM API, Pytorch v2.2.0",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.5.0-14-generic-glibc2.35)",
    "uid": "e1185531208646d4",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/PCSPECIALIST_AMD_AM5_PC_with_Nvidia_RTX_4090-reference-cpu-pytorch-v2.2.0-network_loadgen/bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.87487229720105,
    "Accuracy_div_100": 0.90875,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/PCSPECIALIST_AMD_AM5_PC_with_Nvidia_RTX_4090-reference-gpu-onnxruntime-v1.16.3-network_loadgen/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "CTuning",
    "Platform": "PCSPECIALIST_AMD_AM5_PC_with_Nvidia_RTX_4090-reference-gpu-onnxruntime-v1.16.3-network_loadgen",
    "Result": 184.308,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Network SUT PCSPECIALIST AMD AM5 PC (1x RTX 4090)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "MLCommons python reference implementation with CM API, Onnxruntime v1.16.3",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.5.0-14-generic-glibc2.35)",
    "uid": "f353a41ed9f747bd",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/PCSPECIALIST_AMD_AM5_PC_with_Nvidia_RTX_4090-reference-gpu-onnxruntime-v1.16.3-network_loadgen/bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.97056894987658,
    "Accuracy_div_100": 0.90971,
    "Availability": "available",
    "Division": "open",
    "Location": "open/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "HPE",
    "Platform": "HPE_Cray_XD670_H100_SXM_80GBx8_TRT_TRT",
    "Result": 62986.7,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "HPE Cray XD670 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.3",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.3",
    "uid": "8fc440b59c3a40b4",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT_TRT/bert-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 43.0675,
    "Accuracy_div_100": 0.43068,
    "Availability": "available",
    "Division": "open",
    "Location": "open/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "HPE",
    "Platform": "HPE_Cray_XD670_H100_SXM_80GBx8_TRT_TRT",
    "Result": 223.211,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "HPE Cray XD670 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.3",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.3",
    "uid": "74bc665efd064f8a",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT_TRT/gptj-99/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 43.0675,
    "Accuracy_div_100": 0.43068,
    "Availability": "available",
    "Division": "open",
    "Location": "open/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "HPE",
    "Platform": "HPE_Cray_XD670_H100_SXM_80GBx8_TRT_TRT",
    "Result": 223.951,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "HPE Cray XD670 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.3",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.3",
    "uid": "7b74858299184b28",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT_TRT/gptj-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.35676151551918,
    "Accuracy_div_100": 0.90357,
    "Availability": "available",
    "Division": "open",
    "Location": "open/HPE/results/HPE_ProLiant_DL380a_H100_PCIe_80GBx4_TRT_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "HPE",
    "Platform": "HPE_ProLiant_DL380a_H100_PCIe_80GBx4_TRT_TRT",
    "Result": 22620.8,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "HPE ProLiant DL380a Gen11 (4x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "75f93428a67540af",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/HPE/results/HPE_ProLiant_DL380a_H100_PCIe_80GBx4_TRT_TRT/bert-99/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.97056894987658,
    "Accuracy_div_100": 0.90971,
    "Availability": "available",
    "Division": "open",
    "Location": "open/HPE/results/HPE_ProLiant_DL380a_H100_PCIe_80GBx4_TRT_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "HPE",
    "Platform": "HPE_ProLiant_DL380a_H100_PCIe_80GBx4_TRT_TRT",
    "Result": 19512.3,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "HPE ProLiant DL380a Gen11 (4x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "218f163f81514f9b",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/HPE/results/HPE_ProLiant_DL380a_H100_PCIe_80GBx4_TRT_TRT/bert-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.89637138715483,
    "Accuracy_div_100": 0.90896,
    "Availability": "available",
    "Division": "open",
    "Location": "open/HPE/results/HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "HPE",
    "Platform": "HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT",
    "Result": 6874.3,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "HPE ProLiant DL380a Gen11 (4x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 60,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8580",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "1b8d8b40c2e5441b",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/HPE/results/HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT/bert-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 43.0936,
    "Accuracy_div_100": 0.43094,
    "Availability": "available",
    "Division": "open",
    "Location": "open/HPE/results/HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "HPE",
    "Platform": "HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT",
    "Result": 49.8357,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "HPE ProLiant DL380a Gen11 (4x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 60,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8580",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "e8e6dd4238484ff6",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/HPE/results/HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT/gptj-99/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 43.0936,
    "Accuracy_div_100": 0.43094,
    "Availability": "available",
    "Division": "open",
    "Location": "open/HPE/results/HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "HPE",
    "Platform": "HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT",
    "Result": 49.8357,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "HPE ProLiant DL380a Gen11 (4x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 60,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8580",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "770c28c3665245b4",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/HPE/results/HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT/gptj-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 38.7559,
    "Accuracy_div_100": 0.38756,
    "Availability": "available",
    "Division": "open",
    "Location": "open/JuniperNetworks/results/A100-2N-80GB/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "JuniperNetworks",
    "Platform": "A100-2N-80GB",
    "Result": 3659.41,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "A100-2N-80GB",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "A100-SXM-80GB",
    "accelerators_per_node": 16,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.2.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 128,
    "host_processor_model_name": "AMD EPYC 7763 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 2,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "4ee464d10bf4441b",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/JuniperNetworks/results/A100-2N-80GB/llama2-70b-99/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 38.5151,
    "Accuracy_div_100": 0.38515,
    "Availability": "available",
    "Division": "open",
    "Location": "open/JuniperNetworks/results/H100-2N-80GB/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "JuniperNetworks",
    "Platform": "H100-2N-80GB",
    "Result": 6235.72,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "H100-2N-80GB",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "H100-SXM-80GB",
    "accelerators_per_node": 16,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.2.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 112,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480CL",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 2,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "8c8ec7c591a64f33",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/JuniperNetworks/results/H100-2N-80GB/llama2-70b-99/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 42.3672,
    "Accuracy_div_100": 0.42367,
    "Availability": "available",
    "Division": "open",
    "Location": "open/NVIDIA/results/DGX-H100_H100-SXM-80GBx1_TRT_PRUNED/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "NVIDIA",
    "Platform": "DGX-H100_H100-SXM-80GBx1_TRT_PRUNED",
    "Result": 43.3445,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX H100 (1x H100-SXM-80GB)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "e433b4c12d074c68",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/NVIDIA/results/DGX-H100_H100-SXM-80GBx1_TRT_PRUNED/gptj-99/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 44.4855,
    "Accuracy_div_100": 0.44486,
    "Availability": "available",
    "Division": "open",
    "Location": "open/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT_SPARSE/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "NVIDIA",
    "Platform": "DGX-H100_H100-SXM-80GBx8_TRT_SPARSE",
    "Result": 28931.9,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX H100 (8x H100-SXM-80GB)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "9c23687fc88b4197",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT_SPARSE/llama2-70b-99/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 44.4855,
    "Accuracy_div_100": 0.44486,
    "Availability": "available",
    "Division": "open",
    "Location": "open/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT_SPARSE/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "NVIDIA",
    "Platform": "DGX-H100_H100-SXM-80GBx8_TRT_SPARSE",
    "Result": 28931.9,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX H100 (8x H100-SXM-80GB)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "5c9cdd8592344685",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT_SPARSE/llama2-70b-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 43.0965,
    "Accuracy_div_100": 0.43096,
    "Availability": "available",
    "Division": "open",
    "Location": "open/RedHat/results/DGX-RedHat-OpenShift/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "RedHat",
    "Platform": "DGX-RedHat-OpenShift",
    "Result": 138.338,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX H100 (8xH100-SXM-80GB, Red Hat OpenShift AI, vLLM(fp16))",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 112,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480CL",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "NVIDIA H100-SXM-80GB. Red Hat OpenShift Container Platform 4.14 + OpenShift AI",
    "number_of_nodes": 1,
    "operating_system": "Red Hat Enterprise Linux CoreOS release 4.14",
    "uid": "a5a79ace7862411f",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/RedHat/results/DGX-RedHat-OpenShift/gptj-99/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 43.0965,
    "Accuracy_div_100": 0.43096,
    "Availability": "available",
    "Division": "open",
    "Location": "open/RedHat/results/DGX-RedHat-OpenShift/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "RedHat",
    "Platform": "DGX-RedHat-OpenShift",
    "Result": 138.338,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX H100 (8xH100-SXM-80GB, Red Hat OpenShift AI, vLLM(fp16))",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 112,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480CL",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "NVIDIA H100-SXM-80GB. Red Hat OpenShift Container Platform 4.14 + OpenShift AI",
    "number_of_nodes": 1,
    "operating_system": "Red Hat Enterprise Linux CoreOS release 4.14",
    "uid": "a4a0bc241a264ee3",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/RedHat/results/DGX-RedHat-OpenShift/gptj-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 44.4162,
    "Accuracy_div_100": 0.44416,
    "Availability": "available",
    "Division": "open",
    "Location": "open/RedHat-Supermicro/results/AS-4125GS-TNRT-RedHat-OpenShift-AI/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "RedHat-Supermicro",
    "Platform": "AS-4125GS-TNRT-RedHat-OpenShift-AI",
    "Result": 3038.78,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AS-4125GS-TNRT(8xH100-PCIe-80GB, Red Hat OpenShift AI, vLLM(fp16))",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 9554 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "NVIDIA H100-PCIe-80GB. Red Hat OpenShift Container Platform 4.14 + OpenShift AI",
    "number_of_nodes": 1,
    "operating_system": "Red Hat Enterprise Linux CoreOS release 4.14",
    "uid": "51f2b6f71f1244cd",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/RedHat-Supermicro/results/AS-4125GS-TNRT-RedHat-OpenShift-AI/llama2-70b-99/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 44.4162,
    "Accuracy_div_100": 0.44416,
    "Availability": "available",
    "Division": "open",
    "Location": "open/RedHat-Supermicro/results/AS-4125GS-TNRT-RedHat-OpenShift-AI/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "RedHat-Supermicro",
    "Platform": "AS-4125GS-TNRT-RedHat-OpenShift-AI",
    "Result": 3038.78,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AS-4125GS-TNRT(8xH100-PCIe-80GB, Red Hat OpenShift AI, vLLM(fp16))",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 9554 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "NVIDIA H100-PCIe-80GB. Red Hat OpenShift Container Platform 4.14 + OpenShift AI",
    "number_of_nodes": 1,
    "operating_system": "Red Hat Enterprise Linux CoreOS release 4.14",
    "uid": "96c5410af1f04082",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/RedHat-Supermicro/results/AS-4125GS-TNRT-RedHat-OpenShift-AI/llama2-70b-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 42.9603,
    "Accuracy_div_100": 0.4296,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Moffett/results/Moffett_S30x8_Inspur/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Moffett",
    "Platform": "Moffett_S30x8_Inspur",
    "Result": 170.586,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Inspur NF5468M6 (8x SparseOne S30, PCIe/FHFL, Moffett-SDK)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "MOFFETT S30-PCIe/FHFL-60GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "Moffett SDK",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 80,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380 CPU @ 2.30GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.5 LTS",
    "uid": "13e0a3ab44e24bd4",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/open/Moffett/results/Moffett_S30x8_Inspur/gptj-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 42.9604,
    "Accuracy_div_100": 0.4296,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Moffett/results/Moffett_S30_H3C/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Moffett",
    "Platform": "Moffett_S30_H3C",
    "Result": 23.2809,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "H3C R5300 G5 (1x SparseOne S30, PCIe/FHFL, Moffett-SDK)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "MOFFETT S30-PCIe/FHFL-60GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Moffett SDK",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 112,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6348",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.5 LTS",
    "uid": "d952c9c5762641b5",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/open/Moffett/results/Moffett_S30_H3C/gptj-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 42.9604,
    "Accuracy_div_100": 0.4296,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Moffett/results/Moffett_S30x4_H3C/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Moffett",
    "Platform": "Moffett_S30x4_H3C",
    "Result": 91.574,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "H3C R5300 G5 (4x SparseOne S30, PCIe/FHFL, Moffett-SDK)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "MOFFETT S30-PCIe/FHFL-60GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "Moffett SDK",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 112,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6348",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.5 LTS",
    "uid": "a29aa195339a4c8b",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/open/Moffett/results/Moffett_S30x4_H3C/gptj-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 42.9177,
    "Accuracy_div_100": 0.42918,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Supermicro/results/1-node-4S-SPR-PyTorch-INT8/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Supermicro",
    "Platform": "1-node-4S-SPR-PyTorch-INT8",
    "Result": 2.81426,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "1-node-4S-SPR-PyTorch-INT8",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 4,
    "inferred": 0,
    "notes": "N/A",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream 8",
    "uid": "7ed3bb418af044cf",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/open/Supermicro/results/1-node-4S-SPR-PyTorch-INT8/gptj-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.18328497411034,
    "Accuracy_div_100": 0.90183,
    "Availability": "rdi",
    "Division": "open",
    "Location": "open/NVIDIA/results/L4x1_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "L4x1_TRT",
    "Result": 4609.04,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA L4 (1x L4, TensorRT)",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7313P 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "052c17c80c2d4dc2",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/open/NVIDIA/results/L4x1_TRT/bert-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.79625788222037,
    "Accuracy_div_100": 0.90796,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Intel/results/1-node-2S-SPR-Neural_Engine-INT8/bert-99.9_MiniLM/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9_MiniLM",
    "Organization": "Intel",
    "Platform": "1-node-2S-SPR-Neural_Engine-INT8",
    "Result": 6543.62,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "1-node-2S-SPR-PyTorch-INT8",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54Q-2U. N/A",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream 8",
    "uid": "b6d1922156774da4",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/open/Intel/results/1-node-2S-SPR-Neural_Engine-INT8/bert-99.9_MiniLM/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 89.90716435557265,
    "Accuracy_div_100": 0.89907,
    "Availability": "rdi",
    "Division": "open",
    "Location": "open/Deci/results/aws-c6i.16xlarge-openvino/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Deci",
    "Platform": "aws-c6i.16xlarge-openvino",
    "Result": 120.51,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Amazon EC2 (c6i.16xlarge)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "OpenVINO",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8375C CPU @ 2.90GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.5 LTS",
    "uid": "8cb2aa13102c4400",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/open/Deci/results/aws-c6i.16xlarge-openvino/bert-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 91.03472601136613,
    "Accuracy_div_100": 0.91035,
    "Availability": "rdi",
    "Division": "open",
    "Location": "open/Deci/results/aws-c6i.16xlarge-openvino/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Deci",
    "Platform": "aws-c6i.16xlarge-openvino",
    "Result": 91.4175,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Amazon EC2 (c6i.16xlarge)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "OpenVINO",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8375C CPU @ 2.90GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.5 LTS",
    "uid": "a5d59afdfe91422e",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/open/Deci/results/aws-c6i.16xlarge-openvino/bert-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 89.90716435557265,
    "Accuracy_div_100": 0.89907,
    "Availability": "rdi",
    "Division": "open",
    "Location": "open/Deci/results/aws-m5dn.8xlarge-openvino/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Deci",
    "Platform": "aws-m5dn.8xlarge-openvino",
    "Result": 66.6036,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Amazon EC2 (m5dn.8xlarge)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "OpenVINO",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.5 LTS",
    "uid": "e05696175f9f4282",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/open/Deci/results/aws-m5dn.8xlarge-openvino/bert-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 91.03472601136613,
    "Accuracy_div_100": 0.91035,
    "Availability": "rdi",
    "Division": "open",
    "Location": "open/Deci/results/aws-m5dn.8xlarge-openvino/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Deci",
    "Platform": "aws-m5dn.8xlarge-openvino",
    "Result": 48.7853,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Amazon EC2 (m5dn.8xlarge)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "OpenVINO",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.5 LTS",
    "uid": "a723c1b493484777",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/open/Deci/results/aws-m5dn.8xlarge-openvino/bert-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.38529083707651,
    "Accuracy_div_100": 0.90385,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Azure/results/ND96asr_v4_TRT_Triton/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Azure",
    "Platform": "ND96asr_v4_TRT_Triton",
    "Result": 27625,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ND96asr_v4 (8x A100-SXM-40GB, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-40GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 7V12 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.6",
    "uid": "e2b283d2b7974339",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/open/Azure/results/ND96asr_v4_TRT_Triton/bert-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.86087496792462,
    "Accuracy_div_100": 0.90861,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Azure/results/ND96asr_v4_TRT_Triton/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Azure",
    "Platform": "ND96asr_v4_TRT_Triton",
    "Result": 13928.3,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ND96asr_v4 (8x A100-SXM-40GB, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-40GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 7V12 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.6",
    "uid": "2335819c7fae4936",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/open/Azure/results/ND96asr_v4_TRT_Triton/bert-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.38529083707651,
    "Accuracy_div_100": 0.90385,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Azure/results/ND96asr_v4_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Azure",
    "Platform": "ND96asr_v4_TRT",
    "Result": 27688.7,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ND96asr_v4 (8x A100-SXM-40GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-40GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 7V12 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.6",
    "uid": "e5e4af10ec634291",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/open/Azure/results/ND96asr_v4_TRT/bert-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.86087496792462,
    "Accuracy_div_100": 0.90861,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Azure/results/ND96asr_v4_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Azure",
    "Platform": "ND96asr_v4_TRT",
    "Result": 13802.1,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ND96asr_v4 (8x A100-SXM-40GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-40GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 7V12 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.6",
    "uid": "7c302968a56146b5",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/open/Azure/results/ND96asr_v4_TRT/bert-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.8575190748761,
    "Accuracy_div_100": 0.90858,
    "Availability": "preview",
    "Division": "open",
    "Location": "open/Moffett/results/Moffett_S10_DELL/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Moffett",
    "Platform": "Moffett_S10_DELL",
    "Result": 2535.96,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "DELL-R750 (1x SparseOne S10, PCIe/FHFL, Moffett-SDK)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "MOFFETT S10-PCIe/FHFL-40GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Moffett SDK",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6326 CPU @ 2.90GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.5 LTS",
    "uid": "4f170c9cbfd54b40",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/open/Moffett/results/Moffett_S10_DELL/bert-99.9/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.8575190748761,
    "Accuracy_div_100": 0.90858,
    "Availability": "preview",
    "Division": "open",
    "Location": "open/Moffett/results/Moffett_S30_DELL/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Moffett",
    "Platform": "Moffett_S30_DELL",
    "Result": 3836.89,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "DELL-R750 (1x SparseOne S30, PCIe/FHFL, Moffett-SDK)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "MOFFETT S30-PCIe/FHFL-60GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Moffett SDK",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6326 CPU @ 2.90GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.5 LTS",
    "uid": "23af32a3782e442e",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/open/Moffett/results/Moffett_S30_DELL/bert-99.9/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.8575190748761,
    "Accuracy_div_100": 0.90858,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Moffett/results/Moffett_S4_Inspur/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Moffett",
    "Platform": "Moffett_S4_Inspur",
    "Result": 1219.41,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Inspur-NF5280M6 (1x SparseOne S4, PCIe/HHHL, Moffett-SDK)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "MOFFETT S4-PCIe/HHHL-20GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Moffett SDK",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6326 CPU @ 2.90GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.5 LTS",
    "uid": "49ac56e28d3b494f",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/open/Moffett/results/Moffett_S4_Inspur/bert-99.9/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 91.09565477598386,
    "Accuracy_div_100": 0.91096,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Dell/results/Dell-PowerEdge-R7525-2xAMD-EPYC-7773X/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Dell",
    "Platform": "Dell-PowerEdge-R7525-2xAMD-EPYC-7773X",
    "Result": 116.741,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R7525 2x AMD EPYC 7773X",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "OnnxRuntime",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 128,
    "host_processor_model_name": "AMD EPYC 7773X 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Deci AutoNAC",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu SMP",
    "uid": "61dde63fabcc4897",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/open/Dell/results/Dell-PowerEdge-R7525-2xAMD-EPYC-7773X/bert-99.9/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.8575190748761,
    "Accuracy_div_100": 0.90858,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Moffett/results/Moffett_S10_Inspur/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Moffett",
    "Platform": "Moffett_S10_Inspur",
    "Result": 2548.22,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Inspur NF5468M6-P (1x SparseOne S10, PCIe/FHFL, Moffett-SDK)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "MOFFETT S10-PCIe/FHFL-40GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Moffett SDK",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platium 8380",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.5 LTS",
    "uid": "589909f02e7d496b",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Moffett/results/Moffett_S10_Inspur/bert-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.8575190748761,
    "Accuracy_div_100": 0.90858,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Moffett/results/Moffett_S30_Inspur/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Moffett",
    "Platform": "Moffett_S30_Inspur",
    "Result": 3840.74,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Inspur NF5468M6-P (1x SparseOne S30, PCIe/FHFL, Moffett-SDK)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "MOFFETT S30-PCIe/FHFL-60GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Moffett SDK",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platium 8380",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.5 LTS",
    "uid": "53ef56a3432740ac",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Moffett/results/Moffett_S30_Inspur/bert-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.8575190748761,
    "Accuracy_div_100": 0.90858,
    "Availability": "preview",
    "Division": "open",
    "Location": "open/Moffett/results/Moffett_S40_Inspur/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Moffett",
    "Platform": "Moffett_S40_Inspur",
    "Result": 5068.94,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Inspur NF5468M6-P (1x SparseOne S40, PCIe/FHFL, Moffett-SDK)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "MOFFETT S40-PCIe/FHFL-80GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Moffett SDK",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platium 8380",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.5 LTS",
    "uid": "16436b3cc195493b",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Moffett/results/Moffett_S40_Inspur/bert-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.38982811354983,
    "Accuracy_div_100": 0.9039,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Supermicro/results/A100X4_751GE_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Supermicro",
    "Platform": "A100X4_751GE_TRT",
    "Result": 12392.9,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "SYS-751GE-TNRT, TensorRT",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "INTEL XEON GOLD 6444Y 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.3",
    "uid": "4779f7f7e9fd4724",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Supermicro/results/A100X4_751GE_TRT/bert-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.88273936857954,
    "Accuracy_div_100": 0.90883,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Supermicro/results/A100X4_751GE_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Supermicro",
    "Platform": "A100X4_751GE_TRT",
    "Result": 6476.1,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "SYS-751GE-TNRT, TensorRT",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "INTEL XEON GOLD 6444Y 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.3",
    "uid": "8a556437b3d3426b",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Supermicro/results/A100X4_751GE_TRT/bert-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.38982811354983,
    "Accuracy_div_100": 0.9039,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Supermicro/results/A100X4_751GE_TRT_Triton/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Supermicro",
    "Platform": "A100X4_751GE_TRT_Triton",
    "Result": 12359.8,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "SYS-751GE-TNRT, TensorRT, Triton",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "INTEL XEON GOLD 6444Y 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.3",
    "uid": "27fa86c591374df8",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Supermicro/results/A100X4_751GE_TRT_Triton/bert-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.88273936857954,
    "Accuracy_div_100": 0.90883,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Supermicro/results/A100X4_751GE_TRT_Triton/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Supermicro",
    "Platform": "A100X4_751GE_TRT_Triton",
    "Result": 6485.91,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "SYS-751GE-TNRT, TensorRT, Triton",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "INTEL XEON GOLD 6444Y 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.3",
    "uid": "6ca68b0678554204",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Supermicro/results/A100X4_751GE_TRT_Triton/bert-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.41431155207196,
    "Accuracy_div_100": 0.90414,
    "Availability": "available",
    "Division": "open",
    "Location": "open/NeuralMagic/results/nm192ca_genoa_deepsparse/bert-99_obert-mobilebert/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99_obert-mobilebert",
    "Organization": "NeuralMagic",
    "Platform": "nm192ca_genoa_deepsparse",
    "Result": 5578.73,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NM192ca_genoa (2x AMD EPYC 9654, DeepSparse)",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "DeepSparse 1.4.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "DeepSparse 1.4.0",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.15.0-58-generic-glibc2.35)",
    "uid": "23edd8ae06304a93",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/NeuralMagic/results/nm192ca_genoa_deepsparse/bert-99_obert-mobilebert/offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.79990624075134,
    "Accuracy_div_100": 0.908,
    "Availability": "available",
    "Division": "open",
    "Location": "open/NeuralMagic/results/nm192ca_genoa_deepsparse/bert-99.9_obert-mobilebert/offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9_obert-mobilebert",
    "Organization": "NeuralMagic",
    "Platform": "nm192ca_genoa_deepsparse",
    "Result": 3275.62,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NM192ca_genoa (2x AMD EPYC 9654, DeepSparse)",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "DeepSparse 1.4.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "DeepSparse 1.4.0",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.15.0-58-generic-glibc2.35)",
    "uid": "d8569532eb3f410e",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/NeuralMagic/results/nm192ca_genoa_deepsparse/bert-99.9_obert-mobilebert/offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.0299132434367,
    "Accuracy_div_100": 0.9003,
    "Availability": "available",
    "Division": "open",
    "Location": "open/NeuralMagic/results/nm192ca_genoa_deepsparse/bert-99_obert-large/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99_obert-large",
    "Organization": "NeuralMagic",
    "Platform": "nm192ca_genoa_deepsparse",
    "Result": 1367.14,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NM192ca_genoa (2x AMD EPYC 9654, DeepSparse)",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "DeepSparse 1.4.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "DeepSparse 1.4.0",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.15.0-58-generic-glibc2.35)",
    "uid": "a465524645084dd5",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/NeuralMagic/results/nm192ca_genoa_deepsparse/bert-99_obert-large/offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.87487229720105,
    "Accuracy_div_100": 0.90875,
    "Availability": "available",
    "Division": "open",
    "Location": "open/NeuralMagic/results/nm192ca_genoa_onnxruntime/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NeuralMagic",
    "Platform": "nm192ca_genoa_onnxruntime",
    "Result": 4.59599,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NM192ca_genoa (2x AMD EPYC 9654, ONNXRuntime)",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "onnxruntime v1.14.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "onnxruntime v1.14.0",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.15.0-58-generic-glibc2.35)",
    "uid": "de923e122d014363",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/NeuralMagic/results/nm192ca_genoa_onnxruntime/bert-99/offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 91.43001450212992,
    "Accuracy_div_100": 0.9143,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Deci/results/DGX-A100_A100-SXM-80GBx1_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Deci",
    "Platform": "DGX-A100_A100-SXM-80GBx1_TRT",
    "Result": 13377.2,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX A100 (1x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0.6, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7543",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.3",
    "uid": "5d8df7b79e48423a",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Deci/results/DGX-A100_A100-SXM-80GBx1_TRT/bert-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 91.43001450212992,
    "Accuracy_div_100": 0.9143,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Deci/results/DGX-A100_A100-SXM-80GBx8_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Deci",
    "Platform": "DGX-A100_A100-SXM-80GBx8_TRT",
    "Result": 103053,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX A100 (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0.6, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7543",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.3",
    "uid": "2a226f9267e64099",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Deci/results/DGX-A100_A100-SXM-80GBx8_TRT/bert-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.91720943580663,
    "Accuracy_div_100": 0.90917,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Deci/results/Intel-SPR-112-cores/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Deci",
    "Platform": "Intel-SPR-112-cores",
    "Result": 1189.33,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Intel Sapphire Rapids 112 Cores",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Intel Extension For Pytorch",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+ (Sapphire Rapids) CPU @ 2.00GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Intel IPEX with Deci AutoNAC",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 LTS",
    "uid": "cd6ef3b9193046c2",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Deci/results/Intel-SPR-112-cores/bert-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 91.34622413544257,
    "Accuracy_div_100": 0.91346,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Deci/results/H100_PCIe-80GBx1_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Deci",
    "Platform": "H100_PCIe-80GBx1_TRT",
    "Result": 17584.2,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA H100 (1x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.5.3.1, CUDA 11.8",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6354",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5",
    "uid": "7bdee6e407c545b6",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Deci/results/H100_PCIe-80GBx1_TRT/bert-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 91.28163424674494,
    "Accuracy_div_100": 0.91282,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Deci/results/A30x1_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Deci",
    "Platform": "A30x1_TRT",
    "Result": 5885.46,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA A30 (A30x1, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0.6, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6354",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.3",
    "uid": "f968bb56f0f34256",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Deci/results/A30x1_TRT/bert-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.91678269111374,
    "Accuracy_div_100": 0.90917,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Qualcomm/results/g292_z43_q18-qaic-v1.8.3.7-aic100/bert_pruned_83.2_mp/offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert_pruned_83.2_mp",
    "Organization": "Qualcomm",
    "Platform": "g292_z43_q18-qaic-v1.8.3.7-aic100",
    "Result": 31944.1,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GIGABYTE G292-Z43 (18x QAIC100 Pro)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 18,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.8.3",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7713 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5 LTS (Linux kernel: 5.4.0-135-generic #152-Ubuntu SMP Wed Nov 23 20:19:22 UTC 2022)",
    "uid": "f424bd7429314241",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Qualcomm/results/g292_z43_q18-qaic-v1.8.3.7-aic100/bert_pruned_83.2_mp/offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 86.13436789084363,
    "Accuracy_div_100": 0.86134,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Qualcomm/results/g292_z43_q18-qaic-v1.8.3.7-aic100/distilbert_mp/offline",
    "MlperfModel": "bert-99",
    "Model": "distilbert_mp",
    "Organization": "Qualcomm",
    "Platform": "g292_z43_q18-qaic-v1.8.3.7-aic100",
    "Result": 59177.5,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GIGABYTE G292-Z43 (18x QAIC100 Pro)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 18,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.8.3",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7713 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5 LTS (Linux kernel: 5.4.0-135-generic #152-Ubuntu SMP Wed Nov 23 20:19:22 UTC 2022)",
    "uid": "b173a5335a904283",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Qualcomm/results/g292_z43_q18-qaic-v1.8.3.7-aic100/distilbert_mp/offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.03424083183069,
    "Accuracy_div_100": 0.90034,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Qualcomm/results/g292_z43_q18-qaic-v1.8.3.7-aic100/bert_pruned_82.6_mp/offline",
    "MlperfModel": "bert-99",
    "Model": "bert_pruned_82.6_mp",
    "Organization": "Qualcomm",
    "Platform": "g292_z43_q18-qaic-v1.8.3.7-aic100",
    "Result": 39443.8,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GIGABYTE G292-Z43 (18x QAIC100 Pro)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 18,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.8.3",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7713 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5 LTS (Linux kernel: 5.4.0-135-generic #152-Ubuntu SMP Wed Nov 23 20:19:22 UTC 2022)",
    "uid": "4a6ca103b2a14cdf",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Qualcomm/results/g292_z43_q18-qaic-v1.8.3.7-aic100/bert_pruned_82.6_mp/offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 91.07451933296576,
    "Accuracy_div_100": 0.91075,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Intel/results/1-node-2S-SPR-Neural_Engine-INT8/bert-99.9_MiniLM/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9_MiniLM",
    "Organization": "Intel",
    "Platform": "1-node-2S-SPR-Neural_Engine-INT8",
    "Result": 4260.95,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "1-node-2S-SPR-Neural_Engine-INT8",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54Q-2U",
    "number_of_nodes": 2,
    "operating_system": "CentOS Stream 8",
    "uid": "e7f32cc10d254b39",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Intel/results/1-node-2S-SPR-Neural_Engine-INT8/bert-99.9_MiniLM/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.2931675957547,
    "Accuracy_div_100": 0.90293,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Intel/results/1-node-2S-SPR-OpenVINO-INT8/bert-99_jpqd-mobilebert/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99_jpqd-mobilebert",
    "Organization": "Intel",
    "Platform": "1-node-2S-SPR-OpenVINO-INT8",
    "Result": 1678.28,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "1-node-2S-SPR-OpenVINO-INT8",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "OpenVINO",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Intel Devlopment Platform (2U Server)",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream release 8",
    "uid": "a7abb577a1184522",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Intel/results/1-node-2S-SPR-OpenVINO-INT8/bert-99_jpqd-mobilebert/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.94478332426705,
    "Accuracy_div_100": 0.90945,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Intel/results/1-node-2S-SPR-OpenVINO-INT8/bert-99.9_jpqd-large/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9_jpqd-large",
    "Organization": "Intel",
    "Platform": "1-node-2S-SPR-OpenVINO-INT8",
    "Result": 768.596,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "1-node-2S-SPR-OpenVINO-INT8",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "OpenVINO",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Intel Devlopment Platform (2U Server)",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream release 8",
    "uid": "612cb4173f72444e",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Intel/results/1-node-2S-SPR-OpenVINO-INT8/bert-99.9_jpqd-large/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.15430667223764,
    "Accuracy_div_100": 0.90154,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Intel/results/1-node-2S-SPR-OpenVINO-INT8/bert-99_jpqd-large/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99_jpqd-large",
    "Organization": "Intel",
    "Platform": "1-node-2S-SPR-OpenVINO-INT8",
    "Result": 865.76,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "1-node-2S-SPR-OpenVINO-INT8",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "OpenVINO",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Intel Devlopment Platform (2U Server)",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream release 8",
    "uid": "1793bcfc56864eb6",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Intel/results/1-node-2S-SPR-OpenVINO-INT8/bert-99_jpqd-large/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.14092926702556,
    "Accuracy_div_100": 0.90141,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Intel/results/1-node-2S-SPR-OpenVINO-INT8/bert-99_jpqd-base/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99_jpqd-base",
    "Organization": "Intel",
    "Platform": "1-node-2S-SPR-OpenVINO-INT8",
    "Result": 1105.24,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "1-node-2S-SPR-OpenVINO-INT8",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "OpenVINO",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Intel Devlopment Platform (2U Server)",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream release 8",
    "uid": "883ed8a0587a497e",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Intel/results/1-node-2S-SPR-OpenVINO-INT8/bert-99_jpqd-base/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.24891234802074,
    "Accuracy_div_100": 0.90249,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Intel/results/1-node-2S-ICX-Neural_Engine-INT8/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Intel",
    "Platform": "1-node-2S-ICX-Neural_Engine-INT8",
    "Result": 333.134,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "1-node-2S-ICX-Neural_Engine-INT8",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural_Engine",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54Q-2U",
    "number_of_nodes": 2,
    "operating_system": "Ubuntu 20.04.1 LTS",
    "uid": "d8d00cc6cc514fe7",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Intel/results/1-node-2S-ICX-Neural_Engine-INT8/bert-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.92786470887266,
    "Accuracy_div_100": 0.90928,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Intel/results/1-node-2S-ICX-Neural_Engine-INT8/bert-99.9_MiniLM/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9_MiniLM",
    "Organization": "Intel",
    "Platform": "1-node-2S-ICX-Neural_Engine-INT8",
    "Result": 2227.79,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "1-node-2S-ICX-Neural_Engine-INT8",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural_Engine",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54Q-2U",
    "number_of_nodes": 2,
    "operating_system": "Ubuntu 20.04.1 LTS",
    "uid": "19013ac40eb74dd5",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Intel/results/1-node-2S-ICX-Neural_Engine-INT8/bert-99.9_MiniLM/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.87487229720105,
    "Accuracy_div_100": 0.90875,
    "Availability": "available",
    "Division": "open",
    "Location": "open/cTuning/results/aws_g4dn.xlarge-reference-gpu-pytorch-v2.1.0.dev20230303-default_config/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "cTuning",
    "Platform": "aws_g4dn.xlarge-reference-gpu-pytorch-v2.1.0.dev20230303-default_config",
    "Result": 11.273,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance g4dn.xlarge",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "Tesla T4",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Pytorch 2.1.0 Dev version",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 2,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by MLCommons Collective Mind framework (CK2). ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.15.0-1028-aws-glibc2.35)",
    "uid": "3c1edb1228154369",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/cTuning/results/aws_g4dn.xlarge-reference-gpu-pytorch-v2.1.0.dev20230303-default_config/bert-99/offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.87487229720105,
    "Accuracy_div_100": 0.90875,
    "Availability": "available",
    "Division": "open",
    "Location": "open/cTuning/results/aws_g4dn.xlarge.497G-reference-gpu-pytorch-v1.13.1-default_config/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "cTuning",
    "Platform": "aws_g4dn.xlarge.497G-reference-gpu-pytorch-v1.13.1-default_config",
    "Result": 10.4627,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance g4dn.xlarge",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "Tesla T4",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Pytorch v1.13.1",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 2,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by MLCommons Collective Mind framework (CK2). ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.15.0-1028-aws-glibc2.35)",
    "uid": "4a238d5e3ff1476f",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/cTuning/results/aws_g4dn.xlarge.497G-reference-gpu-pytorch-v1.13.1-default_config/bert-99/offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.87487229720105,
    "Accuracy_div_100": 0.90875,
    "Availability": "available",
    "Division": "open",
    "Location": "open/cTuning/results/aws_g4dn.xlarge-reference-gpu-pytorch-v1.13.1-default_config/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "cTuning",
    "Platform": "aws_g4dn.xlarge-reference-gpu-pytorch-v1.13.1-default_config",
    "Result": 11.3458,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance g4dn.xlarge",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "Tesla T4",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Pytorch 1.13.1",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 2,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by MLCommons Collective Mind framework (CK2). ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.15.0-1028-aws-glibc2.35)",
    "uid": "cb426ced8d274a00",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/cTuning/results/aws_g4dn.xlarge-reference-gpu-pytorch-v1.13.1-default_config/bert-99/offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.87487229720105,
    "Accuracy_div_100": 0.90875,
    "Availability": "available",
    "Division": "open",
    "Location": "open/cTuning/results/aws_g4dn.xlarge.497G-reference-gpu-onnxruntime-v1.14.0-default_config/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "cTuning",
    "Platform": "aws_g4dn.xlarge.497G-reference-gpu-onnxruntime-v1.14.0-default_config",
    "Result": 12.3217,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance g4dn.xlarge",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "Tesla T4",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Onnxruntime v1.14.0 with GPU support",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 2,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by MLCommons Collective Mind framework (CK2). ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.15.0-1028-aws-glibc2.35)",
    "uid": "771ad41bf8864121",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/cTuning/results/aws_g4dn.xlarge.497G-reference-gpu-onnxruntime-v1.14.0-default_config/bert-99/offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.24821866958023,
    "Accuracy_div_100": 0.90248,
    "Availability": "available",
    "Division": "open",
    "Location": "open/cTuning/results/aws_g4dn.xlarge.497G-nvidia_original-gpu-tensorrt-v8.5.2.2-default_config/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "cTuning",
    "Platform": "aws_g4dn.xlarge.497G-nvidia_original-gpu-tensorrt-v8.5.2.2-default_config",
    "Result": 317.058,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance g4dn.xlarge",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "Tesla T4",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.5.2.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 2,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by MLCommons Collective Mind framework (CK2). ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.15.0-1028-aws-glibc2.35)",
    "uid": "356d05294780412c",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/cTuning/results/aws_g4dn.xlarge.497G-nvidia_original-gpu-tensorrt-v8.5.2.2-default_config/bert-99/offline",
    "version": "v3.0"
  }
]
