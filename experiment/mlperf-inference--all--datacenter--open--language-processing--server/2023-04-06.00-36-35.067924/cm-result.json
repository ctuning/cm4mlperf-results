[
  {
    "Accuracy": 90.9573381434376,
    "Accuracy_div_100": 0.90957,
    "Availability": "available",
    "Division": "open",
    "Location": "open/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT_TRT/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "HPE",
    "Platform": "HPE_Cray_XD670_H100_SXM_80GBx8_TRT_TRT",
    "Result": 51826.9,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "HPE Cray XD670 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.3",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.3",
    "uid": "67196698fa264635",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT_TRT/bert-99.9/Server",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.95436140465593,
    "Accuracy_div_100": 0.90954,
    "Availability": "available",
    "Division": "open",
    "Location": "open/HPE/results/HPE_ProLiant_DL380a_H100_PCIe_80GBx4_TRT_TRT/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "HPE",
    "Platform": "HPE_ProLiant_DL380a_H100_PCIe_80GBx4_TRT_TRT",
    "Result": 15996.4,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "HPE ProLiant DL380a Gen11 (4x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "0eaf824b88c04ea9",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/HPE/results/HPE_ProLiant_DL380a_H100_PCIe_80GBx4_TRT_TRT/bert-99/Server",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.97613347593594,
    "Accuracy_div_100": 0.90976,
    "Availability": "available",
    "Division": "open",
    "Location": "open/HPE/results/HPE_ProLiant_DL380a_H100_PCIe_80GBx4_TRT_TRT/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "HPE",
    "Platform": "HPE_ProLiant_DL380a_H100_PCIe_80GBx4_TRT_TRT",
    "Result": 15996.4,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "HPE ProLiant DL380a Gen11 (4x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "24f657a3388041a5",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/HPE/results/HPE_ProLiant_DL380a_H100_PCIe_80GBx4_TRT_TRT/bert-99.9/Server",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.88636511427569,
    "Accuracy_div_100": 0.90886,
    "Availability": "available",
    "Division": "open",
    "Location": "open/HPE/results/HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "HPE",
    "Platform": "HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT",
    "Result": 5437.63,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "HPE ProLiant DL380a Gen11 (4x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 60,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8580",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "abac7d30f12f4b03",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/HPE/results/HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT/bert-99.9/Server",
    "version": "v4.0"
  },
  {
    "Accuracy": 44.5405,
    "Accuracy_div_100": 0.4454,
    "Availability": "available",
    "Division": "open",
    "Location": "open/RedHat-Supermicro/results/AS-4125GS-TNRT-RedHat-OpenShift-AI/llama2-70b-99/Server",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "RedHat-Supermicro",
    "Platform": "AS-4125GS-TNRT-RedHat-OpenShift-AI",
    "Result": 7.44398,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "AS-4125GS-TNRT(8xH100-PCIe-80GB, Red Hat OpenShift AI, vLLM(fp16))",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 9554 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "NVIDIA H100-PCIe-80GB. Red Hat OpenShift Container Platform 4.14 + OpenShift AI",
    "number_of_nodes": 1,
    "operating_system": "Red Hat Enterprise Linux CoreOS release 4.14",
    "uid": "0e9ce33f4cab4852",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/RedHat-Supermicro/results/AS-4125GS-TNRT-RedHat-OpenShift-AI/llama2-70b-99/Server",
    "version": "v4.0"
  },
  {
    "Accuracy": 44.5405,
    "Accuracy_div_100": 0.4454,
    "Availability": "available",
    "Division": "open",
    "Location": "open/RedHat-Supermicro/results/AS-4125GS-TNRT-RedHat-OpenShift-AI/llama2-70b-99.9/Server",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "RedHat-Supermicro",
    "Platform": "AS-4125GS-TNRT-RedHat-OpenShift-AI",
    "Result": 7.44398,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "AS-4125GS-TNRT(8xH100-PCIe-80GB, Red Hat OpenShift AI, vLLM(fp16))",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 9554 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "NVIDIA H100-PCIe-80GB. Red Hat OpenShift Container Platform 4.14 + OpenShift AI",
    "number_of_nodes": 1,
    "operating_system": "Red Hat Enterprise Linux CoreOS release 4.14",
    "uid": "50189dbef7af4509",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/RedHat-Supermicro/results/AS-4125GS-TNRT-RedHat-OpenShift-AI/llama2-70b-99.9/Server",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.16932287713024,
    "Accuracy_div_100": 0.90169,
    "Availability": "rdi",
    "Division": "open",
    "Location": "open/NVIDIA/results/L4x1_TRT/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "L4x1_TRT",
    "Result": 4264.85,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NVIDIA L4 (1x L4, TensorRT)",
    "SystemType": "datacenter,edge",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7313P 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "7c7c7798219d4f34",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/open/NVIDIA/results/L4x1_TRT/bert-99/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.37586600946241,
    "Accuracy_div_100": 0.90376,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Azure/results/NC96ads_A100_v4_TRT_Triton/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Azure",
    "Platform": "NC96ads_A100_v4_TRT_Triton",
    "Result": 10343.7,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NC96ads_A100_v4 (4x A100-PCIe-80GB, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 7V13 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.6 LTS",
    "uid": "7db1e9a46e1e43d2",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/open/Azure/results/NC96ads_A100_v4_TRT_Triton/bert-99/Server",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.37586600946241,
    "Accuracy_div_100": 0.90376,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Azure/results/NC96ads_A100_v4_TRT/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Azure",
    "Platform": "NC96ads_A100_v4_TRT",
    "Result": 11491.3,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NC96ads_A100_v4 (4x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 7V13 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.6 LTS",
    "uid": "626e34e50d874ed4",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/open/Azure/results/NC96ads_A100_v4_TRT/bert-99/Server",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.8575190748761,
    "Accuracy_div_100": 0.90858,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Moffett/results/Moffett_S10_Inspur/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Moffett",
    "Platform": "Moffett_S10_Inspur",
    "Result": 2003.62,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Inspur NF5468M6-P (1x SparseOne S10, PCIe/FHFL, Moffett-SDK)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "MOFFETT S10-PCIe/FHFL-40GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Moffett SDK",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platium 8380",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.5 LTS",
    "uid": "74b3bda18db94ce7",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Moffett/results/Moffett_S10_Inspur/bert-99.9/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.8575190748761,
    "Accuracy_div_100": 0.90858,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Moffett/results/Moffett_S30_Inspur/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Moffett",
    "Platform": "Moffett_S30_Inspur",
    "Result": 3008.8,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Inspur NF5468M6-P (1x SparseOne S30, PCIe/FHFL, Moffett-SDK)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "MOFFETT S30-PCIe/FHFL-60GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Moffett SDK",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platium 8380",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.5 LTS",
    "uid": "3f63f4ab0f844e99",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Moffett/results/Moffett_S30_Inspur/bert-99.9/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.38590173403216,
    "Accuracy_div_100": 0.90386,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Supermicro/results/A100X4_751GE_TRT/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Supermicro",
    "Platform": "A100X4_751GE_TRT",
    "Result": 11499.1,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "SYS-751GE-TNRT, TensorRT",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "INTEL XEON GOLD 6444Y 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.3",
    "uid": "0dce4c05223342d2",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Supermicro/results/A100X4_751GE_TRT/bert-99/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.88723524062507,
    "Accuracy_div_100": 0.90887,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Supermicro/results/A100X4_751GE_TRT/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Supermicro",
    "Platform": "A100X4_751GE_TRT",
    "Result": 5401.64,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "SYS-751GE-TNRT, TensorRT",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "INTEL XEON GOLD 6444Y 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.3",
    "uid": "b7aeda65911a48af",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Supermicro/results/A100X4_751GE_TRT/bert-99.9/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.38590173403216,
    "Accuracy_div_100": 0.90386,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Supermicro/results/A100X4_751GE_TRT_Triton/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Supermicro",
    "Platform": "A100X4_751GE_TRT_Triton",
    "Result": 9002.98,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "SYS-751GE-TNRT, TensorRT, Triton",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "INTEL XEON GOLD 6444Y 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.3",
    "uid": "1901d350bfc84184",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Supermicro/results/A100X4_751GE_TRT_Triton/bert-99/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.88723524062507,
    "Accuracy_div_100": 0.90887,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Supermicro/results/A100X4_751GE_TRT_Triton/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Supermicro",
    "Platform": "A100X4_751GE_TRT_Triton",
    "Result": 4751.84,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "SYS-751GE-TNRT, TensorRT, Triton",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "INTEL XEON GOLD 6444Y 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.3",
    "uid": "0e3947d77c324922",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Supermicro/results/A100X4_751GE_TRT_Triton/bert-99.9/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.91678269111374,
    "Accuracy_div_100": 0.90917,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Qualcomm/results/g292_z43_q18-qaic-v1.8.3.7-aic100/bert_pruned_83.2_mp/server",
    "MlperfModel": "bert-99.9",
    "Model": "bert_pruned_83.2_mp",
    "Organization": "Qualcomm",
    "Platform": "g292_z43_q18-qaic-v1.8.3.7-aic100",
    "Result": 31405.2,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "GIGABYTE G292-Z43 (18x QAIC100 Pro)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 18,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.8.3",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7713 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5 LTS (Linux kernel: 5.4.0-135-generic #152-Ubuntu SMP Wed Nov 23 20:19:22 UTC 2022)",
    "uid": "f803bed40b1242f6",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Qualcomm/results/g292_z43_q18-qaic-v1.8.3.7-aic100/bert_pruned_83.2_mp/server",
    "version": "v3.0"
  },
  {
    "Accuracy": 86.13436789084363,
    "Accuracy_div_100": 0.86134,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Qualcomm/results/g292_z43_q18-qaic-v1.8.3.7-aic100/distilbert_mp/server",
    "MlperfModel": "bert-99",
    "Model": "distilbert_mp",
    "Organization": "Qualcomm",
    "Platform": "g292_z43_q18-qaic-v1.8.3.7-aic100",
    "Result": 53024.3,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "GIGABYTE G292-Z43 (18x QAIC100 Pro)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 18,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.8.3",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7713 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5 LTS (Linux kernel: 5.4.0-135-generic #152-Ubuntu SMP Wed Nov 23 20:19:22 UTC 2022)",
    "uid": "1c7d4479b3f14f4f",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Qualcomm/results/g292_z43_q18-qaic-v1.8.3.7-aic100/distilbert_mp/server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.09233322361673,
    "Accuracy_div_100": 0.90092,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Qualcomm/results/g292_z43_q18-qaic-v1.8.3.7-aic100/bert_pruned_82.6_mp/server",
    "MlperfModel": "bert-99",
    "Model": "bert_pruned_82.6_mp",
    "Organization": "Qualcomm",
    "Platform": "g292_z43_q18-qaic-v1.8.3.7-aic100",
    "Result": 38907.9,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "GIGABYTE G292-Z43 (18x QAIC100 Pro)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 18,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.8.3",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7713 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5 LTS (Linux kernel: 5.4.0-135-generic #152-Ubuntu SMP Wed Nov 23 20:19:22 UTC 2022)",
    "uid": "72ea467118fc4070",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Qualcomm/results/g292_z43_q18-qaic-v1.8.3.7-aic100/bert_pruned_82.6_mp/server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.2931675957547,
    "Accuracy_div_100": 0.90293,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Intel/results/1-node-2S-SPR-OpenVINO-INT8/bert-99_jpqd-mobilebert/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99_jpqd-mobilebert",
    "Organization": "Intel",
    "Platform": "1-node-2S-SPR-OpenVINO-INT8",
    "Result": 1662.75,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "1-node-2S-SPR-OpenVINO-INT8",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "OpenVINO",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Intel Devlopment Platform (2U Server)",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream release 8",
    "uid": "17427a3ad6d94226",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Intel/results/1-node-2S-SPR-OpenVINO-INT8/bert-99_jpqd-mobilebert/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.94478332426705,
    "Accuracy_div_100": 0.90945,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Intel/results/1-node-2S-SPR-OpenVINO-INT8/bert-99.9_jpqd-large/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9_jpqd-large",
    "Organization": "Intel",
    "Platform": "1-node-2S-SPR-OpenVINO-INT8",
    "Result": 549.949,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "1-node-2S-SPR-OpenVINO-INT8",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "OpenVINO",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Intel Devlopment Platform (2U Server)",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream release 8",
    "uid": "b1b97be2bfb54776",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Intel/results/1-node-2S-SPR-OpenVINO-INT8/bert-99.9_jpqd-large/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.15430667223764,
    "Accuracy_div_100": 0.90154,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Intel/results/1-node-2S-SPR-OpenVINO-INT8/bert-99_jpqd-large/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99_jpqd-large",
    "Organization": "Intel",
    "Platform": "1-node-2S-SPR-OpenVINO-INT8",
    "Result": 734.24,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "1-node-2S-SPR-OpenVINO-INT8",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "OpenVINO",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Intel Devlopment Platform (2U Server)",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream release 8",
    "uid": "60770ff1442342a5",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Intel/results/1-node-2S-SPR-OpenVINO-INT8/bert-99_jpqd-large/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.14092926702556,
    "Accuracy_div_100": 0.90141,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Intel/results/1-node-2S-SPR-OpenVINO-INT8/bert-99_jpqd-base/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99_jpqd-base",
    "Organization": "Intel",
    "Platform": "1-node-2S-SPR-OpenVINO-INT8",
    "Result": 1023.49,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "1-node-2S-SPR-OpenVINO-INT8",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "OpenVINO",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Intel Devlopment Platform (2U Server)",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream release 8",
    "uid": "703fbbc3bb274efb",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Intel/results/1-node-2S-SPR-OpenVINO-INT8/bert-99_jpqd-base/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.2039469599852,
    "Accuracy_div_100": 0.90204,
    "Availability": "available",
    "Division": "open",
    "Location": "open/cTuning/results/aws_g4dn.xlarge.497G-nvidia_original-gpu-tensorrt-v8.5.2.2-default_config/bert-99/server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "cTuning",
    "Platform": "aws_g4dn.xlarge.497G-nvidia_original-gpu-tensorrt-v8.5.2.2-default_config",
    "Result": 249.841,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "AWS cloud instance g4dn.xlarge",
    "SystemType": "datacenter,edge",
    "Units": "Queries/s",
    "accelerator_model_name": "Tesla T4",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.5.2.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 2,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by MLCommons Collective Mind framework (CK2). ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.15.0-1028-aws-glibc2.35)",
    "uid": "63fb16380ed648e0",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/cTuning/results/aws_g4dn.xlarge.497G-nvidia_original-gpu-tensorrt-v8.5.2.2-default_config/bert-99/server",
    "version": "v3.0"
  }
]
