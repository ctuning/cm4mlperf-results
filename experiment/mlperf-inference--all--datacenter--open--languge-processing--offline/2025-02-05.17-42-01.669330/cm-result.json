[
  {
    "Accuracy": 45.4026,
    "Accuracy_div_100": 0.45403,
    "Availability": "available",
    "Division": "open",
    "Location": "open/HPE/results/HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT/mixtral-8x7b/Offline",
    "MlperfModel": "mixtral-8x7b",
    "Model": "mixtral-8x7b",
    "Organization": "HPE",
    "Platform": "HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT",
    "Result": 18839,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "HPE ProLiant DL380a Gen11 (4x H100-NVL-94GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "INTEL(R) XEON(R) GOLD 6530",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "uid": "90112b5c9bee4820",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/open/HPE/results/HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT/mixtral-8x7b/Offline",
    "version": "v4.1"
  }
]
