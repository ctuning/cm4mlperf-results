[
  {
    "Accuracy": "mAP: 37.344",
    "Availability": "available",
    "Division": "open",
    "Location": "open/GATEOverflow/results/RTX4090x1-nvidia-gpu-TensorRT-default_config/retinanet/offline",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "GATEOverflow",
    "Platform": "RTX4090x1-nvidia-gpu-TensorRT-default_config",
    "Result": 869.415,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "PCSPECIALIST AMD AM5 PC (1x RTX 4090)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04 (linux-6.8.0-52-generic-glibc2.31)",
    "uid": "69a21ea4cf484fe5",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/open/GATEOverflow/results/RTX4090x1-nvidia-gpu-TensorRT-default_config/retinanet/offline",
    "version": "v5.0",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": 37.161,
    "Accuracy_div_100": 0.37161,
    "Availability": "preview",
    "Division": "open",
    "Location": "open/Qualcomm/results/g292_z43_q16_prev-qaic-v1.8.0.73-aic100/retinanet/offline",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Qualcomm",
    "Platform": "g292_z43_q16_prev-qaic-v1.8.0.73-aic100",
    "Result": 3002.87,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G292-Z43 (16x QAIC100 Pro)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 16,
    "compliance": 1,
    "errors": 0,
    "framework": "Qualcomm Cloud AI SDK v1.8.0.73",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7713 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by MLCommons Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "CentOS 7 (Linux kernel: 5.4.1-1.el7.elrepo.x86_64 #1 SMP Fri Nov 29 10:21:13 EST 2019 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "876d7fd6f8354eda",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/open/Qualcomm/results/g292_z43_q16_prev-qaic-v1.8.0.73-aic100/retinanet/offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 37.161,
    "Accuracy_div_100": 0.37161,
    "Availability": "preview",
    "Division": "open",
    "Location": "open/Qualcomm/results/r282_z93_q8_prev-qaic-v1.8.0.73-aic100/retinanet/offline",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Qualcomm",
    "Platform": "r282_z93_q8_prev-qaic-v1.8.0.73-aic100",
    "Result": 1501.28,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte R282-Z93 (8x QAIC100 Pro)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "Qualcomm Cloud AI SDK v1.8.0.73",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7282 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by MLCommons Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "CentOS 7 (Linux kernel: 5.4.1-1.el7.elrepo.x86_64 #1 SMP Fri Nov 29 10:21:13 EST 2019 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "cee697490c26441c",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/open/Qualcomm/results/r282_z93_q8_prev-qaic-v1.8.0.73-aic100/retinanet/offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 37.161,
    "Accuracy_div_100": 0.37161,
    "Availability": "preview",
    "Division": "open",
    "Location": "open/Qualcomm/results/g292_z43_q18_prev-qaic-v1.8.0.73-aic100/retinanet/offline",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Qualcomm",
    "Platform": "g292_z43_q18_prev-qaic-v1.8.0.73-aic100",
    "Result": 3358.26,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G292-Z43 (18x QAIC100 Pro)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 18,
    "compliance": 1,
    "errors": 0,
    "framework": "Qualcomm Cloud AI SDK v1.8.0.73",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7713 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by MLCommons Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "CentOS 7 (Linux kernel: 5.4.1-1.el7.elrepo.x86_64 #1 SMP Fri Nov 29 10:21:13 EST 2019 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "ae85e2176cdf479f",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/open/Qualcomm/results/g292_z43_q18_prev-qaic-v1.8.0.73-aic100/retinanet/offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 37.572,
    "Accuracy_div_100": 0.37572,
    "Availability": "available",
    "Division": "open",
    "Location": "open/OctoML/results/gcp-n2-standard-80-onnxruntime-cpu/retinanet/offline",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "OctoML",
    "Platform": "gcp-n2-standard-80-onnxruntime-cpu",
    "Result": 9.02049,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Google (Google Compute Engine) n2-standard-80",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Onnxruntime 1.12.0 (out of the box MLPerf)",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 20,
    "host_processor_model_name": "Intel(R) Xeon(R) CPU (Intel Cascade Lake CPU platform)",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Demo of the new MLCommons Collective Mind toolkit v0.7.24 - the next generation of the MLCommons Collective Knowledge framework being developed by the open education workgroup to help the community learn how to use, customize and extend MLPerf benchmarks: https://github.com/mlcommons/ck/blob/master/docs/mlperf-education-workgroup.md",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.1 LTS (Linux-5.8.0-1038-gcp-x86_64-with-glibc2.31)",
    "uid": "2862453bef054e6f",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/open/OctoML/results/gcp-n2-standard-80-onnxruntime-cpu/retinanet/offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 37.552,
    "Accuracy_div_100": 0.37552,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Supermicro/results/A100X4_751GE_TRT/retinanet/Offline",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Supermicro",
    "Platform": "A100X4_751GE_TRT",
    "Result": 2568.81,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "SYS-751GE-TNRT, TensorRT",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "INTEL XEON GOLD 6444Y 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.3",
    "uid": "3a64a52b10b74cee",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Supermicro/results/A100X4_751GE_TRT/retinanet/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 37.552,
    "Accuracy_div_100": 0.37552,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Supermicro/results/A100X4_751GE_TRT_Triton/retinanet/Offline",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Supermicro",
    "Platform": "A100X4_751GE_TRT_Triton",
    "Result": 2529,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "SYS-751GE-TNRT, TensorRT, Triton",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "INTEL XEON GOLD 6444Y 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.3",
    "uid": "8e8f2df5c11c4e0f",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Supermicro/results/A100X4_751GE_TRT_Triton/retinanet/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 37.79,
    "Accuracy_div_100": 0.3779,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Intel/results/1-node-2S-SPR-PyTorch-INT8/retinanet/Offline",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Intel",
    "Platform": "1-node-2S-SPR-PyTorch-INT8",
    "Result": 438.112,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "1-node-2S-SPR-PyTorch-INT8",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Intel Devlopment Platform (2U Server)",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream release 8",
    "uid": "d2cac39ae05c4e07",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Intel/results/1-node-2S-SPR-PyTorch-INT8/retinanet/Offline",
    "version": "v3.0"
  }
]
