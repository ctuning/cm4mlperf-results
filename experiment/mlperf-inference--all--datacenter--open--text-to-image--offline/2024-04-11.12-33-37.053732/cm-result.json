[
  {
    "Accuracy": 31.750536930561065,
    "Accuracy_div_100": 0.31751,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/cm-demo-gfursin-scaleway-L4-1-24G-reference-gpu-pytorch-v2.3.1-default_config/stable-diffusion-xl/offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "CTuning",
    "Platform": "cm-demo-gfursin-scaleway-L4-1-24G-reference-gpu-pytorch-v2.3.1-default_config",
    "Result": 0.125716,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "scaleway-L4-1-24G",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "pytorch v2.3.1",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 8,
    "host_processor_model_name": "AMD EPYC 7413 24-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "cTuning.org/ae: Collective Mind demo for our reproducibility initiatives and artifact evaluation at ACM, IEEE and MLCommons ; automated by MLCommons CM v2.3.4 ; taken by Grigori Fursin",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.15.0-116-generic-glibc2.35)",
    "uid": "d5a36f8872e14c1f",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/open/CTuning/results/cm-demo-gfursin-scaleway-L4-1-24G-reference-gpu-pytorch-v2.3.1-default_config/stable-diffusion-xl/offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 31.80439346909523,
    "Accuracy_div_100": 0.31804,
    "Availability": "available",
    "Division": "open",
    "Location": "open/HPE/results/HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "HPE",
    "Platform": "HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT",
    "Result": 1.79467,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "HPE ProLiant DL380a Gen11 (4x L40S-PCIe-48GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 60,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8580",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "bd53b725ea7f4d94",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/open/HPE/results/HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT/stable-diffusion-xl/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 31.280030560195446,
    "Accuracy_div_100": 0.3128,
    "Availability": "available",
    "Division": "open",
    "Location": "open/NVIDIA/results/H200-SXM-141GBx1_TRT_LCM/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx1_TRT_LCM",
    "Result": 10.7891,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA H200 (1x H200-SXM-141GB)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "1fa2d2d9b6b04710",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/open/NVIDIA/results/H200-SXM-141GBx1_TRT_LCM/stable-diffusion-xl/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 31.793520182073117,
    "Accuracy_div_100": 0.31794,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Oracle/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Oracle",
    "Platform": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "Result": 2.32815,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA GH200-GraceHopper-Superchip (1x GH200-96GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA MGX Reference Platform;",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "uid": "60701c64524b452d",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/open/Oracle/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/stable-diffusion-xl/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 31.713050619661807,
    "Accuracy_div_100": 0.31713,
    "Availability": "available",
    "Division": "open",
    "Location": "open/NVIDIA/results/DGX-H100_H100-SXM-80GBx1_TRT_DEEP_CACHE/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "NVIDIA",
    "Platform": "DGX-H100_H100-SXM-80GBx1_TRT_DEEP_CACHE",
    "Result": 2.85204,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX H100 (1x H100-SXM-80GB)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "15fc93e8a4904e2a",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/NVIDIA/results/DGX-H100_H100-SXM-80GBx1_TRT_DEEP_CACHE/stable-diffusion-xl/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 32.16486001670361,
    "Accuracy_div_100": 0.32165,
    "Availability": "available",
    "Division": "open",
    "Location": "open/NVIDIA/results/DGX-H100_H100-SXM-80GBx1_TRT_DEEP_CACHE_PRUNED/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "NVIDIA",
    "Platform": "DGX-H100_H100-SXM-80GBx1_TRT_DEEP_CACHE_PRUNED",
    "Result": 3.80537,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX H100 (1x H100-SXM-80GB)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "251657cea99e4adc",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/NVIDIA/results/DGX-H100_H100-SXM-80GBx1_TRT_DEEP_CACHE_PRUNED/stable-diffusion-xl/Offline",
    "version": "v4.0"
  }
]
