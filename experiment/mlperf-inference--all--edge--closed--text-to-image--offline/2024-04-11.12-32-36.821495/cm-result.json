[
  {
    "Accuracy": 31.80647490143776,
    "Accuracy_div_100": 0.31806,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/Orin_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "NVIDIA",
    "Platform": "Orin_TRT",
    "Result": 0.101697,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA Jetson AGX Orin Developer Kit 64G (TensorRT)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA Jetson AGX Orin 64G",
    "accelerators_per_node": 1,
    "compliance": 0,
    "errors": 0,
    "framework": "Jetpack 6.0, TensorRT 10.1, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 12,
    "host_processor_model_name": "12-core ARM Cortex-A78AE CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "GPU and both DLAs are used in resnet50 and Retinanet, in Offline scenario",
    "number_of_nodes": 1,
    "operating_system": "Jetson r36.3.1 L4T",
    "uid": "ac173b1f69294628",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/NVIDIA/results/Orin_TRT/stable-diffusion-xl/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 31.755029396116733,
    "Accuracy_div_100": 0.31755,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-gpu-pytorch-v2.1.2-default_config/stable-diffusion-xl/offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "CTuning",
    "Platform": "GATE_Overflow_Intel_Sapphire_Rapids-reference-gpu-pytorch-v2.1.2-default_config",
    "Result": 0.356743,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GATE Overflow Intel Sapphire Rapids (2x RTX 4090)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "MLCommons python reference implementation with CM API, Pytorch v2.1.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.04 (linux-6.2.0-39-generic-glibc2.37)",
    "uid": "8e91602b4c294155",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-gpu-pytorch-v2.1.2-default_config/stable-diffusion-xl/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 31.730986223220825,
    "Accuracy_div_100": 0.31731,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/CTuning/results/PCSPECIALIST_AMD_AM5_with_Nvidia_RTX_4090-reference-gpu-pytorch-v2.1.2-default_config/stable-diffusion-xl/offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "CTuning",
    "Platform": "PCSPECIALIST_AMD_AM5_with_Nvidia_RTX_4090-reference-gpu-pytorch-v2.1.2-default_config",
    "Result": 0.396513,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "PCSPECIALIST AMD AM5 PC (1x RTX 4090)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "MLCommons python reference implementation with CM API, Pytorch v2.1.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.5.0-14-generic-glibc2.35)",
    "uid": "4f05893c106449ee",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/CTuning/results/PCSPECIALIST_AMD_AM5_with_Nvidia_RTX_4090-reference-gpu-pytorch-v2.1.2-default_config/stable-diffusion-xl/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 31.781958403587343,
    "Accuracy_div_100": 0.31782,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XR8620_L4x1_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Dell",
    "Platform": "XR8620_L4x1_TRT",
    "Result": 0.189043,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XR8620t (1x L4, TensorRT)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6433N",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "bb1d0c0f90ee4554",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Dell/results/XR8620_L4x1_TRT/stable-diffusion-xl/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 31.765805671513082,
    "Accuracy_div_100": 0.31766,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Intel/results/1-node-2S-EMR-PyTorch-BF16/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Intel",
    "Platform": "1-node-2S-EMR-PyTorch-BF16",
    "Result": 0.193679,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "1-node-2S-EMR-PyTorch-BF16",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54Q-2U. N/A",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream 8",
    "uid": "6b5819cc11014995",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Intel/results/1-node-2S-EMR-PyTorch-BF16/stable-diffusion-xl/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 31.746802116930485,
    "Accuracy_div_100": 0.31747,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/Orin_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "NVIDIA",
    "Platform": "Orin_TRT",
    "Result": 0.0772202,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA Jetson AGX Orin Developer Kit 64G (TensorRT)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA Jetson AGX Orin 64G",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Jetpack 5.1.1, TensorRT 9.0.1, CUDA 11.4",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 12,
    "host_processor_model_name": "12-core ARM Cortex-A78AE CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "GPU and both DLAs are used in resnet50 and Retinanet, in Offline scenario",
    "number_of_nodes": 1,
    "operating_system": "Jetson r35.3.1 L4T",
    "uid": "82f4bd48f9824caf",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/NVIDIA/results/Orin_TRT/stable-diffusion-xl/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 31.79431421101093,
    "Accuracy_div_100": 0.31794,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Qualcomm/results/r282_q2_ultra_pp/stable-diffusion-xl/offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Qualcomm",
    "Platform": "r282_q2_ultra_pp",
    "Result": 0.356213,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GIGABYTE R282-Z93 (2x QAIC100 Ultra, PP)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 Ultra",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.12.2 / v1.14.2 (SDXL)",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7282 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3 LTS (Linux kernel 5.15.0-94-generic #104-Ubuntu SMP Tue Jan 9 15:25:40 UTC 2024 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "4a60637072e04bc1",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Qualcomm/results/r282_q2_ultra_pp/stable-diffusion-xl/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 31.8049609413743,
    "Accuracy_div_100": 0.31805,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Wiwynn/results/ES200G2_L40Sx2_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Wiwynn",
    "Platform": "ES200G2_L40Sx2_TRT",
    "Result": 1.2599,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Wiwynn ES200G2 (2x L40S, TensorRT)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "INTEL(R) XEON(R) GOLD 6538Y+",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.15.0-92-generic-glibc2.35)",
    "uid": "3a8a017fa119492e",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Wiwynn/results/ES200G2_L40Sx2_TRT/stable-diffusion-xl/Offline",
    "version": "v4.0"
  }
]
