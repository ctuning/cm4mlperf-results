[
  {
    "Accuracy": 31.799790530204774,
    "Accuracy_div_100": 0.318,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/Orin_TRT/stable-diffusion-xl/SingleStream",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "NVIDIA",
    "Platform": "Orin_TRT",
    "Result": 9966.781359,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "NVIDIA Jetson AGX Orin Developer Kit 64G (TensorRT)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA Jetson AGX Orin 64G",
    "accelerators_per_node": 1,
    "compliance": 0,
    "errors": 0,
    "framework": "Jetpack 6.0, TensorRT 10.1, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 12,
    "host_processor_model_name": "12-core ARM Cortex-A78AE CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "GPU and both DLAs are used in resnet50 and Retinanet, in Offline scenario",
    "number_of_nodes": 1,
    "operating_system": "Jetson r36.3.1 L4T",
    "uid": "9343cf617d0c414c",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/NVIDIA/results/Orin_TRT/stable-diffusion-xl/SingleStream",
    "version": "v4.1"
  },
  {
    "Accuracy": 31.755029396116733,
    "Accuracy_div_100": 0.31755,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-gpu-pytorch-v2.1.2-default_config/stable-diffusion-xl/singlestream",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "CTuning",
    "Platform": "GATE_Overflow_Intel_Sapphire_Rapids-reference-gpu-pytorch-v2.1.2-default_config",
    "Result": 2835.868888,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "GATE Overflow Intel Sapphire Rapids (2x RTX 4090)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "MLCommons python reference implementation with CM API, Pytorch v2.1.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.04 (linux-6.2.0-39-generic-glibc2.37)",
    "uid": "f27dceed89b643ca",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-gpu-pytorch-v2.1.2-default_config/stable-diffusion-xl/singlestream",
    "version": "v4.0"
  },
  {
    "Accuracy": 31.730986223220825,
    "Accuracy_div_100": 0.31731,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/CTuning/results/PCSPECIALIST_AMD_AM5_with_Nvidia_RTX_4090-reference-gpu-pytorch-v2.1.2-default_config/stable-diffusion-xl/singlestream",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "CTuning",
    "Platform": "PCSPECIALIST_AMD_AM5_with_Nvidia_RTX_4090-reference-gpu-pytorch-v2.1.2-default_config",
    "Result": 2602.503524,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "PCSPECIALIST AMD AM5 PC (1x RTX 4090)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "MLCommons python reference implementation with CM API, Pytorch v2.1.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.5.0-14-generic-glibc2.35)",
    "uid": "5fc7321d9cdf4e46",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/CTuning/results/PCSPECIALIST_AMD_AM5_with_Nvidia_RTX_4090-reference-gpu-pytorch-v2.1.2-default_config/stable-diffusion-xl/singlestream",
    "version": "v4.0"
  },
  {
    "Accuracy": 31.80243787318468,
    "Accuracy_div_100": 0.31802,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XR8620_L4x1_TRT/stable-diffusion-xl/SingleStream",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Dell",
    "Platform": "XR8620_L4x1_TRT",
    "Result": 5299.909124,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "Dell PowerEdge XR8620t (1x L4, TensorRT)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6433N",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "0b343b4a9e474c2f",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Dell/results/XR8620_L4x1_TRT/stable-diffusion-xl/SingleStream",
    "version": "v4.0"
  },
  {
    "Accuracy": 31.751816655397416,
    "Accuracy_div_100": 0.31752,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Intel/results/1-node-2S-EMR-PyTorch-BF16/stable-diffusion-xl/SingleStream",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Intel",
    "Platform": "1-node-2S-EMR-PyTorch-BF16",
    "Result": 11231.512231,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "1-node-2S-EMR-PyTorch-BF16",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54Q-2U. N/A",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream 8",
    "uid": "8f35e1c94ea544ed",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Intel/results/1-node-2S-EMR-PyTorch-BF16/stable-diffusion-xl/SingleStream",
    "version": "v4.0"
  },
  {
    "Accuracy": 31.74628773063421,
    "Accuracy_div_100": 0.31746,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/Orin_TRT/stable-diffusion-xl/SingleStream",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "NVIDIA",
    "Platform": "Orin_TRT",
    "Result": 12941.921115,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "NVIDIA Jetson AGX Orin Developer Kit 64G (TensorRT)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA Jetson AGX Orin 64G",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Jetpack 5.1.1, TensorRT 9.0.1, CUDA 11.4",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 12,
    "host_processor_model_name": "12-core ARM Cortex-A78AE CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "GPU and both DLAs are used in resnet50 and Retinanet, in Offline scenario",
    "number_of_nodes": 1,
    "operating_system": "Jetson r35.3.1 L4T",
    "uid": "46d6a81a0ccc4a39",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/NVIDIA/results/Orin_TRT/stable-diffusion-xl/SingleStream",
    "version": "v4.0"
  },
  {
    "Accuracy": 31.794359177947044,
    "Accuracy_div_100": 0.31794,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Qualcomm/results/r282_q2_ultra_pp/stable-diffusion-xl/singlestream",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Qualcomm",
    "Platform": "r282_q2_ultra_pp",
    "Result": 11668.906368,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "GIGABYTE R282-Z93 (2x QAIC100 Ultra, PP)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 Ultra",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.12.2 / v1.14.2 (SDXL)",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7282 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3 LTS (Linux kernel 5.15.0-94-generic #104-Ubuntu SMP Tue Jan 9 15:25:40 UTC 2024 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "2e2e9fd633644d0b",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Qualcomm/results/r282_q2_ultra_pp/stable-diffusion-xl/singlestream",
    "version": "v4.0"
  },
  {
    "Accuracy": 31.756315421760082,
    "Accuracy_div_100": 0.31756,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Wiwynn/results/ES200G2_L40Sx2_TRT/stable-diffusion-xl/SingleStream",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Wiwynn",
    "Platform": "ES200G2_L40Sx2_TRT",
    "Result": 1966.283702,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "Wiwynn ES200G2 (2x L40S, TensorRT)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "INTEL(R) XEON(R) GOLD 6538Y+",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.15.0-92-generic-glibc2.35)",
    "uid": "8dd93c49a81949b4",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Wiwynn/results/ES200G2_L40Sx2_TRT/stable-diffusion-xl/SingleStream",
    "version": "v4.0"
  }
]
