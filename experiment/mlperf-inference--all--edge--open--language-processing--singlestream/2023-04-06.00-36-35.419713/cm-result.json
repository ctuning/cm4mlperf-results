[
  {
    "Accuracy": 88.42042174998099,
    "Accuracy_div_100": 0.8842,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config/bert-base-pruned90-none-bert-99/singlestream",
    "MlperfModel": "bert-99",
    "Model": "bert-base-pruned90-none-bert-99",
    "Organization": "CTuning",
    "Platform": "AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 65.471325,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "TRIGKEY Mini PC Ryzen 5 5560",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 6,
    "host_processor_model_name": "AMD Ryzen 5 5560U with Radeon Graphics",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.5.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.10 (linux-6.5.0-17-generic-glibc2.38)",
    "uid": "41ea563cb00f4443",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config/bert-base-pruned90-none-bert-99/singlestream",
    "version": "v4.0"
  },
  {
    "Accuracy": 87.88571389692375,
    "Accuracy_div_100": 0.87886,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config/bert-base-pruned95_obs_quant-none-bert-99/singlestream",
    "MlperfModel": "bert-99",
    "Model": "bert-base-pruned95_obs_quant-none-bert-99",
    "Organization": "CTuning",
    "Platform": "AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 29.490806,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "TRIGKEY Mini PC Ryzen 5 5560",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 6,
    "host_processor_model_name": "AMD Ryzen 5 5560U with Radeon Graphics",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.5.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.10 (linux-6.5.0-17-generic-glibc2.38)",
    "uid": "af5de6678a7a4fe5",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config/bert-base-pruned95_obs_quant-none-bert-99/singlestream",
    "version": "v4.0"
  },
  {
    "Accuracy": 89.65191480026783,
    "Accuracy_div_100": 0.89652,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config/bert-large-base-none-bert-99/singlestream",
    "MlperfModel": "bert-99",
    "Model": "bert-large-base-none-bert-99",
    "Organization": "CTuning",
    "Platform": "AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 602.89593,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "TRIGKEY Mini PC Ryzen 5 5560",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 6,
    "host_processor_model_name": "AMD Ryzen 5 5560U with Radeon Graphics",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.5.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.10 (linux-6.5.0-17-generic-glibc2.38)",
    "uid": "d8fa7e33c35f45a4",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config/bert-large-base-none-bert-99/singlestream",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.29174382621062,
    "Accuracy_div_100": 0.90292,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config/bert-large-pruned80_quant-none-vnni-bert-99/singlestream",
    "MlperfModel": "bert-99",
    "Model": "bert-large-pruned80_quant-none-vnni-bert-99",
    "Organization": "CTuning",
    "Platform": "AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 141.409546,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "TRIGKEY Mini PC Ryzen 5 5560",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 6,
    "host_processor_model_name": "AMD Ryzen 5 5560U with Radeon Graphics",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.5.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.10 (linux-6.5.0-17-generic-glibc2.38)",
    "uid": "7dd53470bee64bda",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config/bert-large-pruned80_quant-none-vnni-bert-99/singlestream",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.4308347276475,
    "Accuracy_div_100": 0.90431,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config/mobilebert-14layer_pruned50-none-vnni-bert-99/singlestream",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-14layer_pruned50-none-vnni-bert-99",
    "Organization": "CTuning",
    "Platform": "AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 26.193637,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "TRIGKEY Mini PC Ryzen 5 5560",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 6,
    "host_processor_model_name": "AMD Ryzen 5 5560U with Radeon Graphics",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.5.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.10 (linux-6.5.0-17-generic-glibc2.38)",
    "uid": "6ea39e61d3d44310",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config/mobilebert-14layer_pruned50-none-vnni-bert-99/singlestream",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.36718210138123,
    "Accuracy_div_100": 0.90367,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config/mobilebert-14layer_pruned50_quant-none-vnni-bert-99/singlestream",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-14layer_pruned50_quant-none-vnni-bert-99",
    "Organization": "CTuning",
    "Platform": "AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 17.078629,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "TRIGKEY Mini PC Ryzen 5 5560",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 6,
    "host_processor_model_name": "AMD Ryzen 5 5560U with Radeon Graphics",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.5.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.10 (linux-6.5.0-17-generic-glibc2.38)",
    "uid": "223eac3f2a3845ee",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config/mobilebert-14layer_pruned50_quant-none-vnni-bert-99/singlestream",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.81268530031994,
    "Accuracy_div_100": 0.90813,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config/mobilebert-base_quant-none-bert-99/singlestream",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-base_quant-none-bert-99",
    "Organization": "CTuning",
    "Platform": "AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 37.692117,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "TRIGKEY Mini PC Ryzen 5 5560",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 6,
    "host_processor_model_name": "AMD Ryzen 5 5560U with Radeon Graphics",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.5.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.10 (linux-6.5.0-17-generic-glibc2.38)",
    "uid": "4f9946a1fc344923",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config/mobilebert-base_quant-none-bert-99/singlestream",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.89066465550044,
    "Accuracy_div_100": 0.90891,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config/mobilebert-none-base-none-bert-99/singlestream",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-none-base-none-bert-99",
    "Organization": "CTuning",
    "Platform": "AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 50.57429,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "TRIGKEY Mini PC Ryzen 5 5560",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 6,
    "host_processor_model_name": "AMD Ryzen 5 5560U with Radeon Graphics",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.5.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.10 (linux-6.5.0-17-generic-glibc2.38)",
    "uid": "35f69d3a863444c2",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config/mobilebert-none-base-none-bert-99/singlestream",
    "version": "v4.0"
  },
  {
    "Accuracy": 88.31078542237867,
    "Accuracy_div_100": 0.88311,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config/obert-base-pruned90-none-bert-99/singlestream",
    "MlperfModel": "bert-99",
    "Model": "obert-base-pruned90-none-bert-99",
    "Organization": "CTuning",
    "Platform": "AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 66.333164,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "TRIGKEY Mini PC Ryzen 5 5560",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 6,
    "host_processor_model_name": "AMD Ryzen 5 5560U with Radeon Graphics",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.5.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.10 (linux-6.5.0-17-generic-glibc2.38)",
    "uid": "970859027ff74e73",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config/obert-base-pruned90-none-bert-99/singlestream",
    "version": "v4.0"
  },
  {
    "Accuracy": 89.65191480026783,
    "Accuracy_div_100": 0.89652,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config/obert-large-base-none-bert-99/singlestream",
    "MlperfModel": "bert-99",
    "Model": "obert-large-base-none-bert-99",
    "Organization": "CTuning",
    "Platform": "AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 603.075929,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "TRIGKEY Mini PC Ryzen 5 5560",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 6,
    "host_processor_model_name": "AMD Ryzen 5 5560U with Radeon Graphics",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.5.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.10 (linux-6.5.0-17-generic-glibc2.38)",
    "uid": "cee8d6d8df2b41ee",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config/obert-large-base-none-bert-99/singlestream",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.17832662822171,
    "Accuracy_div_100": 0.90178,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned95-none-vnni-bert-99/singlestream",
    "MlperfModel": "bert-99",
    "Model": "obert-large-pruned95-none-vnni-bert-99",
    "Organization": "CTuning",
    "Platform": "AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 145.293863,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "TRIGKEY Mini PC Ryzen 5 5560",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 6,
    "host_processor_model_name": "AMD Ryzen 5 5560U with Radeon Graphics",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.5.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.10 (linux-6.5.0-17-generic-glibc2.38)",
    "uid": "9d9ad0e9ff9e4b35",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned95-none-vnni-bert-99/singlestream",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.01097011863615,
    "Accuracy_div_100": 0.90011,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned95_quant-none-vnni-bert-99/singlestream",
    "MlperfModel": "bert-99",
    "Model": "obert-large-pruned95_quant-none-vnni-bert-99",
    "Organization": "CTuning",
    "Platform": "AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 80.42338,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "TRIGKEY Mini PC Ryzen 5 5560",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 6,
    "host_processor_model_name": "AMD Ryzen 5 5560U with Radeon Graphics",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.5.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.10 (linux-6.5.0-17-generic-glibc2.38)",
    "uid": "1465527136074518",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned95_quant-none-vnni-bert-99/singlestream",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.1356467730578,
    "Accuracy_div_100": 0.90136,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned97-none-bert-99/singlestream",
    "MlperfModel": "bert-99",
    "Model": "obert-large-pruned97-none-bert-99",
    "Organization": "CTuning",
    "Platform": "AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 133.148383,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "TRIGKEY Mini PC Ryzen 5 5560",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 6,
    "host_processor_model_name": "AMD Ryzen 5 5560U with Radeon Graphics",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.5.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.10 (linux-6.5.0-17-generic-glibc2.38)",
    "uid": "0eedaed8d0044317",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned97-none-bert-99/singlestream",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.14276789144404,
    "Accuracy_div_100": 0.90143,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned97-quant-none-bert-99/singlestream",
    "MlperfModel": "bert-99",
    "Model": "obert-large-pruned97-quant-none-bert-99",
    "Organization": "CTuning",
    "Platform": "AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 107.284977,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "TRIGKEY Mini PC Ryzen 5 5560",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 6,
    "host_processor_model_name": "AMD Ryzen 5 5560U with Radeon Graphics",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.5.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.10 (linux-6.5.0-17-generic-glibc2.38)",
    "uid": "a62c7b862c0142f7",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned97-quant-none-bert-99/singlestream",
    "version": "v4.0"
  },
  {
    "Accuracy": 88.42042174998099,
    "Accuracy_div_100": 0.8842,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config/bert-base-pruned90-none-bert-99/singlestream",
    "MlperfModel": "bert-99",
    "Model": "bert-base-pruned90-none-bert-99",
    "Organization": "CTuning",
    "Platform": "GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 13.793175,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "GATE Overflow Intel Sapphire Rapids",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.6.2. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.04 (linux-6.2.0-39-generic-glibc2.37)",
    "uid": "32910311d99843ae",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config/bert-base-pruned90-none-bert-99/singlestream",
    "version": "v4.0"
  },
  {
    "Accuracy": 87.89212297504716,
    "Accuracy_div_100": 0.87892,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config/bert-base-pruned95_obs_quant-none-bert-99/singlestream",
    "MlperfModel": "bert-99",
    "Model": "bert-base-pruned95_obs_quant-none-bert-99",
    "Organization": "CTuning",
    "Platform": "GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 6.698966,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "GATE Overflow Intel Sapphire Rapids",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.6.2. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.04 (linux-6.2.0-39-generic-glibc2.37)",
    "uid": "4b8d0caaab014082",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config/bert-base-pruned95_obs_quant-none-bert-99/singlestream",
    "version": "v4.0"
  },
  {
    "Accuracy": 89.65191480026783,
    "Accuracy_div_100": 0.89652,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config/bert-large-base-none-bert-99/singlestream",
    "MlperfModel": "bert-99",
    "Model": "bert-large-base-none-bert-99",
    "Organization": "CTuning",
    "Platform": "GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 94.973539,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "GATE Overflow Intel Sapphire Rapids",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.6.2. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.04 (linux-6.2.0-39-generic-glibc2.37)",
    "uid": "c626d0b97d534bde",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config/bert-large-base-none-bert-99/singlestream",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.26941848776319,
    "Accuracy_div_100": 0.90269,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config/bert-large-pruned80_quant-none-vnni-bert-99/singlestream",
    "MlperfModel": "bert-99",
    "Model": "bert-large-pruned80_quant-none-vnni-bert-99",
    "Organization": "CTuning",
    "Platform": "GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 21.498438,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "GATE Overflow Intel Sapphire Rapids",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.6.2. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.04 (linux-6.2.0-39-generic-glibc2.37)",
    "uid": "aa753751fba74ec0",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config/bert-large-pruned80_quant-none-vnni-bert-99/singlestream",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.4308347276475,
    "Accuracy_div_100": 0.90431,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config/mobilebert-14layer_pruned50-none-vnni-bert-99/singlestream",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-14layer_pruned50-none-vnni-bert-99",
    "Organization": "CTuning",
    "Platform": "GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 8.510294,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "GATE Overflow Intel Sapphire Rapids",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.6.2. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.04 (linux-6.2.0-39-generic-glibc2.37)",
    "uid": "ca8f12da02834935",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config/mobilebert-14layer_pruned50-none-vnni-bert-99/singlestream",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.40462194474198,
    "Accuracy_div_100": 0.90405,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config/mobilebert-14layer_pruned50_quant-none-vnni-bert-99/singlestream",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-14layer_pruned50_quant-none-vnni-bert-99",
    "Organization": "CTuning",
    "Platform": "GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 5.166326,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "GATE Overflow Intel Sapphire Rapids",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.6.2. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.04 (linux-6.2.0-39-generic-glibc2.37)",
    "uid": "a3454f90cc1e48d5",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config/mobilebert-14layer_pruned50_quant-none-vnni-bert-99/singlestream",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.79584822581347,
    "Accuracy_div_100": 0.90796,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config/mobilebert-base_quant-none-bert-99/singlestream",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-base_quant-none-bert-99",
    "Organization": "CTuning",
    "Platform": "GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 16.293047,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "GATE Overflow Intel Sapphire Rapids",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.6.2. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.04 (linux-6.2.0-39-generic-glibc2.37)",
    "uid": "97a511100735428d",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config/mobilebert-base_quant-none-bert-99/singlestream",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.89066465550044,
    "Accuracy_div_100": 0.90891,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config/mobilebert-none-base-none-bert-99/singlestream",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-none-base-none-bert-99",
    "Organization": "CTuning",
    "Platform": "GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 19.189883,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "GATE Overflow Intel Sapphire Rapids",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.6.2. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.04 (linux-6.2.0-39-generic-glibc2.37)",
    "uid": "a110883ab2864a1a",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config/mobilebert-none-base-none-bert-99/singlestream",
    "version": "v4.0"
  },
  {
    "Accuracy": 88.31078542237867,
    "Accuracy_div_100": 0.88311,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config/obert-base-pruned90-none-bert-99/singlestream",
    "MlperfModel": "bert-99",
    "Model": "obert-base-pruned90-none-bert-99",
    "Organization": "CTuning",
    "Platform": "GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 13.547493,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "GATE Overflow Intel Sapphire Rapids",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.6.2. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.04 (linux-6.2.0-39-generic-glibc2.37)",
    "uid": "aff1f8bafcb34e9e",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config/obert-base-pruned90-none-bert-99/singlestream",
    "version": "v4.0"
  },
  {
    "Accuracy": 89.65191480026783,
    "Accuracy_div_100": 0.89652,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config/obert-large-base-none-bert-99/singlestream",
    "MlperfModel": "bert-99",
    "Model": "obert-large-base-none-bert-99",
    "Organization": "CTuning",
    "Platform": "GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 95.048213,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "GATE Overflow Intel Sapphire Rapids",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.6.2. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.04 (linux-6.2.0-39-generic-glibc2.37)",
    "uid": "f8e4748fa9c24030",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config/obert-large-base-none-bert-99/singlestream",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.17832662822171,
    "Accuracy_div_100": 0.90178,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned95-none-vnni-bert-99/singlestream",
    "MlperfModel": "bert-99",
    "Model": "obert-large-pruned95-none-vnni-bert-99",
    "Organization": "CTuning",
    "Platform": "GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 31.513634,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "GATE Overflow Intel Sapphire Rapids",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.6.2. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.04 (linux-6.2.0-39-generic-glibc2.37)",
    "uid": "af6a33f508c54b14",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned95-none-vnni-bert-99/singlestream",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.0299132434367,
    "Accuracy_div_100": 0.9003,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned95_quant-none-vnni-bert-99/singlestream",
    "MlperfModel": "bert-99",
    "Model": "obert-large-pruned95_quant-none-vnni-bert-99",
    "Organization": "CTuning",
    "Platform": "GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 16.095451,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "GATE Overflow Intel Sapphire Rapids",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.6.2. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.04 (linux-6.2.0-39-generic-glibc2.37)",
    "uid": "c689c29ba6ee4dff",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned95_quant-none-vnni-bert-99/singlestream",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.1356467730578,
    "Accuracy_div_100": 0.90136,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned97-none-bert-99/singlestream",
    "MlperfModel": "bert-99",
    "Model": "obert-large-pruned97-none-bert-99",
    "Organization": "CTuning",
    "Platform": "GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 27.207798,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "GATE Overflow Intel Sapphire Rapids",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.6.2. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.04 (linux-6.2.0-39-generic-glibc2.37)",
    "uid": "23bd0d94724847ba",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned97-none-bert-99/singlestream",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.1810702860831,
    "Accuracy_div_100": 0.90181,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned97-quant-none-bert-99/singlestream",
    "MlperfModel": "bert-99",
    "Model": "obert-large-pruned97-quant-none-bert-99",
    "Organization": "CTuning",
    "Platform": "GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 24.45344,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "GATE Overflow Intel Sapphire Rapids",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.6.2. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.04 (linux-6.2.0-39-generic-glibc2.37)",
    "uid": "0643a08b2a614000",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned97-quant-none-bert-99/singlestream",
    "version": "v4.0"
  },
  {
    "Accuracy": 42.9604,
    "Accuracy_div_100": 0.4296,
    "Availability": "available",
    "Division": "open",
    "Location": "open/TTA/results/KR580S1-A100-SXM-40GB-pytorch-v2.0.1-default_config/gptj-99/singlestream",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "TTA",
    "Platform": "KR580S1-A100-SXM-40GB-pytorch-v2.0.1-default_config",
    "Result": 5250.468665,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "KR580S1",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA A100-PCIe-40GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "pytorch v2.0.1",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 36,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6140 CPU @ 2.30GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Powered by MLCommons Collective Mind framework (CK2). ",
    "number_of_nodes": 1,
    "operating_system": "Centos 8 (linux-4.18.0-500.el8.x86_64-glibc2.28)",
    "uid": "44bec385b9d04eed",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/open/TTA/results/KR580S1-A100-SXM-40GB-pytorch-v2.0.1-default_config/gptj-99/singlestream",
    "version": "v3.1"
  },
  {
    "Accuracy": 43.1778,
    "Accuracy_div_100": 0.43178,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/amd_zen4_workstation-reference-gpu-pytorch-v2.0.1-default_config/gptj-99/singlestream",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "CTuning",
    "Platform": "amd_zen4_workstation-reference-gpu-pytorch-v2.0.1-default_config",
    "Result": 5387.449249,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "PCSPECIALIST AMD AM5 PC with Nvidia RTX 4090",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090 (Ada Lovelace)",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "MLCommons reference implementation with CM API, Pytorch v2.0.1",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by MLCommons CM automation language and CK playground. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.19.0-46-generic-glibc2.35)",
    "uid": "fcc5fa14af9a41e8",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/open/CTuning/results/amd_zen4_workstation-reference-gpu-pytorch-v2.0.1-default_config/gptj-99/singlestream",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.41225790876659,
    "Accuracy_div_100": 0.90412,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/fac1ca4b1b6b-nvidia_original-gpu-tensorrt-vdefault-default_config/bert-99/singlestream",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "CTuning",
    "Platform": "fac1ca4b1b6b-nvidia_original-gpu-tensorrt-vdefault-default_config",
    "Result": 9.11351,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "Dell Precision 14 5470 Mobile Workstation",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA RTX A1000",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Nvidia inference implementation with CM API, TensorRT v8.6.1.6",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 14,
    "host_processor_model_name": "12th Gen Intel(R) Core(TM) i7-12800H",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Result submitted by Jose Armando Hernandez. Powered by MLCommons CM automation language and CK playground",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.19.0-50-generic-glibc2.35)",
    "uid": "ab5bcb488056445e",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/open/CTuning/results/fac1ca4b1b6b-nvidia_original-gpu-tensorrt-vdefault-default_config/bert-99/singlestream",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.87487229720105,
    "Accuracy_div_100": 0.90875,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/jose_Precision_14_5470-reference-gpu-onnxruntime-v1.15.1-default_config/bert-99/singlestream",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "CTuning",
    "Platform": "jose_Precision_14_5470-reference-gpu-onnxruntime-v1.15.1-default_config",
    "Result": 519.059036,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "Dell Precision 14 5470 Mobile Workstation",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA RTX A1000",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "MLCommons reference implementation with CM API, Onnxruntime v1.15.1",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 14,
    "host_processor_model_name": "12th Gen Intel(R) Core(TM) i7-12800H",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": " Result taken by Jose Armando Hernandez. Powered by MLCommons CM automation language and CK playground. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.19.0-46-generic-glibc2.35)",
    "uid": "a1c115777fa9439d",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/open/CTuning/results/jose_Precision_14_5470-reference-gpu-onnxruntime-v1.15.1-default_config/bert-99/singlestream",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.87487229720105,
    "Accuracy_div_100": 0.90875,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/fac1ca4b1b6b-reference-gpu-onnxruntime-v1.15.1-default_config/bert-99/singlestream",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "CTuning",
    "Platform": "fac1ca4b1b6b-reference-gpu-onnxruntime-v1.15.1-default_config",
    "Result": 519.059036,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "Dell Precision 14 5470 Mobile Workstation",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA RTX A1000",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "MLCommons reference implementation with CM API, Onnxruntime v1.15.1",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 14,
    "host_processor_model_name": "12th Gen Intel(R) Core(TM) i7-12800H",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Result submitted by Jose Armando Hernandez. Powered by MLCommons CM automation language and CK playground",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.19.0-50-generic-glibc2.35)",
    "uid": "83fa6fc7c9fd4103",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/open/CTuning/results/fac1ca4b1b6b-reference-gpu-onnxruntime-v1.15.1-default_config/bert-99/singlestream",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.8897262883197,
    "Accuracy_div_100": 0.9089,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/amd_ryzen_workstation-reference-cpu-onnxruntime-v1.15.1-default_config/pruned-bert-99/singlestream",
    "MlperfModel": "bert-99",
    "Model": "pruned-bert-99",
    "Organization": "CTuning",
    "Platform": "amd_ryzen_workstation-reference-cpu-onnxruntime-v1.15.1-default_config",
    "Result": 344.888105,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "PCSPECIALIST AMD AM5 PC",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "MLCommons reference implementation with CM API, Onnxruntime v1.15.1",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by MLCommons CM automation language and CK playground. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.19.0-50-generic-glibc2.35)",
    "uid": "f552a571e14f4526",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/open/CTuning/results/amd_ryzen_workstation-reference-cpu-onnxruntime-v1.15.1-default_config/pruned-bert-99/singlestream",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.32072989985656,
    "Accuracy_div_100": 0.90321,
    "Availability": "available",
    "Division": "open",
    "Location": "open/NeuralMagic/results/nm80ci_icx_deepsparse/bert-99_obert-mobilebert/SingleStream",
    "MlperfModel": "bert-99",
    "Model": "bert-99_obert-mobilebert",
    "Organization": "NeuralMagic",
    "Platform": "nm80ci_icx_deepsparse",
    "Result": 5.443248,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "NM80ci_ICX (2x Intel Xeon 8380, DeepSparse)",
    "SystemType": "edge,datacenter",
    "Units": "Latency (ms)",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "DeepSparse",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380 CPU @ 2.30GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "DeepSparse 1.0.2, Python 3.9.13, GCC 11.2.0",
    "number_of_nodes": 1,
    "operating_system": " Ubuntu 22.04 LTS",
    "uid": "b92c56e084ca4645",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/open/NeuralMagic/results/nm80ci_icx_deepsparse/bert-99_obert-mobilebert/SingleStream",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.41656583679988,
    "Accuracy_div_100": 0.90417,
    "Availability": "available",
    "Division": "open",
    "Location": "open/NeuralMagic/results/nm80ci_icx_deepsparse/bert-99_prune-ofa-large/SingleStream",
    "MlperfModel": "bert-99",
    "Model": "bert-99_prune-ofa-large",
    "Organization": "NeuralMagic",
    "Platform": "nm80ci_icx_deepsparse",
    "Result": 21.977228,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "NM80ci_ICX (2x Intel Xeon 8380, DeepSparse)",
    "SystemType": "edge,datacenter",
    "Units": "Latency (ms)",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "DeepSparse",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380 CPU @ 2.30GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "DeepSparse 1.0.2, Python 3.9.13, GCC 11.2.0",
    "number_of_nodes": 1,
    "operating_system": " Ubuntu 22.04 LTS",
    "uid": "b383bd730ad843ec",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/open/NeuralMagic/results/nm80ci_icx_deepsparse/bert-99_prune-ofa-large/SingleStream",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.21282641816266,
    "Accuracy_div_100": 0.90213,
    "Availability": "available",
    "Division": "open",
    "Location": "open/NeuralMagic/results/nm80ci_icx_deepsparse/bert-99_obert-large/SingleStream",
    "MlperfModel": "bert-99",
    "Model": "bert-99_obert-large",
    "Organization": "NeuralMagic",
    "Platform": "nm80ci_icx_deepsparse",
    "Result": 16.887679,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "NM80ci_ICX (2x Intel Xeon 8380, DeepSparse)",
    "SystemType": "edge,datacenter",
    "Units": "Latency (ms)",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "DeepSparse",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380 CPU @ 2.30GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "DeepSparse 1.0.2, Python 3.9.13, GCC 11.2.0",
    "number_of_nodes": 1,
    "operating_system": " Ubuntu 22.04 LTS",
    "uid": "e6eabf8045e14414",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/open/NeuralMagic/results/nm80ci_icx_deepsparse/bert-99_obert-large/SingleStream",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.32506865037143,
    "Accuracy_div_100": 0.90325,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Krai/results/chai/bert-99_obert_mobilebert_50sparse_qat/singlestream",
    "MlperfModel": "bert-99",
    "Model": "bert-99_obert_mobilebert_50sparse_qat",
    "Organization": "Krai",
    "Platform": "chai",
    "Result": 28.823247,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "Dell Precision 7920 Tower (1x NVIDIA RTX A5000 GPU)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA RTX A5000",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "ONNX runtime v1.12 with GPU support",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6240R CPU @ 2.40GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by the KRAI X technology",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.1 LTS (Linux kernel: 5.19.0-32-generic #33~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Mon Jan 30 17:03:34 UTC 2)",
    "uid": "9b832e8aa6124651",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Krai/results/chai/bert-99_obert_mobilebert_50sparse_qat/singlestream",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.15897966063973,
    "Accuracy_div_100": 0.90159,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Krai/results/chai/bert-99_obert_large_95sparse_qat/singlestream",
    "MlperfModel": "bert-99",
    "Model": "bert-99_obert_large_95sparse_qat",
    "Organization": "Krai",
    "Platform": "chai",
    "Result": 125.587361,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "Dell Precision 7920 Tower (1x NVIDIA RTX A5000 GPU)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA RTX A5000",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "ONNX runtime v1.12 with GPU support",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6240R CPU @ 2.40GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by the KRAI X technology",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.1 LTS (Linux kernel: 5.19.0-32-generic #33~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Mon Jan 30 17:03:34 UTC 2)",
    "uid": "658a36dc6ad84a96",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Krai/results/chai/bert-99_obert_large_95sparse_qat/singlestream",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.67466754181211,
    "Accuracy_div_100": 0.90675,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Krai/results/chai/bert-99_bert_large_huggingface_bast/singlestream",
    "MlperfModel": "bert-99",
    "Model": "bert-99_bert_large_huggingface_bast",
    "Organization": "Krai",
    "Platform": "chai",
    "Result": 15.227221,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "Dell Precision 7920 Tower (1x NVIDIA RTX A5000 GPU)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA RTX A5000",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "ONNX runtime v1.12 with GPU support",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6240R CPU @ 2.40GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by the KRAI X technology",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.1 LTS (Linux kernel: 5.19.0-32-generic #33~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Mon Jan 30 17:03:34 UTC 2)",
    "uid": "54fa7bb4660042c1",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Krai/results/chai/bert-99_bert_large_huggingface_bast/singlestream",
    "version": "v3.0"
  },
  {
    "Accuracy": 91.0251156865308,
    "Accuracy_div_100": 0.91025,
    "Availability": "available",
    "Division": "open",
    "Location": "open/cTuning/results/gcp_n1_standard_4_nvidia_t4-reference-gpu-onnxruntime-v1.14.0-default_config/bert-99/singlestream",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "cTuning",
    "Platform": "gcp_n1_standard_4_nvidia_t4-reference-gpu-onnxruntime-v1.14.0-default_config",
    "Result": 80.878297,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "Google cloud instance n1-standard-4 (Debian 10)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "Tesla T4",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Onnxruntime v1.14.0 with GPU support",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "Intel(R) Xeon(R) CPU @ 2.30GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": " Result taken by Grigori Fursin. Powered by MLCommons Collective Mind framework (CK2). ",
    "number_of_nodes": 1,
    "operating_system": "Debian 10 (linux-4.19.0-23-cloud-amd64-glibc2.28)",
    "uid": "6a6d3fa42e7d4f14",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/cTuning/results/gcp_n1_standard_4_nvidia_t4-reference-gpu-onnxruntime-v1.14.0-default_config/bert-99/singlestream",
    "version": "v3.0"
  },
  {
    "Accuracy": 89.961820272891,
    "Accuracy_div_100": 0.89962,
    "Availability": "available",
    "Division": "open",
    "Location": "open/cTuning/results/gcp_n1_standard_4_nvidia_t4-reference-cpu-onnxruntime-v1.13.1-default_config/bert-99/singlestream",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "cTuning",
    "Platform": "gcp_n1_standard_4_nvidia_t4-reference-cpu-onnxruntime-v1.13.1-default_config",
    "Result": 952.839522,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "Google cloud instance n1-standard-4",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Onnxruntime v1.13.1",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "Intel(R) Xeon(R) CPU @ 2.30GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": " Result taken by Grigori Fursin. Powered by MLCommons Collective Mind framework (CK2). ",
    "number_of_nodes": 1,
    "operating_system": "Debian 10 (linux-4.19.0-23-cloud-amd64-glibc2.28)",
    "uid": "06147333fd3a42a1",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/cTuning/results/gcp_n1_standard_4_nvidia_t4-reference-cpu-onnxruntime-v1.13.1-default_config/bert-99/singlestream",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.81319248746797,
    "Accuracy_div_100": 0.90813,
    "Availability": "available",
    "Division": "open",
    "Location": "open/cTuning/results/gcp_n1_highmem_4_nvidia_k80-reference-gpu-onnxruntime-v1.14.0-default_config/bert-99/singlestream",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "cTuning",
    "Platform": "gcp_n1_highmem_4_nvidia_k80-reference-gpu-onnxruntime-v1.14.0-default_config",
    "Result": 151.153289,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "Google cloud instance n1-highmem-4 with Nvidia K80 GPU",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "Nvidia Tesla K80",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Onnxruntime v1.14.0 with GPU support",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "Intel(R) Xeon(R) CPU @ 2.30GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": " Result taken by Grigori Fursin. Powered by MLCommons Collective Mind framework (CK2). ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.15.0-1029-gcp-glibc2.35)",
    "uid": "ddca1b419dda452c",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/cTuning/results/gcp_n1_highmem_4_nvidia_k80-reference-gpu-onnxruntime-v1.14.0-default_config/bert-99/singlestream",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.70178690362079,
    "Accuracy_div_100": 0.90702,
    "Availability": "available",
    "Division": "open",
    "Location": "open/cTuning/results/gcp_n1_highmem_4_nvidia_k80-reference-gpu-tensorflow-v2.11.0-default_config/bert-99/singlestream",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "cTuning",
    "Platform": "gcp_n1_highmem_4_nvidia_k80-reference-gpu-tensorflow-v2.11.0-default_config",
    "Result": 193.78854,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "Google cloud instance n1-highmem-4 with Nvidia K80 GPU",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "Nvidia Tesla K80",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Onnxruntime v1.14.0 with GPU support",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "Intel(R) Xeon(R) CPU @ 2.30GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": " Result taken by Grigori Fursin. Powered by MLCommons Collective Mind framework (CK2). ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.15.0-1029-gcp-glibc2.35)",
    "uid": "92e43ffc8ed54091",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/cTuning/results/gcp_n1_highmem_4_nvidia_k80-reference-gpu-tensorflow-v2.11.0-default_config/bert-99/singlestream",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.82662393091758,
    "Accuracy_div_100": 0.90827,
    "Availability": "available",
    "Division": "open",
    "Location": "open/cTuning/results/gcp_n1_standard_4_nvidia_t4-reference-gpu-pytorch-v1.13.1-default_config/bert-99/singlestream",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "cTuning",
    "Platform": "gcp_n1_standard_4_nvidia_t4-reference-gpu-pytorch-v1.13.1-default_config",
    "Result": 95.731032,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "Google cloud instance n1-standard-4",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "Tesla T4",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Pytorch v1.13.1 with GPU support",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "Intel(R) Xeon(R) CPU @ 2.30GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": " Result taken by Grigori Fursin. Powered by MLCommons Collective Mind framework (CK2). ",
    "number_of_nodes": 1,
    "operating_system": "Debian 10 (linux-4.19.0-23-cloud-amd64-glibc2.28)",
    "uid": "22ae25127e054f6a",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/cTuning/results/gcp_n1_standard_4_nvidia_t4-reference-gpu-pytorch-v1.13.1-default_config/bert-99/singlestream",
    "version": "v3.0"
  }
]
