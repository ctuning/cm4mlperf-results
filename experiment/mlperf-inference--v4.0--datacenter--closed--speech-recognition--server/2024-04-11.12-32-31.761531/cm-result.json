[
  {
    "Accuracy": 92.56578502333763,
    "Accuracy_div_100": 0.92566,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC8000_E11P_H100x8_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "ASUSTeK",
    "Platform": "ESC8000_E11P_H100x8_TRT",
    "Result": 99973.3,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "ESC8000-E11P (8x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Data bandwidth for GPU-PCIe: 504 GB/s; PCIe-NIC: 126 GB/s",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "e3f2f92501304e4e",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/ASUSTeK/results/ESC8000_E11P_H100x8_TRT/rnnt/Server",
    "version": "v4.0"
  },
  {
    "Accuracy": 92.5567656542425,
    "Accuracy_div_100": 0.92557,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC8000_E11_L40Sx8_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "ASUSTeK",
    "Platform": "ESC8000_E11_L40Sx8_TRT",
    "Result": 87974.4,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "ESC8000-E11 (8x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6442Y",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Data bandwidth for GPU-PCIe: 252 GB/s; PCIe-NIC: 63 GB/s",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "0446200f71914980",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/ASUSTeK/results/ESC8000_E11_L40Sx8_TRT/rnnt/Server",
    "version": "v4.0"
  },
  {
    "Accuracy": 92.18020699452073,
    "Accuracy_div_100": 0.9218,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/1-node-2S-C240M7-EMR-PyTorch-MIX/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Cisco",
    "Platform": "1-node-2S-C240M7-EMR-PyTorch-MIX",
    "Result": 5797.6,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "1-node-2S-C240M7-EMR-PyTorch-MIX",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8592V",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "0ce43c73145a49d2",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Cisco/results/1-node-2S-C240M7-EMR-PyTorch-MIX/rnnt/Server",
    "version": "v4.0"
  },
  {
    "Accuracy": 92.5567656542425,
    "Accuracy_div_100": 0.92557,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R750xa_A100_PCIe_80GBx4_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Dell",
    "Platform": "R750xa_A100_PCIe_80GBx4_TRT",
    "Result": 49536.9,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge R750xa (4x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6338 CPU @ 2.00GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.1",
    "uid": "63cf1cfeb13741dc",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Dell/results/R750xa_A100_PCIe_80GBx4_TRT/rnnt/Server",
    "version": "v4.0"
  },
  {
    "Accuracy": 92.5567656542425,
    "Accuracy_div_100": 0.92557,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760xa_L40Sx4_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Dell",
    "Platform": "R760xa_L40Sx4_TRT",
    "Result": 42237.1,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge R760xa (4x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6338 CPU @ 2.00GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.1",
    "uid": "c48b152daf8043f3",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Dell/results/R760xa_L40Sx4_TRT/rnnt/Server",
    "version": "v4.0"
  },
  {
    "Accuracy": 92.18020699452073,
    "Accuracy_div_100": 0.9218,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760_CPU/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Dell",
    "Platform": "R760_CPU",
    "Result": 5797.6,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge R760",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "INT4 for GPT-J, Mixed for RNN-T and INT8 for all other models",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream 8",
    "uid": "e8c7c9c9ec4c450c",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Dell/results/R760_CPU/rnnt/Server",
    "version": "v4.0"
  },
  {
    "Accuracy": 92.55225596969493,
    "Accuracy_div_100": 0.92552,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760_L40Sx2_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Dell",
    "Platform": "R760_L40Sx2_TRT",
    "Result": 21746.7,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge R760 (2x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.3",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 120,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8580",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "uid": "92055affafce46c5",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Dell/results/R760_L40Sx2_TRT/rnnt/Server",
    "version": "v4.0"
  },
  {
    "Accuracy": 92.5545108119687,
    "Accuracy_div_100": 0.92555,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R7615_L40Sx2_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Dell",
    "Platform": "R7615_L40Sx2_TRT",
    "Result": 22347.7,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge R7615 (2x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 9354 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6 LTS",
    "uid": "fe6063ed3d05491d",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Dell/results/R7615_L40Sx2_TRT/rnnt/Server",
    "version": "v4.0"
  },
  {
    "Accuracy": 92.5545108119687,
    "Accuracy_div_100": 0.92555,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/vR760_L40S_48Cx2_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Dell",
    "Platform": "vR760_L40S_48Cx2_TRT",
    "Result": 20546.3,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge R760 (2x L40S, TensorRT, VMware ESXi 8.0.2)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "Virtualized NVIDIA L40S",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 60,
    "host_processor_model_name": "Intel Xeon Platinum 8580",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Broadcom VM Specifications 32vCPU out of 120 and memory of 128 GB out of 1.5TB",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4, VMware ESXi 8.0.2 22380479",
    "uid": "175bf3e56110430f",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Dell/results/vR760_L40S_48Cx2_TRT/rnnt/Server",
    "version": "v4.0"
  },
  {
    "Accuracy": 92.56578502333763,
    "Accuracy_div_100": 0.92566,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Dell",
    "Platform": "XE8640_H100_SXM_80GBx4_TRT",
    "Result": 96966.3,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XE8640 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "uid": "9af7c2564f594da7",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/rnnt/Server",
    "version": "v4.0"
  },
  {
    "Accuracy": 92.56578502333763,
    "Accuracy_div_100": 0.92566,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9640_H100_SXM_80GBX4_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Dell",
    "Platform": "XE9640_H100_SXM_80GBX4_TRT",
    "Result": 92103.4,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XE9640 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "f155a0bbca7e4acc",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Dell/results/XE9640_H100_SXM_80GBX4_TRT/rnnt/Server",
    "version": "v4.0"
  },
  {
    "Accuracy": 92.56578502333763,
    "Accuracy_div_100": 0.92566,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Dell",
    "Platform": "XE9680_H100_SXM_80GBx8_TRT",
    "Result": 187291,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XE9680 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "6ac4ca33665a4f6b",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/rnnt/Server",
    "version": "v4.0"
  },
  {
    "Accuracy": 92.56578502333763,
    "Accuracy_div_100": 0.92566,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/GigaComputing/results/GIGABYTE-G593-SD1_DGX-H100_H100-SXM-80GBx8_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "GigaComputing",
    "Platform": "GIGABYTE-G593-SD1_DGX-H100_H100-SXM-80GBx8_TRT",
    "Result": 179985,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "GIGABYTE G593-SD1",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Data bandwidth for GPU-PCIe: 504 GB/s; PCIe-NIC: 600GB/s",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "e8f0fe325ff94bdf",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/GigaComputing/results/GIGABYTE-G593-SD1_DGX-H100_H100-SXM-80GBx8_TRT/rnnt/Server",
    "version": "v4.0"
  },
  {
    "Accuracy": 92.56578502333763,
    "Accuracy_div_100": 0.92566,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "HPE",
    "Platform": "HPE_Cray_XD670_H100_SXM_80GBx8_TRT_TRT",
    "Result": 179985,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "HPE Cray XD670 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.3",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.3",
    "uid": "d7b35645ba0b40cf",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT_TRT/rnnt/Server",
    "version": "v4.0"
  },
  {
    "Accuracy": 92.56578502333763,
    "Accuracy_div_100": 0.92566,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_ProLiant_DL380a_H100_PCIe_80GBx4_TRT_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "HPE",
    "Platform": "HPE_ProLiant_DL380a_H100_PCIe_80GBx4_TRT_TRT",
    "Result": 68084.4,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "HPE ProLiant DL380a Gen11 (4x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "ab41f1f671c148e6",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/HPE/results/HPE_ProLiant_DL380a_H100_PCIe_80GBx4_TRT_TRT/rnnt/Server",
    "version": "v4.0"
  },
  {
    "Accuracy": 92.5545108119687,
    "Accuracy_div_100": 0.92555,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "HPE",
    "Platform": "HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT",
    "Result": 34191,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "HPE ProLiant DL380a Gen11 (4x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 60,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8580",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "342079d0c3a34798",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/HPE/results/HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT/rnnt/Server",
    "version": "v4.0"
  },
  {
    "Accuracy": 92.18020699452073,
    "Accuracy_div_100": 0.9218,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Intel/results/1-node-2S-EMR-PyTorch/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Intel",
    "Platform": "1-node-2S-EMR-PyTorch",
    "Result": 5797.6,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "1-node-2S-EMR-PyTorch",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54Q-2U. N/A",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream 8",
    "uid": "304eda09163045cd",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Intel/results/1-node-2S-EMR-PyTorch/rnnt/Server",
    "version": "v4.0"
  },
  {
    "Accuracy": 92.55225596969493,
    "Accuracy_div_100": 0.92552,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/SE455_L40x2_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Lenovo",
    "Platform": "SE455_L40x2_TRT",
    "Result": 16697,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Lenovo SE455 (2x NVIDIA L40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.3",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "AMD EPYC 8124P 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "c4a2788b0eac4cc8",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Lenovo/results/SE455_L40x2_TRT/rnnt/Server",
    "version": "v4.0"
  },
  {
    "Accuracy": 92.56127533879005,
    "Accuracy_div_100": 0.92561,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx1_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "NVIDIA",
    "Platform": "DGX-H100_H100-SXM-80GBx1_TRT",
    "Result": 21996.9,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NVIDIA DGX H100 (1x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "6f5ef02bb04b4bbc",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx1_TRT/rnnt/Server",
    "version": "v4.0"
  },
  {
    "Accuracy": 92.56578502333763,
    "Accuracy_div_100": 0.92566,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "NVIDIA",
    "Platform": "DGX-H100_H100-SXM-80GBx8_TRT",
    "Result": 175983,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "858ee8f0c8d84c67",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/rnnt/Server",
    "version": "v4.0"
  },
  {
    "Accuracy": 92.56578502333763,
    "Accuracy_div_100": 0.92566,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Oracle/results/OCI-H100_H100-SXM-80GBx8_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Oracle",
    "Platform": "OCI-H100_H100-SXM-80GBx8_TRT",
    "Result": 143986,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "BM.GPU.H100.8",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0.1, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "3831170dfd444edd",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Oracle/results/OCI-H100_H100-SXM-80GBx8_TRT/rnnt/Server",
    "version": "v4.0"
  },
  {
    "Accuracy": 92.18020699452073,
    "Accuracy_div_100": 0.9218,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/1-node-2S-EMR-PyTorch/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "1-node-2S-EMR-PyTorch",
    "Result": 5797.6,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "1-node-2S-EMR-PyTorch-INT8",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": "N/A",
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54X-1U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.1",
    "uid": "36bf5eb6df9c429b",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Quanta_Cloud_Technology/results/1-node-2S-EMR-PyTorch/rnnt/Server",
    "version": "v4.0"
  },
  {
    "Accuracy": 92.5680398656114,
    "Accuracy_div_100": 0.92568,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/D54U_3U_H100_PCIe_80GBx4_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "D54U_3U_H100_PCIe_80GBx4_TRT",
    "Result": 59982.6,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "D54U_3U_H100_PCIe_80GBx4_TRT",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.3",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54U-3U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.2",
    "uid": "d4fb078762474043",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Quanta_Cloud_Technology/results/D54U_3U_H100_PCIe_80GBx4_TRT/rnnt/Server",
    "version": "v4.0"
  },
  {
    "Accuracy": 92.5567656542425,
    "Accuracy_div_100": 0.92557,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/D54U_3U_L40S_PCIe_48GBx4_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "D54U_3U_L40S_PCIe_48GBx4_TRT",
    "Result": 39985.9,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "D54U_3U_L40S_PCIe_48GBx4_TRT",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.3",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54U-3U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.2",
    "uid": "675f847605f342c4",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Quanta_Cloud_Technology/results/D54U_3U_L40S_PCIe_48GBx4_TRT/rnnt/Server",
    "version": "v4.0"
  },
  {
    "Accuracy": 92.56578502333763,
    "Accuracy_div_100": 0.92566,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Supermicro",
    "Platform": "SYS_821GE_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 175983,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "SYS-821GE-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8568Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3 LTS",
    "uid": "46db25d7648140d4",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/rnnt/Server",
    "version": "v4.0"
  },
  {
    "Accuracy": 92.18020699452073,
    "Accuracy_div_100": 0.9218,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Wiwynn/results/1-node-1S-EMR-PyTorch/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Wiwynn",
    "Platform": "1-node-1S-EMR-PyTorch",
    "Result": 1448.78,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Wiwynn ES200G2 (1-node-1S-EMR-PyTorch)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "INTEL(R) XEON(R) GOLD 6538Y+",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Wiwynn ES200G2. N/A",
    "number_of_nodes": 1,
    "operating_system": "Centos 8 (linux-6.6.8-1.el8.elrepo.x86_64-glibc2.28)",
    "uid": "053dad1bedca4bdb",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Wiwynn/results/1-node-1S-EMR-PyTorch/rnnt/Server",
    "version": "v4.0"
  }
]
