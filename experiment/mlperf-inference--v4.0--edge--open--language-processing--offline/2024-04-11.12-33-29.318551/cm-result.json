[
  {
    "Accuracy": 88.42042174998099,
    "Accuracy_div_100": 0.8842,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config/bert-base-pruned90-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-base-pruned90-none-bert-99",
    "Organization": "CTuning",
    "Platform": "AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 24.8239,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "TRIGKEY Mini PC Ryzen 5 5560",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 6,
    "host_processor_model_name": "AMD Ryzen 5 5560U with Radeon Graphics",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.5.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.10 (linux-6.5.0-17-generic-glibc2.38)",
    "uid": "d74858dc706c4cfe",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config/bert-base-pruned90-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 87.88571389692375,
    "Accuracy_div_100": 0.87886,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config/bert-base-pruned95_obs_quant-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-base-pruned95_obs_quant-none-bert-99",
    "Organization": "CTuning",
    "Platform": "AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 57.2763,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "TRIGKEY Mini PC Ryzen 5 5560",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 6,
    "host_processor_model_name": "AMD Ryzen 5 5560U with Radeon Graphics",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.5.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.10 (linux-6.5.0-17-generic-glibc2.38)",
    "uid": "44d01b6d6f464dd0",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config/bert-base-pruned95_obs_quant-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 89.65191480026783,
    "Accuracy_div_100": 0.89652,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config/bert-large-base-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-large-base-none-bert-99",
    "Organization": "CTuning",
    "Platform": "AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 2.51275,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "TRIGKEY Mini PC Ryzen 5 5560",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 6,
    "host_processor_model_name": "AMD Ryzen 5 5560U with Radeon Graphics",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.5.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.10 (linux-6.5.0-17-generic-glibc2.38)",
    "uid": "93f762e8445947d9",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config/bert-large-base-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.29174382621062,
    "Accuracy_div_100": 0.90292,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config/bert-large-pruned80_quant-none-vnni-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-large-pruned80_quant-none-vnni-bert-99",
    "Organization": "CTuning",
    "Platform": "AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 11.2458,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "TRIGKEY Mini PC Ryzen 5 5560",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 6,
    "host_processor_model_name": "AMD Ryzen 5 5560U with Radeon Graphics",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.5.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.10 (linux-6.5.0-17-generic-glibc2.38)",
    "uid": "43ebd14ed20f441f",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config/bert-large-pruned80_quant-none-vnni-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.4308347276475,
    "Accuracy_div_100": 0.90431,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config/mobilebert-14layer_pruned50-none-vnni-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-14layer_pruned50-none-vnni-bert-99",
    "Organization": "CTuning",
    "Platform": "AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 55.8759,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "TRIGKEY Mini PC Ryzen 5 5560",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 6,
    "host_processor_model_name": "AMD Ryzen 5 5560U with Radeon Graphics",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.5.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.10 (linux-6.5.0-17-generic-glibc2.38)",
    "uid": "18c23cfeeb964ebd",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config/mobilebert-14layer_pruned50-none-vnni-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.36718210138123,
    "Accuracy_div_100": 0.90367,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config/mobilebert-14layer_pruned50_quant-none-vnni-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-14layer_pruned50_quant-none-vnni-bert-99",
    "Organization": "CTuning",
    "Platform": "AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 87.0337,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "TRIGKEY Mini PC Ryzen 5 5560",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 6,
    "host_processor_model_name": "AMD Ryzen 5 5560U with Radeon Graphics",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.5.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.10 (linux-6.5.0-17-generic-glibc2.38)",
    "uid": "caf53d5b75c94d06",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config/mobilebert-14layer_pruned50_quant-none-vnni-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.81268530031994,
    "Accuracy_div_100": 0.90813,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config/mobilebert-base_quant-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-base_quant-none-bert-99",
    "Organization": "CTuning",
    "Platform": "AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 41.0727,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "TRIGKEY Mini PC Ryzen 5 5560",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 6,
    "host_processor_model_name": "AMD Ryzen 5 5560U with Radeon Graphics",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.5.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.10 (linux-6.5.0-17-generic-glibc2.38)",
    "uid": "29443220354046d9",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config/mobilebert-base_quant-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.89066465550044,
    "Accuracy_div_100": 0.90891,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config/mobilebert-none-base-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-none-base-none-bert-99",
    "Organization": "CTuning",
    "Platform": "AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 29.9816,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "TRIGKEY Mini PC Ryzen 5 5560",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 6,
    "host_processor_model_name": "AMD Ryzen 5 5560U with Radeon Graphics",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.5.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.10 (linux-6.5.0-17-generic-glibc2.38)",
    "uid": "a73ea5fb5f8445a7",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config/mobilebert-none-base-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 88.31078542237867,
    "Accuracy_div_100": 0.88311,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config/obert-base-pruned90-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-base-pruned90-none-bert-99",
    "Organization": "CTuning",
    "Platform": "AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 24.5669,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "TRIGKEY Mini PC Ryzen 5 5560",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 6,
    "host_processor_model_name": "AMD Ryzen 5 5560U with Radeon Graphics",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.5.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.10 (linux-6.5.0-17-generic-glibc2.38)",
    "uid": "56336c7a0c4244dd",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config/obert-base-pruned90-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 89.65191480026783,
    "Accuracy_div_100": 0.89652,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config/obert-large-base-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-large-base-none-bert-99",
    "Organization": "CTuning",
    "Platform": "AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 2.51694,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "TRIGKEY Mini PC Ryzen 5 5560",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 6,
    "host_processor_model_name": "AMD Ryzen 5 5560U with Radeon Graphics",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.5.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.10 (linux-6.5.0-17-generic-glibc2.38)",
    "uid": "746dc7a8856548ff",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config/obert-large-base-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.17832662822171,
    "Accuracy_div_100": 0.90178,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned95-none-vnni-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-large-pruned95-none-vnni-bert-99",
    "Organization": "CTuning",
    "Platform": "AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 11.5058,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "TRIGKEY Mini PC Ryzen 5 5560",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 6,
    "host_processor_model_name": "AMD Ryzen 5 5560U with Radeon Graphics",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.5.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.10 (linux-6.5.0-17-generic-glibc2.38)",
    "uid": "fdd2a92d2a424c61",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned95-none-vnni-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.01097011863615,
    "Accuracy_div_100": 0.90011,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned95_quant-none-vnni-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-large-pruned95_quant-none-vnni-bert-99",
    "Organization": "CTuning",
    "Platform": "AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 20.9442,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "TRIGKEY Mini PC Ryzen 5 5560",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 6,
    "host_processor_model_name": "AMD Ryzen 5 5560U with Radeon Graphics",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.5.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.10 (linux-6.5.0-17-generic-glibc2.38)",
    "uid": "8bf7b19b51084196",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned95_quant-none-vnni-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.1356467730578,
    "Accuracy_div_100": 0.90136,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned97-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-large-pruned97-none-bert-99",
    "Organization": "CTuning",
    "Platform": "AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 12.9379,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "TRIGKEY Mini PC Ryzen 5 5560",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 6,
    "host_processor_model_name": "AMD Ryzen 5 5560U with Radeon Graphics",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.5.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.10 (linux-6.5.0-17-generic-glibc2.38)",
    "uid": "4fbc8fae2a0e41a1",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned97-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.14276789144404,
    "Accuracy_div_100": 0.90143,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned97-quant-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-large-pruned97-quant-none-bert-99",
    "Organization": "CTuning",
    "Platform": "AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 17.6165,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "TRIGKEY Mini PC Ryzen 5 5560",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 6,
    "host_processor_model_name": "AMD Ryzen 5 5560U with Radeon Graphics",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.5.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.10 (linux-6.5.0-17-generic-glibc2.38)",
    "uid": "10eed5c102ac4dbc",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned97-quant-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 88.42042174998099,
    "Accuracy_div_100": 0.8842,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/aws_c5.2xlarge-reference-cpu-deepsparse-vdefault-default_config/bert-base-pruned90-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-base-pruned90-none-bert-99",
    "Organization": "CTuning",
    "Platform": "aws_c5.2xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 27.004,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance c5.2xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8275CL CPU @ 3.00GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-1017-aws-glibc2.35)",
    "uid": "1d718b7b65d54671",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/aws_c5.2xlarge-reference-cpu-deepsparse-vdefault-default_config/bert-base-pruned90-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 87.89212297504716,
    "Accuracy_div_100": 0.87892,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/aws_c5.2xlarge-reference-cpu-deepsparse-vdefault-default_config/bert-base-pruned95_obs_quant-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-base-pruned95_obs_quant-none-bert-99",
    "Organization": "CTuning",
    "Platform": "aws_c5.2xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 44.7662,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance c5.2xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8275CL CPU @ 3.00GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-1017-aws-glibc2.35)",
    "uid": "3545d62f6a7c4964",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/aws_c5.2xlarge-reference-cpu-deepsparse-vdefault-default_config/bert-base-pruned95_obs_quant-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.4308347276475,
    "Accuracy_div_100": 0.90431,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/aws_c5.2xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-14layer_pruned50-none-vnni-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-14layer_pruned50-none-vnni-bert-99",
    "Organization": "CTuning",
    "Platform": "aws_c5.2xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 64.134,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance c5.2xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8275CL CPU @ 3.00GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-1017-aws-glibc2.35)",
    "uid": "b7df4ca87b2c47e5",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/aws_c5.2xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-14layer_pruned50-none-vnni-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.40462194474198,
    "Accuracy_div_100": 0.90405,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/aws_c5.2xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-14layer_pruned50_quant-none-vnni-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-14layer_pruned50_quant-none-vnni-bert-99",
    "Organization": "CTuning",
    "Platform": "aws_c5.2xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 90.0017,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance c5.2xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8275CL CPU @ 3.00GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-1017-aws-glibc2.35)",
    "uid": "da3cdd5bf4c54404",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/aws_c5.2xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-14layer_pruned50_quant-none-vnni-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.7887526723603,
    "Accuracy_div_100": 0.90789,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/aws_c5.2xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-base_quant-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-base_quant-none-bert-99",
    "Organization": "CTuning",
    "Platform": "aws_c5.2xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 33.1638,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance c5.2xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8275CL CPU @ 3.00GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-1017-aws-glibc2.35)",
    "uid": "3539723ad85a4fb2",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/aws_c5.2xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-base_quant-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.89066465550044,
    "Accuracy_div_100": 0.90891,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/aws_c5.2xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-none-base-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-none-base-none-bert-99",
    "Organization": "CTuning",
    "Platform": "aws_c5.2xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 32.9594,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance c5.2xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8275CL CPU @ 3.00GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-1017-aws-glibc2.35)",
    "uid": "f78e3a67ada24f9d",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/aws_c5.2xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-none-base-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 88.31078542237867,
    "Accuracy_div_100": 0.88311,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/aws_c5.2xlarge-reference-cpu-deepsparse-vdefault-default_config/obert-base-pruned90-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-base-pruned90-none-bert-99",
    "Organization": "CTuning",
    "Platform": "aws_c5.2xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 26.7835,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance c5.2xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8275CL CPU @ 3.00GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-1017-aws-glibc2.35)",
    "uid": "898260dbbda64a6d",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/aws_c5.2xlarge-reference-cpu-deepsparse-vdefault-default_config/obert-base-pruned90-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 88.42042174998099,
    "Accuracy_div_100": 0.8842,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/aws_c5.xlarge-reference-cpu-deepsparse-vdefault-default_config/bert-base-pruned90-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-base-pruned90-none-bert-99",
    "Organization": "CTuning",
    "Platform": "aws_c5.xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 13.0995,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance c5.xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 2,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8124M CPU @ 3.00GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-1017-aws-glibc2.35)",
    "uid": "2b75685d59264d9d",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/aws_c5.xlarge-reference-cpu-deepsparse-vdefault-default_config/bert-base-pruned90-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 87.89212297504716,
    "Accuracy_div_100": 0.87892,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/aws_c5.xlarge-reference-cpu-deepsparse-vdefault-default_config/bert-base-pruned95_obs_quant-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-base-pruned95_obs_quant-none-bert-99",
    "Organization": "CTuning",
    "Platform": "aws_c5.xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 23.1141,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance c5.xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 2,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8124M CPU @ 3.00GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-1017-aws-glibc2.35)",
    "uid": "873a712875b948c8",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/aws_c5.xlarge-reference-cpu-deepsparse-vdefault-default_config/bert-base-pruned95_obs_quant-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.4308347276475,
    "Accuracy_div_100": 0.90431,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/aws_c5.xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-14layer_pruned50-none-vnni-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-14layer_pruned50-none-vnni-bert-99",
    "Organization": "CTuning",
    "Platform": "aws_c5.xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 32.9884,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance c5.xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 2,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8124M CPU @ 3.00GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-1017-aws-glibc2.35)",
    "uid": "206e193d0dc34bca",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/aws_c5.xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-14layer_pruned50-none-vnni-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.40462194474198,
    "Accuracy_div_100": 0.90405,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/aws_c5.xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-14layer_pruned50_quant-none-vnni-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-14layer_pruned50_quant-none-vnni-bert-99",
    "Organization": "CTuning",
    "Platform": "aws_c5.xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 47.1924,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance c5.xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 2,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8124M CPU @ 3.00GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-1017-aws-glibc2.35)",
    "uid": "cdb459c263374257",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/aws_c5.xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-14layer_pruned50_quant-none-vnni-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.7887526723603,
    "Accuracy_div_100": 0.90789,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/aws_c5.xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-base_quant-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-base_quant-none-bert-99",
    "Organization": "CTuning",
    "Platform": "aws_c5.xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 17.0601,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance c5.xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 2,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8124M CPU @ 3.00GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-1017-aws-glibc2.35)",
    "uid": "2f698a1922374b25",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/aws_c5.xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-base_quant-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.89066465550044,
    "Accuracy_div_100": 0.90891,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/aws_c5.xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-none-base-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-none-base-none-bert-99",
    "Organization": "CTuning",
    "Platform": "aws_c5.xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 16.9837,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance c5.xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 2,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8124M CPU @ 3.00GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-1017-aws-glibc2.35)",
    "uid": "63b1e86bc3704205",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/aws_c5.xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-none-base-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 88.31078542237867,
    "Accuracy_div_100": 0.88311,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/aws_c5.xlarge-reference-cpu-deepsparse-vdefault-default_config/obert-base-pruned90-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-base-pruned90-none-bert-99",
    "Organization": "CTuning",
    "Platform": "aws_c5.xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 12.9574,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance c5.xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 2,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8124M CPU @ 3.00GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-1017-aws-glibc2.35)",
    "uid": "5c133ae2376b426a",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/aws_c5.xlarge-reference-cpu-deepsparse-vdefault-default_config/obert-base-pruned90-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 88.42042174998099,
    "Accuracy_div_100": 0.8842,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/c5a.2xlarge-reference-cpu-deepsparse-vdefault-default_config/bert-base-pruned90-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-base-pruned90-none-bert-99",
    "Organization": "CTuning",
    "Platform": "c5a.2xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 18.2922,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance c5a.2xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "AMD EPYC 7R32",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Amzn 2023 (linux-6.1.77-99.164.amzn2023.x86_64-glibc2.34)",
    "uid": "f9571059883e45d2",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/c5a.2xlarge-reference-cpu-deepsparse-vdefault-default_config/bert-base-pruned90-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 87.88571389692375,
    "Accuracy_div_100": 0.87886,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/c5a.2xlarge-reference-cpu-deepsparse-vdefault-default_config/bert-base-pruned95_obs_quant-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-base-pruned95_obs_quant-none-bert-99",
    "Organization": "CTuning",
    "Platform": "c5a.2xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 34.9947,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance c5a.2xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "AMD EPYC 7R32",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Amzn 2023 (linux-6.1.77-99.164.amzn2023.x86_64-glibc2.34)",
    "uid": "6c95edeb36ba4dce",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/c5a.2xlarge-reference-cpu-deepsparse-vdefault-default_config/bert-base-pruned95_obs_quant-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 89.65191480026783,
    "Accuracy_div_100": 0.89652,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/c5a.2xlarge-reference-cpu-deepsparse-vdefault-default_config/bert-large-base-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-large-base-none-bert-99",
    "Organization": "CTuning",
    "Platform": "c5a.2xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 2.1002,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance c5a.2xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "AMD EPYC 7R32",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Amzn 2023 (linux-6.1.77-99.164.amzn2023.x86_64-glibc2.34)",
    "uid": "2a9e793856a54d95",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/c5a.2xlarge-reference-cpu-deepsparse-vdefault-default_config/bert-large-base-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.29174382621062,
    "Accuracy_div_100": 0.90292,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/c5a.2xlarge-reference-cpu-deepsparse-vdefault-default_config/bert-large-pruned80_quant-none-vnni-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-large-pruned80_quant-none-vnni-bert-99",
    "Organization": "CTuning",
    "Platform": "c5a.2xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 7.10203,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance c5a.2xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "AMD EPYC 7R32",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Amzn 2023 (linux-6.1.77-99.164.amzn2023.x86_64-glibc2.34)",
    "uid": "075d5036a31246d1",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/c5a.2xlarge-reference-cpu-deepsparse-vdefault-default_config/bert-large-pruned80_quant-none-vnni-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.4308347276475,
    "Accuracy_div_100": 0.90431,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/c5a.2xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-14layer_pruned50-none-vnni-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-14layer_pruned50-none-vnni-bert-99",
    "Organization": "CTuning",
    "Platform": "c5a.2xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 41.3109,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance c5a.2xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "AMD EPYC 7R32",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Amzn 2023 (linux-6.1.77-99.164.amzn2023.x86_64-glibc2.34)",
    "uid": "9674b9d5c2564f70",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/c5a.2xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-14layer_pruned50-none-vnni-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.36718210138123,
    "Accuracy_div_100": 0.90367,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/c5a.2xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-14layer_pruned50_quant-none-vnni-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-14layer_pruned50_quant-none-vnni-bert-99",
    "Organization": "CTuning",
    "Platform": "c5a.2xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 55.2553,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance c5a.2xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "AMD EPYC 7R32",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Amzn 2023 (linux-6.1.77-99.164.amzn2023.x86_64-glibc2.34)",
    "uid": "89b657f016cb4aae",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/c5a.2xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-14layer_pruned50_quant-none-vnni-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.81268530031994,
    "Accuracy_div_100": 0.90813,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/c5a.2xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-base_quant-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-base_quant-none-bert-99",
    "Organization": "CTuning",
    "Platform": "c5a.2xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 25.5183,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance c5a.2xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "AMD EPYC 7R32",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Amzn 2023 (linux-6.1.77-99.164.amzn2023.x86_64-glibc2.34)",
    "uid": "38c0934ca02d452f",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/c5a.2xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-base_quant-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.89066465550044,
    "Accuracy_div_100": 0.90891,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/c5a.2xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-none-base-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-none-base-none-bert-99",
    "Organization": "CTuning",
    "Platform": "c5a.2xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 25.0774,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance c5a.2xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "AMD EPYC 7R32",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Amzn 2023 (linux-6.1.77-99.164.amzn2023.x86_64-glibc2.34)",
    "uid": "ab9c8ef8dcd24ca1",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/c5a.2xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-none-base-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 88.31078542237867,
    "Accuracy_div_100": 0.88311,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/c5a.2xlarge-reference-cpu-deepsparse-vdefault-default_config/obert-base-pruned90-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-base-pruned90-none-bert-99",
    "Organization": "CTuning",
    "Platform": "c5a.2xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 18.0132,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance c5a.2xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "AMD EPYC 7R32",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Amzn 2023 (linux-6.1.77-99.164.amzn2023.x86_64-glibc2.34)",
    "uid": "f277257e9be0452b",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/c5a.2xlarge-reference-cpu-deepsparse-vdefault-default_config/obert-base-pruned90-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 89.65191480026783,
    "Accuracy_div_100": 0.89652,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/c5a.2xlarge-reference-cpu-deepsparse-vdefault-default_config/obert-large-base-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-large-base-none-bert-99",
    "Organization": "CTuning",
    "Platform": "c5a.2xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 2.09354,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance c5a.2xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "AMD EPYC 7R32",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Amzn 2023 (linux-6.1.77-99.164.amzn2023.x86_64-glibc2.34)",
    "uid": "1bdbf5be008a4529",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/c5a.2xlarge-reference-cpu-deepsparse-vdefault-default_config/obert-large-base-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.17832662822171,
    "Accuracy_div_100": 0.90178,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/c5a.2xlarge-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned95-none-vnni-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-large-pruned95-none-vnni-bert-99",
    "Organization": "CTuning",
    "Platform": "c5a.2xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 8.9269,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance c5a.2xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "AMD EPYC 7R32",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Amzn 2023 (linux-6.1.77-99.164.amzn2023.x86_64-glibc2.34)",
    "uid": "987942a8615f45b9",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/c5a.2xlarge-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned95-none-vnni-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.01097011863615,
    "Accuracy_div_100": 0.90011,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/c5a.2xlarge-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned95_quant-none-vnni-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-large-pruned95_quant-none-vnni-bert-99",
    "Organization": "CTuning",
    "Platform": "c5a.2xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 12.9917,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance c5a.2xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "AMD EPYC 7R32",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Amzn 2023 (linux-6.1.77-99.164.amzn2023.x86_64-glibc2.34)",
    "uid": "ded8df4d1b274ea5",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/c5a.2xlarge-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned95_quant-none-vnni-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.1356467730578,
    "Accuracy_div_100": 0.90136,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/c5a.2xlarge-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned97-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-large-pruned97-none-bert-99",
    "Organization": "CTuning",
    "Platform": "c5a.2xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 9.82064,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance c5a.2xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "AMD EPYC 7R32",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Amzn 2023 (linux-6.1.77-99.164.amzn2023.x86_64-glibc2.34)",
    "uid": "4285ae7f1ebe42c5",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/c5a.2xlarge-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned97-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.14276789144404,
    "Accuracy_div_100": 0.90143,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/c5a.2xlarge-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned97-quant-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-large-pruned97-quant-none-bert-99",
    "Organization": "CTuning",
    "Platform": "c5a.2xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 12.4613,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance c5a.2xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "AMD EPYC 7R32",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Amzn 2023 (linux-6.1.77-99.164.amzn2023.x86_64-glibc2.34)",
    "uid": "2cfee615bdd744f7",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/c5a.2xlarge-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned97-quant-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 88.42042174998099,
    "Accuracy_div_100": 0.8842,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/c5a.xlarge-reference-cpu-deepsparse-vdefault-default_config/bert-base-pruned90-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-base-pruned90-none-bert-99",
    "Organization": "CTuning",
    "Platform": "c5a.xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 9.66538,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance c5a.xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 2,
    "host_processor_model_name": "AMD EPYC 7R32",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-1017-aws-glibc2.35)",
    "uid": "cfd52d3cbfdf46f7",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/c5a.xlarge-reference-cpu-deepsparse-vdefault-default_config/bert-base-pruned90-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 87.88571389692375,
    "Accuracy_div_100": 0.87886,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/c5a.xlarge-reference-cpu-deepsparse-vdefault-default_config/bert-base-pruned95_obs_quant-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-base-pruned95_obs_quant-none-bert-99",
    "Organization": "CTuning",
    "Platform": "c5a.xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 19.0903,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance c5a.xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 2,
    "host_processor_model_name": "AMD EPYC 7R32",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-1017-aws-glibc2.35)",
    "uid": "0bd2fba4271e47ab",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/c5a.xlarge-reference-cpu-deepsparse-vdefault-default_config/bert-base-pruned95_obs_quant-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.4308347276475,
    "Accuracy_div_100": 0.90431,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/c5a.xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-14layer_pruned50-none-vnni-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-14layer_pruned50-none-vnni-bert-99",
    "Organization": "CTuning",
    "Platform": "c5a.xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 24.6438,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance c5a.xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 2,
    "host_processor_model_name": "AMD EPYC 7R32",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-1017-aws-glibc2.35)",
    "uid": "183efc5950ce47cd",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/c5a.xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-14layer_pruned50-none-vnni-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.36718210138123,
    "Accuracy_div_100": 0.90367,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/c5a.xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-14layer_pruned50_quant-none-vnni-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-14layer_pruned50_quant-none-vnni-bert-99",
    "Organization": "CTuning",
    "Platform": "c5a.xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 31.2663,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance c5a.xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 2,
    "host_processor_model_name": "AMD EPYC 7R32",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-1017-aws-glibc2.35)",
    "uid": "2ce2258b9d55462c",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/c5a.xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-14layer_pruned50_quant-none-vnni-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.81268530031994,
    "Accuracy_div_100": 0.90813,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/c5a.xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-base_quant-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-base_quant-none-bert-99",
    "Organization": "CTuning",
    "Platform": "c5a.xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 14.2526,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance c5a.xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 2,
    "host_processor_model_name": "AMD EPYC 7R32",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-1017-aws-glibc2.35)",
    "uid": "7b84df02edf845ea",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/c5a.xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-base_quant-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.89066465550044,
    "Accuracy_div_100": 0.90891,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/c5a.xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-none-base-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-none-base-none-bert-99",
    "Organization": "CTuning",
    "Platform": "c5a.xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 14.0041,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance c5a.xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 2,
    "host_processor_model_name": "AMD EPYC 7R32",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-1017-aws-glibc2.35)",
    "uid": "5a947b2e494a48ab",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/c5a.xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-none-base-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 88.31078542237867,
    "Accuracy_div_100": 0.88311,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/c5a.xlarge-reference-cpu-deepsparse-vdefault-default_config/obert-base-pruned90-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-base-pruned90-none-bert-99",
    "Organization": "CTuning",
    "Platform": "c5a.xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 9.50949,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance c5a.xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 2,
    "host_processor_model_name": "AMD EPYC 7R32",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-1017-aws-glibc2.35)",
    "uid": "3d705792722c434a",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/c5a.xlarge-reference-cpu-deepsparse-vdefault-default_config/obert-base-pruned90-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 42.9043,
    "Accuracy_div_100": 0.42904,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-intel-cpu-pytorch-vdefault-default_config/gptj-99/offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "CTuning",
    "Platform": "GATE_Overflow_Intel_Sapphire_Rapids-intel-cpu-pytorch-vdefault-default_config",
    "Result": 0.326534,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GATE Overflow Intel Sapphire Rapids",
    "SystemType": "edge,datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Intel inference implementation with CM API, Pytorch git@927dc662386af052018212c7d01309a506fc94cd",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.6.2. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.04 (linux-6.2.0-39-generic-glibc2.37)",
    "uid": "97e602f9371a410c",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-intel-cpu-pytorch-vdefault-default_config/gptj-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 88.42042174998099,
    "Accuracy_div_100": 0.8842,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config/bert-base-pruned90-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-base-pruned90-none-bert-99",
    "Organization": "CTuning",
    "Platform": "GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 105.09,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GATE Overflow Intel Sapphire Rapids",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.6.2. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.04 (linux-6.2.0-39-generic-glibc2.37)",
    "uid": "3760cbb1aaa04374",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config/bert-base-pruned90-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 87.89212297504716,
    "Accuracy_div_100": 0.87892,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config/bert-base-pruned95_obs_quant-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-base-pruned95_obs_quant-none-bert-99",
    "Organization": "CTuning",
    "Platform": "GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 204.347,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GATE Overflow Intel Sapphire Rapids",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.6.2. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.04 (linux-6.2.0-39-generic-glibc2.37)",
    "uid": "28855685c3414c18",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config/bert-base-pruned95_obs_quant-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 89.65191480026783,
    "Accuracy_div_100": 0.89652,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config/bert-large-base-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-large-base-none-bert-99",
    "Organization": "CTuning",
    "Platform": "GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 14.1282,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GATE Overflow Intel Sapphire Rapids",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.6.2. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.04 (linux-6.2.0-39-generic-glibc2.37)",
    "uid": "cbc3239a9cda44ef",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config/bert-large-base-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.26941848776319,
    "Accuracy_div_100": 0.90269,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config/bert-large-pruned80_quant-none-vnni-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-large-pruned80_quant-none-vnni-bert-99",
    "Organization": "CTuning",
    "Platform": "GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 69.1786,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GATE Overflow Intel Sapphire Rapids",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.6.2. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.04 (linux-6.2.0-39-generic-glibc2.37)",
    "uid": "56f35de8ab7c41f9",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config/bert-large-pruned80_quant-none-vnni-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.4308347276475,
    "Accuracy_div_100": 0.90431,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config/mobilebert-14layer_pruned50-none-vnni-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-14layer_pruned50-none-vnni-bert-99",
    "Organization": "CTuning",
    "Platform": "GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 160.822,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GATE Overflow Intel Sapphire Rapids",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.6.2. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.04 (linux-6.2.0-39-generic-glibc2.37)",
    "uid": "c8c96cf1dae548d3",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config/mobilebert-14layer_pruned50-none-vnni-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.40462194474198,
    "Accuracy_div_100": 0.90405,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config/mobilebert-14layer_pruned50_quant-none-vnni-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-14layer_pruned50_quant-none-vnni-bert-99",
    "Organization": "CTuning",
    "Platform": "GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 268.655,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GATE Overflow Intel Sapphire Rapids",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.6.2. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.04 (linux-6.2.0-39-generic-glibc2.37)",
    "uid": "37484a1b0d0d4aa4",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config/mobilebert-14layer_pruned50_quant-none-vnni-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.79584822581347,
    "Accuracy_div_100": 0.90796,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config/mobilebert-base_quant-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-base_quant-none-bert-99",
    "Organization": "CTuning",
    "Platform": "GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 67.6974,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GATE Overflow Intel Sapphire Rapids",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.6.2. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.04 (linux-6.2.0-39-generic-glibc2.37)",
    "uid": "3cd4da1df3904dd6",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config/mobilebert-base_quant-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.89066465550044,
    "Accuracy_div_100": 0.90891,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config/mobilebert-none-base-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-none-base-none-bert-99",
    "Organization": "CTuning",
    "Platform": "GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 61.2531,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GATE Overflow Intel Sapphire Rapids",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.6.2. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.04 (linux-6.2.0-39-generic-glibc2.37)",
    "uid": "8f558da6597646b7",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config/mobilebert-none-base-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 88.31078542237867,
    "Accuracy_div_100": 0.88311,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config/obert-base-pruned90-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-base-pruned90-none-bert-99",
    "Organization": "CTuning",
    "Platform": "GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 106.096,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GATE Overflow Intel Sapphire Rapids",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.6.2. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.04 (linux-6.2.0-39-generic-glibc2.37)",
    "uid": "252521c2c2d44104",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config/obert-base-pruned90-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 89.65191480026783,
    "Accuracy_div_100": 0.89652,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config/obert-large-base-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-large-base-none-bert-99",
    "Organization": "CTuning",
    "Platform": "GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 14.2471,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GATE Overflow Intel Sapphire Rapids",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.6.2. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.04 (linux-6.2.0-39-generic-glibc2.37)",
    "uid": "6cfbc15c33704029",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config/obert-large-base-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.17832662822171,
    "Accuracy_div_100": 0.90178,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned95-none-vnni-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-large-pruned95-none-vnni-bert-99",
    "Organization": "CTuning",
    "Platform": "GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 48.3105,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GATE Overflow Intel Sapphire Rapids",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.6.2. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.04 (linux-6.2.0-39-generic-glibc2.37)",
    "uid": "468cd7ce49e9431f",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned95-none-vnni-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.0299132434367,
    "Accuracy_div_100": 0.9003,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned95_quant-none-vnni-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-large-pruned95_quant-none-vnni-bert-99",
    "Organization": "CTuning",
    "Platform": "GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 90.1756,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GATE Overflow Intel Sapphire Rapids",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.6.2. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.04 (linux-6.2.0-39-generic-glibc2.37)",
    "uid": "116a043e8ff94d95",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned95_quant-none-vnni-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.1356467730578,
    "Accuracy_div_100": 0.90136,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned97-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-large-pruned97-none-bert-99",
    "Organization": "CTuning",
    "Platform": "GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 53.4944,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GATE Overflow Intel Sapphire Rapids",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.6.2. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.04 (linux-6.2.0-39-generic-glibc2.37)",
    "uid": "c4b4048d4a5c40bf",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned97-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.1810702860831,
    "Accuracy_div_100": 0.90181,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned97-quant-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-large-pruned97-quant-none-bert-99",
    "Organization": "CTuning",
    "Platform": "GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 54.3318,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GATE Overflow Intel Sapphire Rapids",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.6.2. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.04 (linux-6.2.0-39-generic-glibc2.37)",
    "uid": "ee07d857c392495b",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned97-quant-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 88.42042174998099,
    "Accuracy_div_100": 0.8842,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/macbook_pro_m1_2-reference-cpu-deepsparse-vdefault-default_config/bert-base-pruned90-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-base-pruned90-none-bert-99",
    "Organization": "CTuning",
    "Platform": "macbook_pro_m1_2-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 14.7436,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Apple MacBook Pro M1",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 10,
    "host_processor_model_name": "Apple M1 Pro",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.5.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.5.11-linuxkit-glibc2.35)",
    "uid": "d9d81388994e4da0",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/macbook_pro_m1_2-reference-cpu-deepsparse-vdefault-default_config/bert-base-pruned90-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 87.93374374304268,
    "Accuracy_div_100": 0.87934,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/macbook_pro_m1_2-reference-cpu-deepsparse-vdefault-default_config/bert-base-pruned95_obs_quant-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-base-pruned95_obs_quant-none-bert-99",
    "Organization": "CTuning",
    "Platform": "macbook_pro_m1_2-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 18.9292,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Apple MacBook Pro M1",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 10,
    "host_processor_model_name": "Apple M1 Pro",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.5.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.5.11-linuxkit-glibc2.35)",
    "uid": "89528a70eabd47a6",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/macbook_pro_m1_2-reference-cpu-deepsparse-vdefault-default_config/bert-base-pruned95_obs_quant-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": "None",
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/macbook_pro_m1_2-reference-cpu-deepsparse-vdefault-default_config/bert-large-base-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-large-base-none-bert-99",
    "Organization": "CTuning",
    "Platform": "macbook_pro_m1_2-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 1.2094,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Apple MacBook Pro M1",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 10,
    "host_processor_model_name": "Apple M1 Pro",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.5.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.5.11-linuxkit-glibc2.35)",
    "uid": "00674d537f7644eb",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/macbook_pro_m1_2-reference-cpu-deepsparse-vdefault-default_config/bert-large-base-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.23098133171213,
    "Accuracy_div_100": 0.90231,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/macbook_pro_m1_2-reference-cpu-deepsparse-vdefault-default_config/bert-large-pruned80_quant-none-vnni-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-large-pruned80_quant-none-vnni-bert-99",
    "Organization": "CTuning",
    "Platform": "macbook_pro_m1_2-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 9.13778,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Apple MacBook Pro M1",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 10,
    "host_processor_model_name": "Apple M1 Pro",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.5.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.5.11-linuxkit-glibc2.35)",
    "uid": "cf3a2ae41b70468c",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/macbook_pro_m1_2-reference-cpu-deepsparse-vdefault-default_config/bert-large-pruned80_quant-none-vnni-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.4308347276475,
    "Accuracy_div_100": 0.90431,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/macbook_pro_m1_2-reference-cpu-deepsparse-vdefault-default_config/mobilebert-14layer_pruned50-none-vnni-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-14layer_pruned50-none-vnni-bert-99",
    "Organization": "CTuning",
    "Platform": "macbook_pro_m1_2-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 26.2901,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Apple MacBook Pro M1",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 10,
    "host_processor_model_name": "Apple M1 Pro",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.5.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.5.11-linuxkit-glibc2.35)",
    "uid": "c82135f100dd46a4",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/macbook_pro_m1_2-reference-cpu-deepsparse-vdefault-default_config/mobilebert-14layer_pruned50-none-vnni-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.79118282730964,
    "Accuracy_div_100": 0.90791,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/macbook_pro_m1_2-reference-cpu-deepsparse-vdefault-default_config/mobilebert-base_quant-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-base_quant-none-bert-99",
    "Organization": "CTuning",
    "Platform": "macbook_pro_m1_2-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 12.733,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Apple MacBook Pro M1",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 10,
    "host_processor_model_name": "Apple M1 Pro",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.5.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.5.11-linuxkit-glibc2.35)",
    "uid": "4e5615ca2fdd412f",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/macbook_pro_m1_2-reference-cpu-deepsparse-vdefault-default_config/mobilebert-base_quant-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.89066465550044,
    "Accuracy_div_100": 0.90891,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/macbook_pro_m1_2-reference-cpu-deepsparse-vdefault-default_config/mobilebert-none-base-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-none-base-none-bert-99",
    "Organization": "CTuning",
    "Platform": "macbook_pro_m1_2-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 12.092,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Apple MacBook Pro M1",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 10,
    "host_processor_model_name": "Apple M1 Pro",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.5.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.5.11-linuxkit-glibc2.35)",
    "uid": "f98bec82e73445b5",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/macbook_pro_m1_2-reference-cpu-deepsparse-vdefault-default_config/mobilebert-none-base-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 88.31078542237867,
    "Accuracy_div_100": 0.88311,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/macbook_pro_m1_2-reference-cpu-deepsparse-vdefault-default_config/obert-base-pruned90-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-base-pruned90-none-bert-99",
    "Organization": "CTuning",
    "Platform": "macbook_pro_m1_2-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 14.5634,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Apple MacBook Pro M1",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 10,
    "host_processor_model_name": "Apple M1 Pro",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.5.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.5.11-linuxkit-glibc2.35)",
    "uid": "386b63ab0a344c27",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/macbook_pro_m1_2-reference-cpu-deepsparse-vdefault-default_config/obert-base-pruned90-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": "None",
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/macbook_pro_m1_2-reference-cpu-deepsparse-vdefault-default_config/obert-large-base-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-large-base-none-bert-99",
    "Organization": "CTuning",
    "Platform": "macbook_pro_m1_2-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 1.29439,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Apple MacBook Pro M1",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 10,
    "host_processor_model_name": "Apple M1 Pro",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.5.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.5.11-linuxkit-glibc2.35)",
    "uid": "b32397e41fe34690",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/macbook_pro_m1_2-reference-cpu-deepsparse-vdefault-default_config/obert-large-base-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.17832662822171,
    "Accuracy_div_100": 0.90178,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/macbook_pro_m1_2-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned95-none-vnni-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-large-pruned95-none-vnni-bert-99",
    "Organization": "CTuning",
    "Platform": "macbook_pro_m1_2-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 5.98684,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Apple MacBook Pro M1",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 10,
    "host_processor_model_name": "Apple M1 Pro",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.5.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.5.11-linuxkit-glibc2.35)",
    "uid": "3fc12d6c314648f1",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/macbook_pro_m1_2-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned95-none-vnni-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 89.94051065318,
    "Accuracy_div_100": 0.89941,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/macbook_pro_m1_2-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned95_quant-none-vnni-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-large-pruned95_quant-none-vnni-bert-99",
    "Organization": "CTuning",
    "Platform": "macbook_pro_m1_2-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 7.63646,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Apple MacBook Pro M1",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 10,
    "host_processor_model_name": "Apple M1 Pro",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.5.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.5.11-linuxkit-glibc2.35)",
    "uid": "6f5886f80fa748e4",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/macbook_pro_m1_2-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned95_quant-none-vnni-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.1356467730578,
    "Accuracy_div_100": 0.90136,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/macbook_pro_m1_2-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned97-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-large-pruned97-none-bert-99",
    "Organization": "CTuning",
    "Platform": "macbook_pro_m1_2-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 5.9642,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Apple MacBook Pro M1",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 10,
    "host_processor_model_name": "Apple M1 Pro",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.5.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.5.11-linuxkit-glibc2.35)",
    "uid": "47538ded6cc44bc1",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/macbook_pro_m1_2-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned97-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.08646571797165,
    "Accuracy_div_100": 0.90086,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/macbook_pro_m1_2-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned97-quant-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-large-pruned97-quant-none-bert-99",
    "Organization": "CTuning",
    "Platform": "macbook_pro_m1_2-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 12.8954,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Apple MacBook Pro M1",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 10,
    "host_processor_model_name": "Apple M1 Pro",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.5.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.5.11-linuxkit-glibc2.35)",
    "uid": "9ffb1ab6ca174be9",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/macbook_pro_m1_2-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned97-quant-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 88.42042174998099,
    "Accuracy_div_100": 0.8842,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/t3.2xlarge-reference-cpu-deepsparse-vdefault-default_config/bert-base-pruned90-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-base-pruned90-none-bert-99",
    "Organization": "CTuning",
    "Platform": "t3.2xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 12.6396,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance t3.2xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-1017-aws-glibc2.35)",
    "uid": "5633a9e012414b29",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/t3.2xlarge-reference-cpu-deepsparse-vdefault-default_config/bert-base-pruned90-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 87.89212297504716,
    "Accuracy_div_100": 0.87892,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/t3.2xlarge-reference-cpu-deepsparse-vdefault-default_config/bert-base-pruned95_obs_quant-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-base-pruned95_obs_quant-none-bert-99",
    "Organization": "CTuning",
    "Platform": "t3.2xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 19.115,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance t3.2xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-1017-aws-glibc2.35)",
    "uid": "dabc53f1da244015",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/t3.2xlarge-reference-cpu-deepsparse-vdefault-default_config/bert-base-pruned95_obs_quant-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 89.65191480026783,
    "Accuracy_div_100": 0.89652,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/t3.2xlarge-reference-cpu-deepsparse-vdefault-default_config/bert-large-base-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-large-base-none-bert-99",
    "Organization": "CTuning",
    "Platform": "t3.2xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 2.03328,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance t3.2xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-1017-aws-glibc2.35)",
    "uid": "d0fb6108919144c2",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/t3.2xlarge-reference-cpu-deepsparse-vdefault-default_config/bert-large-base-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.26941848776319,
    "Accuracy_div_100": 0.90269,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/t3.2xlarge-reference-cpu-deepsparse-vdefault-default_config/bert-large-pruned80_quant-none-vnni-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-large-pruned80_quant-none-vnni-bert-99",
    "Organization": "CTuning",
    "Platform": "t3.2xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 5.47764,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance t3.2xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-1017-aws-glibc2.35)",
    "uid": "302ab0a70ef94288",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/t3.2xlarge-reference-cpu-deepsparse-vdefault-default_config/bert-large-pruned80_quant-none-vnni-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.4308347276475,
    "Accuracy_div_100": 0.90431,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/t3.2xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-14layer_pruned50-none-vnni-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-14layer_pruned50-none-vnni-bert-99",
    "Organization": "CTuning",
    "Platform": "t3.2xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 21.1835,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance t3.2xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-1017-aws-glibc2.35)",
    "uid": "9af5b9eb2f0e49d0",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/t3.2xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-14layer_pruned50-none-vnni-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.40462194474198,
    "Accuracy_div_100": 0.90405,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/t3.2xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-14layer_pruned50_quant-none-vnni-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-14layer_pruned50_quant-none-vnni-bert-99",
    "Organization": "CTuning",
    "Platform": "t3.2xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 27.4951,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance t3.2xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-1017-aws-glibc2.35)",
    "uid": "8d3445c9d5884dd4",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/t3.2xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-14layer_pruned50_quant-none-vnni-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.79584822581347,
    "Accuracy_div_100": 0.90796,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/t3.2xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-base_quant-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-base_quant-none-bert-99",
    "Organization": "CTuning",
    "Platform": "t3.2xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 13.3361,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance t3.2xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-1017-aws-glibc2.35)",
    "uid": "da64e7a7b45248f1",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/t3.2xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-base_quant-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.89066465550044,
    "Accuracy_div_100": 0.90891,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/t3.2xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-none-base-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-none-base-none-bert-99",
    "Organization": "CTuning",
    "Platform": "t3.2xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 26.2284,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance t3.2xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-1017-aws-glibc2.35)",
    "uid": "abd1b37fc97e4f70",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/t3.2xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-none-base-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 88.31078542237867,
    "Accuracy_div_100": 0.88311,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/t3.2xlarge-reference-cpu-deepsparse-vdefault-default_config/obert-base-pruned90-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-base-pruned90-none-bert-99",
    "Organization": "CTuning",
    "Platform": "t3.2xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 12.135,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance t3.2xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-1017-aws-glibc2.35)",
    "uid": "5e01db85d3934928",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/t3.2xlarge-reference-cpu-deepsparse-vdefault-default_config/obert-base-pruned90-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 89.65191480026783,
    "Accuracy_div_100": 0.89652,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/t3.2xlarge-reference-cpu-deepsparse-vdefault-default_config/obert-large-base-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-large-base-none-bert-99",
    "Organization": "CTuning",
    "Platform": "t3.2xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 2.0909,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance t3.2xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-1017-aws-glibc2.35)",
    "uid": "cf4ee2c2ecaf4a40",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/t3.2xlarge-reference-cpu-deepsparse-vdefault-default_config/obert-large-base-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.17832662822171,
    "Accuracy_div_100": 0.90178,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/t3.2xlarge-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned95-none-vnni-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-large-pruned95-none-vnni-bert-99",
    "Organization": "CTuning",
    "Platform": "t3.2xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 5.59124,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance t3.2xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-1017-aws-glibc2.35)",
    "uid": "22220ae6e65040c4",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/t3.2xlarge-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned95-none-vnni-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.0299132434367,
    "Accuracy_div_100": 0.9003,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/t3.2xlarge-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned95_quant-none-vnni-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-large-pruned95_quant-none-vnni-bert-99",
    "Organization": "CTuning",
    "Platform": "t3.2xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 7.29728,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance t3.2xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-1017-aws-glibc2.35)",
    "uid": "c71516533eb7484b",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/t3.2xlarge-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned95_quant-none-vnni-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.1356467730578,
    "Accuracy_div_100": 0.90136,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/t3.2xlarge-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned97-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-large-pruned97-none-bert-99",
    "Organization": "CTuning",
    "Platform": "t3.2xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 7.17755,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance t3.2xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-1017-aws-glibc2.35)",
    "uid": "cfaa7e8584cd4e3f",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/t3.2xlarge-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned97-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.15626980699892,
    "Accuracy_div_100": 0.90156,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/t3.2xlarge-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned97-quant-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-large-pruned97-quant-none-bert-99",
    "Organization": "CTuning",
    "Platform": "t3.2xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 7.32305,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance t3.2xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-1017-aws-glibc2.35)",
    "uid": "d2f938906b7d4f73",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/t3.2xlarge-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned97-quant-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 88.42042174998099,
    "Accuracy_div_100": 0.8842,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/t3.xlarge-reference-cpu-deepsparse-vdefault-default_config/bert-base-pruned90-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-base-pruned90-none-bert-99",
    "Organization": "CTuning",
    "Platform": "t3.xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 9.2359,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance t3.xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 2,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-1017-aws-glibc2.35)",
    "uid": "631dba9fe26f416f",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/t3.xlarge-reference-cpu-deepsparse-vdefault-default_config/bert-base-pruned90-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 87.89212297504716,
    "Accuracy_div_100": 0.87892,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/t3.xlarge-reference-cpu-deepsparse-vdefault-default_config/bert-base-pruned95_obs_quant-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-base-pruned95_obs_quant-none-bert-99",
    "Organization": "CTuning",
    "Platform": "t3.xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 13.0945,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance t3.xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 2,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-1017-aws-glibc2.35)",
    "uid": "147e78e310334795",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/t3.xlarge-reference-cpu-deepsparse-vdefault-default_config/bert-base-pruned95_obs_quant-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.4308347276475,
    "Accuracy_div_100": 0.90431,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/t3.xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-14layer_pruned50-none-vnni-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-14layer_pruned50-none-vnni-bert-99",
    "Organization": "CTuning",
    "Platform": "t3.xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 20.5071,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance t3.xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 2,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-1017-aws-glibc2.35)",
    "uid": "634cf19a7e954b22",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/t3.xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-14layer_pruned50-none-vnni-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.40462194474198,
    "Accuracy_div_100": 0.90405,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/t3.xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-14layer_pruned50_quant-none-vnni-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-14layer_pruned50_quant-none-vnni-bert-99",
    "Organization": "CTuning",
    "Platform": "t3.xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 27.1278,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance t3.xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 2,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-1017-aws-glibc2.35)",
    "uid": "76d8e15c56a24d95",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/t3.xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-14layer_pruned50_quant-none-vnni-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.7887526723603,
    "Accuracy_div_100": 0.90789,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/t3.xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-base_quant-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-base_quant-none-bert-99",
    "Organization": "CTuning",
    "Platform": "t3.xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 10.6813,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance t3.xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 2,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-1017-aws-glibc2.35)",
    "uid": "3c5259cb56fc4230",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/t3.xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-base_quant-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.89066465550044,
    "Accuracy_div_100": 0.90891,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/t3.xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-none-base-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-none-base-none-bert-99",
    "Organization": "CTuning",
    "Platform": "t3.xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 13.3146,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance t3.xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 2,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-1017-aws-glibc2.35)",
    "uid": "9b6f94ddf9f5417a",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/t3.xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-none-base-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 88.31078542237867,
    "Accuracy_div_100": 0.88311,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/t3.xlarge-reference-cpu-deepsparse-vdefault-default_config/obert-base-pruned90-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-base-pruned90-none-bert-99",
    "Organization": "CTuning",
    "Platform": "t3.xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 9.25857,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance t3.xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 2,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-1017-aws-glibc2.35)",
    "uid": "fbea7e7bc5bd4fba",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/t3.xlarge-reference-cpu-deepsparse-vdefault-default_config/obert-base-pruned90-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.1356467730578,
    "Accuracy_div_100": 0.90136,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/t3.xlarge-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned97-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-large-pruned97-none-bert-99",
    "Organization": "CTuning",
    "Platform": "t3.xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 4.54128,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance t3.xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 2,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-1017-aws-glibc2.35)",
    "uid": "25c17d7074944947",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/t3.xlarge-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned97-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.1810702860831,
    "Accuracy_div_100": 0.90181,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/t3.xlarge-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned97-quant-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-large-pruned97-quant-none-bert-99",
    "Organization": "CTuning",
    "Platform": "t3.xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 4.03085,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance t3.xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 2,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-1017-aws-glibc2.35)",
    "uid": "c99ea73c29d44412",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/t3.xlarge-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned97-quant-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 89.65191480026783,
    "Accuracy_div_100": 0.89652,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/Tejasvis_MBP-reference-cpu-deepsparse-vdefault-default_config/bert-large-base-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-large-base-none-bert-99",
    "Organization": "CTuning",
    "Platform": "Tejasvis_MBP-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 2.68036,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Apple MacBook Pro M1 (Tejasvis)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 10,
    "host_processor_model_name": "Apple M1 Pro",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": " (darwin-23.3.0)",
    "uid": "3422d52c9ff24227",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/Tejasvis_MBP-reference-cpu-deepsparse-vdefault-default_config/bert-large-base-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.23098133171213,
    "Accuracy_div_100": 0.90231,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/Tejasvis_MBP-reference-cpu-deepsparse-vdefault-default_config/bert-large-pruned80_quant-none-vnni-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-large-pruned80_quant-none-vnni-bert-99",
    "Organization": "CTuning",
    "Platform": "Tejasvis_MBP-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 13.2117,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Apple MacBook Pro M1 (Tejasvis)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 10,
    "host_processor_model_name": "Apple M1 Pro",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": " (darwin-23.3.0)",
    "uid": "1b01514ca9914cf4",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/Tejasvis_MBP-reference-cpu-deepsparse-vdefault-default_config/bert-large-pruned80_quant-none-vnni-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.89066465550044,
    "Accuracy_div_100": 0.90891,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/Tejasvis_MBP-reference-cpu-deepsparse-vdefault-default_config/mobilebert-none-base-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-none-base-none-bert-99",
    "Organization": "CTuning",
    "Platform": "Tejasvis_MBP-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 30.1667,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Apple MacBook Pro M1 (Tejasvis)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 10,
    "host_processor_model_name": "Apple M1 Pro",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": " (darwin-23.3.0)",
    "uid": "dc05ccca88964389",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/Tejasvis_MBP-reference-cpu-deepsparse-vdefault-default_config/mobilebert-none-base-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 89.65191480026783,
    "Accuracy_div_100": 0.89652,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/Tejasvis_MBP-reference-cpu-deepsparse-vdefault-default_config/obert-large-base-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-large-base-none-bert-99",
    "Organization": "CTuning",
    "Platform": "Tejasvis_MBP-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 2.69294,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Apple MacBook Pro M1 (Tejasvis)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 10,
    "host_processor_model_name": "Apple M1 Pro",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": " (darwin-23.3.0)",
    "uid": "e1cd67c562564eed",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/Tejasvis_MBP-reference-cpu-deepsparse-vdefault-default_config/obert-large-base-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.17832662822171,
    "Accuracy_div_100": 0.90178,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/Tejasvis_MBP-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned95-none-vnni-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-large-pruned95-none-vnni-bert-99",
    "Organization": "CTuning",
    "Platform": "Tejasvis_MBP-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 9.79108,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Apple MacBook Pro M1 (Tejasvis)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 10,
    "host_processor_model_name": "Apple M1 Pro",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": " (darwin-23.3.0)",
    "uid": "ca1e4c959d004bd4",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/Tejasvis_MBP-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned95-none-vnni-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.1356467730578,
    "Accuracy_div_100": 0.90136,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/Tejasvis_MBP-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned97-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-large-pruned97-none-bert-99",
    "Organization": "CTuning",
    "Platform": "Tejasvis_MBP-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 9.88061,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Apple MacBook Pro M1 (Tejasvis)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 10,
    "host_processor_model_name": "Apple M1 Pro",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": " (darwin-23.3.0)",
    "uid": "7eb735f0e3714563",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/Tejasvis_MBP-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned97-none-bert-99/offline",
    "version": "v4.0"
  }
]
