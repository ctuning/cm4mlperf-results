[
  {
    "Accuracy": 31.792681410610676,
    "Accuracy_div_100": 0.31793,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC4000A_E12_4XH100_TRT/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "ASUSTeK",
    "Platform": "ESC4000A_E12_4XH100_TRT",
    "Result": 5.3739,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "ASUSTeK ESC4000A-E12 (4xH100-NVL-94GB)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 4,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "uid": "6420554901344231",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/ASUSTeK/results/ESC4000A_E12_4XH100_TRT/stable-diffusion-xl/Server",
    "version": "v4.1"
  },
  {
    "Accuracy": 31.788641649782658,
    "Accuracy_div_100": 0.31789,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC8000A_E12_H100x8_TRT/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "ASUSTeK",
    "Platform": "ESC8000A_E12_H100x8_TRT",
    "Result": 7.84131,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "ESC8000A-E12 (8x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "AMD EPYC 9374F 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Data bandwidth for GPU-PCIe: 504 GB/s; PCIe-NIC: 126 GB/s",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "uid": "f674174741f24e26",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/ASUSTeK/results/ESC8000A_E12_H100x8_TRT/stable-diffusion-xl/Server",
    "version": "v4.1"
  },
  {
    "Accuracy": 31.800740675926207,
    "Accuracy_div_100": 0.31801,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC_N8_E11_H100x8_TRT/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "ASUSTeK",
    "Platform": "ESC_N8_E11_H100x8_TRT",
    "Result": 15.7041,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "ESC-N8-E11 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "2d9d1ba6105a47e2",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/ASUSTeK/results/ESC_N8_E11_H100x8_TRT/stable-diffusion-xl/Server",
    "version": "v4.1"
  },
  {
    "Accuracy": 31.80976548939943,
    "Accuracy_div_100": 0.3181,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/C240M7_L40Sx2_TRT/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Cisco",
    "Platform": "C240M7_L40Sx2_TRT",
    "Result": 1.25757,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Cisco UCS C240 M7 (2x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 2,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel Xeon Gold 6448H",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "415e7a6299c8484a",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Cisco/results/C240M7_L40Sx2_TRT/stable-diffusion-xl/Server",
    "version": "v4.1"
  },
  {
    "Accuracy": 31.77801339238882,
    "Accuracy_div_100": 0.31778,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/C245M8_H100_PCIe_80GBx2_TRT/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Cisco",
    "Platform": "C245M8_H100_PCIe_80GBx2_TRT",
    "Result": 2.1963,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Cisco UCS C245 M8 (2x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 2,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9684X 96-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "28f00f5246d24ff5",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Cisco/results/C245M8_H100_PCIe_80GBx2_TRT/stable-diffusion-xl/Server",
    "version": "v4.1"
  },
  {
    "Accuracy": 31.806383980810644,
    "Accuracy_div_100": 0.31806,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/C245M8_L40Sx2_TRT/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Cisco",
    "Platform": "C245M8_L40Sx2_TRT",
    "Result": 1.25759,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Cisco UCS C245 M8 (2x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 2,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9684X 96-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "6d12cdd1387545c0",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Cisco/results/C245M8_L40Sx2_TRT/stable-diffusion-xl/Server",
    "version": "v4.1"
  },
  {
    "Accuracy": 31.804661527872085,
    "Accuracy_div_100": 0.31805,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/X210c_L40SX2_TRT/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Cisco",
    "Platform": "X210c_L40SX2_TRT",
    "Result": 1.26746,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Cisco UCS X210c M7 (2x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 2,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8562Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "d4874d6872b749a2",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Cisco/results/X210c_L40SX2_TRT/stable-diffusion-xl/Server",
    "version": "v4.1"
  },
  {
    "Accuracy": 31.780787407159806,
    "Accuracy_div_100": 0.31781,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760xa_H100NVL_PCIe_94GBx4_TRT/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Dell",
    "Platform": "R760xa_H100NVL_PCIe_94GBx4_TRT",
    "Result": 4.87198,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge R760xa (4xH100 NVL, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 4,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 120,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "6a4f3faf6c5b431d",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Dell/results/R760xa_H100NVL_PCIe_94GBx4_TRT/stable-diffusion-xl/Server",
    "version": "v4.1"
  },
  {
    "Accuracy": 31.780136460363863,
    "Accuracy_div_100": 0.3178,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Dell",
    "Platform": "XE8640_H100_SXM_80GBx4_TRT",
    "Result": 7.85802,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XE8640 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "uid": "c3825483a4e74a65",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/stable-diffusion-xl/Server",
    "version": "v4.1"
  },
  {
    "Accuracy": 31.80400671750307,
    "Accuracy_div_100": 0.31804,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9640_H100_SXM_80GBx4_TRT/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Dell",
    "Platform": "XE9640_H100_SXM_80GBx4_TRT",
    "Result": 6.36178,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XE9640 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "uid": "cc7eb076cac34909",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Dell/results/XE9640_H100_SXM_80GBx4_TRT/stable-diffusion-xl/Server",
    "version": "v4.1"
  },
  {
    "Accuracy": 31.7751819768548,
    "Accuracy_div_100": 0.31775,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_H200_SXM_141GBx8_TRT/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Dell",
    "Platform": "XE9680_H200_SXM_141GBx8_TRT",
    "Result": 16.6945,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XE9680 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "49666dec7bae4dab",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Dell/results/XE9680_H200_SXM_141GBx8_TRT/stable-diffusion-xl/Server",
    "version": "v4.1"
  },
  {
    "Accuracy": 31.78535566031933,
    "Accuracy_div_100": 0.31785,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Fujitsu",
    "Platform": "GX2560M7_H100_SXM_80GBx4_TRT",
    "Result": 7.84386,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "GX2560M7_H100_SXM_80GBx4 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "9f80788a0cec4f42",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/stable-diffusion-xl/Server",
    "version": "v4.1"
  },
  {
    "Accuracy": 31.792413492798804,
    "Accuracy_div_100": 0.31792,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "GigaComputing",
    "Platform": "GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT",
    "Result": 16.5912,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "GIGABYTE G593-SD1",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "086608b3cd7f4774",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/stable-diffusion-xl/Server",
    "version": "v4.1"
  },
  {
    "Accuracy": 31.78315771371126,
    "Accuracy_div_100": 0.31783,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Google/results/DGX-H100_H100-SXM-80GBx8_TRT/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Google",
    "Platform": "DGX-H100_H100-SXM-80GBx8_TRT",
    "Result": 15.8185,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8481C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "9eaf5578120843de",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Google/results/DGX-H100_H100-SXM-80GBx8_TRT/stable-diffusion-xl/Server",
    "version": "v4.1"
  },
  {
    "Accuracy": 31.732986239790918,
    "Accuracy_div_100": 0.31733,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Google/results/tpu_v5e_x4_flax/stable-diffusion-xl/server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Google",
    "Platform": "tpu_v5e_x4_flax",
    "Result": 1.54554,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "tpu-v5e-4",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "TPU v5e",
    "accelerators_per_node": 4,
    "compliance": 0,
    "errors": 0,
    "framework": "flax",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 112,
    "host_processor_model_name": "AMD EPYC 7B13",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Linux version 5.19.0-1030-gcp (buildd@bos03-amd64-050) (x86_64-linux-gnu-gcc-12 (Ubuntu 12.1.0-2ubuntu1~22.04) 12.1.0, GNU ld (GNU Binutils for Ubuntu) 2.38) #32~22.04.1-Ubuntu SMP Thu Jul 13 09:36:23 UTC 2023",
    "uid": "823c6fdf65b145f3",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Google/results/tpu_v5e_x4_flax/stable-diffusion-xl/server",
    "version": "v4.1"
  },
  {
    "Accuracy": 31.736226662099362,
    "Accuracy_div_100": 0.31736,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Google/results/tpu_v6_x4_flax/stable-diffusion-xl/server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Google",
    "Platform": "tpu_v6_x4_flax",
    "Result": 4.48577,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "tpu-v6-4",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "TPU v6",
    "accelerators_per_node": 4,
    "compliance": 0,
    "errors": 0,
    "framework": "flax",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 180,
    "host_processor_model_name": "AMD EPYC 9B14",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Linux version 6.2.0-1019-gcp (buildd@lcy02-amd64-032) (x86_64-linux-gnu-gcc-12 (Ubuntu 12.3.0-1ubuntu1~22.04) 12.3.0, GNU ld (GNU Binutils for Ubuntu) 2.38) #21~22.04.1-Ubuntu SMP Thu Nov 16 18:18:34 UTC 2023",
    "uid": "e3baa822ad8c4ef4",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Google/results/tpu_v6_x4_flax/stable-diffusion-xl/server",
    "version": "v4.1"
  },
  {
    "Accuracy": 31.780244728624822,
    "Accuracy_div_100": 0.3178,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/HPE/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "HPE",
    "Platform": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT",
    "Result": 2.01813,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "HPE ProLiant Compute DL384 Gen12 (1x GH200-144GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "accelerators_per_node": 1,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA GH200 144GB HBM3e",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "uid": "a52427d332dc4140",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/HPE/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/stable-diffusion-xl/Server",
    "version": "v4.1"
  },
  {
    "Accuracy": 31.79274706661701,
    "Accuracy_div_100": 0.31793,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "HPE",
    "Platform": "HPE_Cray_XD670_H100_SXM_80GBx8_TRT",
    "Result": 15.8155,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "HPE Cray XD670 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "22.04.4 LTS",
    "uid": "da820f572263497e",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT/stable-diffusion-xl/Server",
    "version": "v4.1"
  },
  {
    "Accuracy": 31.79951359838247,
    "Accuracy_div_100": 0.318,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "HPE",
    "Platform": "HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT",
    "Result": 3.9493,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "HPE ProLiant DL380a Gen11 (4x H100-NVL-94GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 4,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "INTEL(R) XEON(R) GOLD 6530",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "uid": "f5b447e34bc24955",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/HPE/results/HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT/stable-diffusion-xl/Server",
    "version": "v4.1"
  },
  {
    "Accuracy": 31.800972669124604,
    "Accuracy_div_100": 0.31801,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/H200_SXM_141GBx8_TRT/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Lenovo",
    "Platform": "H200_SXM_141GBx8_TRT",
    "Result": 16.645,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "ThinkSystem SR685a V3(8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.5",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "AMD EPYC 9454",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "939c261586f74331",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Lenovo/results/H200_SXM_141GBx8_TRT/stable-diffusion-xl/Server",
    "version": "v4.1"
  },
  {
    "Accuracy": 31.780624158978462,
    "Accuracy_div_100": 0.31781,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/Lenovo_8xH200_TRT/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Lenovo",
    "Platform": "Lenovo_8xH200_TRT",
    "Result": 16.9831,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "ThinkSystem SR680a V3 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8568Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "a5da3500f4b540b5",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Lenovo/results/Lenovo_8xH200_TRT/stable-diffusion-xl/Server",
    "version": "v4.1"
  },
  {
    "Accuracy": 31.788790368437766,
    "Accuracy_div_100": 0.31789,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/SR675_V3_8xH100_NVL_TRT/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Lenovo",
    "Platform": "SR675_V3_8xH100_NVL_TRT",
    "Result": 11.6801,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "ThinkSystem SR675 V3 (8x H100-NVL-94GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.5",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 84,
    "host_processor_model_name": "AMD EPYC 9634 84-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "3d2f0199fbbc419c",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Lenovo/results/SR675_V3_8xH100_NVL_TRT/stable-diffusion-xl/Server",
    "version": "v4.1"
  },
  {
    "Accuracy": 31.782496818602084,
    "Accuracy_div_100": 0.31782,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "NVIDIA",
    "Platform": "DGX-H100_H100-SXM-80GBx8_TRT",
    "Result": 15.7189,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "fa44be45bd0442f8",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/stable-diffusion-xl/Server",
    "version": "v4.1"
  },
  {
    "Accuracy": 31.785339580476283,
    "Accuracy_div_100": 0.31785,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "NVIDIA",
    "Platform": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT",
    "Result": 2.01829,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NVIDIA GH200 NVL2 Platform (1x GH200-144GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "accelerators_per_node": 1,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA GH200 144GB HBM3e",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "uid": "a4250735f7f44410",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/stable-diffusion-xl/Server",
    "version": "v4.1"
  },
  {
    "Accuracy": 31.77436184436083,
    "Accuracy_div_100": 0.31774,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT",
    "Result": 16.782,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "d865d099204d465e",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/NVIDIA/results/H200-SXM-141GBx8_TRT/stable-diffusion-xl/Server",
    "version": "v4.1"
  },
  {
    "Accuracy": 31.78107093989849,
    "Accuracy_div_100": 0.31781,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/D54U_3U_H100_PCIe_80GBx4_TRT/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "D54U_3U_H100_PCIe_80GBx4_TRT",
    "Result": 4.0094,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "D54U_3U_H100_PCIe_80GBx4_TRT",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54U-3U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.2",
    "uid": "02e90d1e912f4dd5",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Quanta_Cloud_Technology/results/D54U_3U_H100_PCIe_80GBx4_TRT/stable-diffusion-xl/Server",
    "version": "v4.1"
  },
  {
    "Accuracy": 31.784094333946705,
    "Accuracy_div_100": 0.31784,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "Result": 1.84443,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "accelerators_per_node": 1,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "QuantaGrid S74G-2U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.3",
    "uid": "20c29e5c93c34d79",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Quanta_Cloud_Technology/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/stable-diffusion-xl/Server",
    "version": "v4.1"
  },
  {
    "Accuracy": 31.80437699943781,
    "Accuracy_div_100": 0.31804,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Supermicro",
    "Platform": "AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT",
    "Result": 15.7157,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "AS-4125GS-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "uid": "6b67581e38484b35",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/stable-diffusion-xl/Server",
    "version": "v4.1"
  },
  {
    "Accuracy": 31.78228974968195,
    "Accuracy_div_100": 0.31782,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Supermicro",
    "Platform": "AS_8125GS_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 15.6683,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "AS-8125GS-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "AMD EPYC 9474F",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "uid": "bb63884ea1984c5c",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/stable-diffusion-xl/Server",
    "version": "v4.1"
  },
  {
    "Accuracy": 31.786237963438033,
    "Accuracy_div_100": 0.31786,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Supermicro",
    "Platform": "SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT",
    "Result": 16.0608,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "SYS-421GE-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8570",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "uid": "fa0bcef0320641b7",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/stable-diffusion-xl/Server",
    "version": "v4.1"
  },
  {
    "Accuracy": 31.78609716743231,
    "Accuracy_div_100": 0.31786,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Supermicro",
    "Platform": "SYS_821GE_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 15.994,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "SYS-821GE-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "uid": "7d9f04874dc24186",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/stable-diffusion-xl/Server",
    "version": "v4.1"
  }
]
