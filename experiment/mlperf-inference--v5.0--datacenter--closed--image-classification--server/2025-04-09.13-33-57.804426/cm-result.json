[
  {
    "Accuracy": "acc: 76.078",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_HPE_VAST_TRT/resnet50/Server",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "HPE",
    "Platform": "HPE_Cray_XD670_H100_SXM_80GBx8_HPE_VAST_TRT",
    "Result": 620188,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "HPE Cray XD670 with HPE GreenLake for File Storage (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04.1 LTS",
    "uid": "9c2ac12d8d504bae",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_HPE_VAST_TRT/resnet50/Server",
    "version": "v5.0",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "acc: 76.078",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_PROLIANT_DL380A_H200_NVL_141GBX8_TRT/resnet50/Server",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "HPE",
    "Platform": "HPE_PROLIANT_DL380A_H200_NVL_141GBX8_TRT",
    "Result": 620188,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "HPE ProLiant DL380a Compute Gen12 (8x H200-NVL-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H200-NVL-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 192,
    "host_processor_model_name": "Intel(R) Xeon(R) 6740E",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04.1 LTS",
    "uid": "78ac2946dc4f4dfe",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/HPE/results/HPE_PROLIANT_DL380A_H200_NVL_141GBX8_TRT/resnet50/Server",
    "version": "v5.0",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "acc: 76.078",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT/resnet50/Server",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "HPE",
    "Platform": "HPE_Cray_XD670_H100_SXM_80GBx8_TRT",
    "Result": 620188,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "HPE Cray XD670 with Cray ClusterStor (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04.1 LTS",
    "uid": "fbe7191dae104bdb",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT/resnet50/Server",
    "version": "v5.0",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "acc: 76.078",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_ProLiant_DL380a_L40S_PCIe_48GBx8_TRT/resnet50/Server",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "HPE",
    "Platform": "HPE_ProLiant_DL380a_L40S_PCIe_48GBx8_TRT",
    "Result": 344052,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "HPE ProLiant Compute DL380a Gen12 (8x L40S-PCIe-48GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "Intel(R) Xeon(R) 6740E",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04.1 LTS",
    "uid": "1cb3b1319db54e98",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/HPE/results/HPE_ProLiant_DL380a_L40S_PCIe_48GBx8_TRT/resnet50/Server",
    "version": "v5.0",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "acc: 76.078",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_Cray_XD670_H200_SXM_141GBx8_TRT/resnet50/Server",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "HPE",
    "Platform": "HPE_Cray_XD670_H200_SXM_141GBx8_TRT",
    "Result": 667216,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "HPE Cray XD670 with Cray ClusterStor (8x H200-SXM-141GB)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8562Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "RHEL 9.4",
    "uid": "d4aa008631484b0c",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/HPE/results/HPE_Cray_XD670_H200_SXM_141GBx8_TRT/resnet50/Server",
    "version": "v5.0",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "acc: 76.078",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_ProLiant_DL380a_H100_NVL_94GBx8_TRT/resnet50/Server",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "HPE",
    "Platform": "HPE_ProLiant_DL380a_H100_NVL_94GBx8_TRT",
    "Result": 480097,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "HPE ProLiant Compute DL380a Gen12 (8x H100-NVL-94GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "INTEL(R) XEON(R) 6740E",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04.1 LTS",
    "uid": "37bc266a1e39496c",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/HPE/results/HPE_ProLiant_DL380a_H100_NVL_94GBx8_TRT/resnet50/Server",
    "version": "v5.0",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "acc: 76.078",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Sustainable_Metal_Cloud/results/H200-SXM-141GBx8_TRT/resnet50/Server",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Sustainable_Metal_Cloud",
    "Platform": "H200-SXM-141GBx8_TRT",
    "Result": 632197,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XE9680 (8xH200-SXM-141GBx8, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8462Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "uid": "d4650dd03a7b478d",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Sustainable_Metal_Cloud/results/H200-SXM-141GBx8_TRT/resnet50/Server",
    "version": "v5.0",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "acc: 76.078",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/S74G_2U_GH200_96GB_aarch64x1_TRT/resnet50/Server",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "S74G_2U_GH200_96GB_aarch64x1_TRT",
    "Result": 72995.1,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "QuantaGrid S74G-2U (1x GH200-96GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "accelerators_per_node": 1,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "QuantaGrid S74G-2U (1x NVIDIA GH200 96GB HBM3)",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.3",
    "uid": "db65432a47aa4344",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Quanta_Cloud_Technology/results/S74G_2U_GH200_96GB_aarch64x1_TRT/resnet50/Server",
    "version": "v5.0",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "acc: 76.078",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/D74U_7U_H100_SXM_80GBx8_TRT/resnet50/Server",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "D74U_7U_H100_SXM_80GBx8_TRT",
    "Result": 584161,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "QuantaGrid D74H-7U (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.2",
    "uid": "7ec560f5d66a472b",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Quanta_Cloud_Technology/results/D74U_7U_H100_SXM_80GBx8_TRT/resnet50/Server",
    "version": "v5.0",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "acc: 75.730",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/1-node-2S-GNR_86C/resnet50/Server",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "1-node-2S-GNR_86C",
    "Result": 27987.9,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "1-node-2S-GNR_86C",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 0,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 86,
    "host_processor_model_name": "INTEL(R) XEON(R) 6787P",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid-D55X-1U. N/A",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.4",
    "uid": "1228f0507077443f",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Quanta_Cloud_Technology/results/1-node-2S-GNR_86C/resnet50/Server",
    "version": "v5.0",
    "weight_data_types": "INT8"
  },
  {
    "Accuracy": "acc: 76.078",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/D54U_3U_H100_PCIe_80GBx4_TRT/resnet50/Server",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "D54U_3U_H100_PCIe_80GBx4_TRT",
    "Result": 188014,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "QuantaGrid D54U-3U (4x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8.0.43, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54U-3U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.2",
    "uid": "b104051982b34de2",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Quanta_Cloud_Technology/results/D54U_3U_H100_PCIe_80GBx4_TRT/resnet50/Server",
    "version": "v5.0",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "acc: 76.076",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT/resnet50/Server",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT",
    "Result": 632194,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "uid": "856df64e7fda4564",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/NVIDIA/results/H200-SXM-141GBx8_TRT/resnet50/Server",
    "version": "v5.0",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "acc: 76.078",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Oracle/results/H200-SXM-141GBx8_TRT/resnet50/Server",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Oracle",
    "Platform": "H200-SXM-141GBx8_TRT",
    "Result": 632198,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.5 LT",
    "uid": "9c03521941aa4ad2",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Oracle/results/H200-SXM-141GBx8_TRT/resnet50/Server",
    "version": "v5.0",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "acc: 76.078",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC8000_H200_NVLx8_TRT/resnet50/Server",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "ASUSTeK",
    "Platform": "ESC8000_H200_NVLx8_TRT",
    "Result": 540125,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "ASUSTeK ESC8000A-E13P (8x H200-NVL-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H200-NVL-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "AMD EPYC 9475F 48-Core Processo",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Data bandwidth for GPU-PCIe: 504 GB/s; PCIe-NIC: 126 GB/s",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "uid": "15a8ead3e2fa4961",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/ASUSTeK/results/ESC8000_H200_NVLx8_TRT/resnet50/Server",
    "version": "v5.0",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "acc: 76.078",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/GigaComputing/results/G893-SD1_H200-SXM-141GBx8_TRT/resnet50/Server",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "GigaComputing",
    "Platform": "G893-SD1_H200-SXM-141GBx8_TRT",
    "Result": 676219,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "G893-SD1",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "43051ef9282a4528",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/GigaComputing/results/G893-SD1_H200-SXM-141GBx8_TRT/resnet50/Server",
    "version": "v5.0",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "acc: 75.730",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Intel/results/1-node-2S-GNR_128C/resnet50/Server",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Intel",
    "Platform": "1-node-2S-GNR_128C",
    "Result": 40184.8,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "1-node-2S-GNR_128C",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 0,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 128,
    "host_processor_model_name": "INTEL(R) XEON(R) 6980P",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "N/A. N/A",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream 9",
    "uid": "4c4ff8af37584543",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Intel/results/1-node-2S-GNR_128C/resnet50/Server",
    "version": "v5.0",
    "weight_data_types": "INT8"
  },
  {
    "Accuracy": "acc: 76.078",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/C885A_H100_SXMx8_TRT/resnet50/Server",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Cisco",
    "Platform": "C885A_H100_SXMx8_TRT",
    "Result": 652002,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Cisco UCS C885A M8 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 9554 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "uid": "04d9336a1a2a4881",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Cisco/results/C885A_H100_SXMx8_TRT/resnet50/Server",
    "version": "v5.0",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "acc: 75.730",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/1-node-2S-GNR_86C/resnet50/Server",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Cisco",
    "Platform": "1-node-2S-GNR_86C",
    "Result": 27988,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "1-node-2S-GNR_86C",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 0,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 86,
    "host_processor_model_name": "INTEL(R) XEON(R) 6787P",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Cisco UCS C240 M8. N/A",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "uid": "0c6465d0a372433f",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Cisco/results/1-node-2S-GNR_86C/resnet50/Server",
    "version": "v5.0",
    "weight_data_types": "INT8"
  },
  {
    "Accuracy": "acc: 76.078",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/C245M8_H100NVL_94GBx2_TRT/resnet50/Server",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Cisco",
    "Platform": "C245M8_H100NVL_94GBx2_TRT",
    "Result": 109989,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Cisco UCS C245 M8 (2x H100NVL-PCIe-94GB)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 2,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "AMD EPYC 9224",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "uid": "dcd16142117e447a",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Cisco/results/C245M8_H100NVL_94GBx2_TRT/resnet50/Server",
    "version": "v5.0",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "acc: 76.078",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/X215M8_H100NVLx2_TRT/resnet50/Server",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Cisco",
    "Platform": "X215M8_H100NVLx2_TRT",
    "Result": 119990,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Cisco UCS X215c M8 with X440P PCIe node (2x H100NVL-PCIe-94GB)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 2,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "AMD EPYC 9554",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "uid": "1417f8ec58f84df5",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Cisco/results/X215M8_H100NVLx2_TRT/resnet50/Server",
    "version": "v5.0",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "acc: 76.078",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/C885A_M8_H200_SXM_141GBx8_TRT/resnet50/Server",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Cisco",
    "Platform": "C885A_M8_H200_SXM_141GBx8_TRT",
    "Result": 648207,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Cisco UCS C885A M8 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 128,
    "host_processor_model_name": "AMD EPYC 9575F",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "uid": "799630398b044123",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Cisco/results/C885A_M8_H200_SXM_141GBx8_TRT/resnet50/Server",
    "version": "v5.0",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "acc: 76.078",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_821GE_TNHR_H200_SXM_141GBX8_TRT/resnet50/Server",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Supermicro",
    "Platform": "SYS_821GE_TNHR_H200_SXM_141GBX8_TRT",
    "Result": 640203,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "SYS-821GE-TNHR (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8568Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "uid": "6437fd91448241c4",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Supermicro/results/SYS_821GE_TNHR_H200_SXM_141GBX8_TRT/resnet50/Server",
    "version": "v5.0",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "acc: 75.730",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/1-node-2S-GNR_128C/resnet50/Server",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Supermicro",
    "Platform": "1-node-2S-GNR_128C",
    "Result": 40285.5,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "SYS-822GA-NGR3",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 0,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 128,
    "host_processor_model_name": "INTEL(R) XEON(R) 6980P",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "N/A",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "b2ad9179aab6426d",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Supermicro/results/1-node-2S-GNR_128C/resnet50/Server",
    "version": "v5.0",
    "weight_data_types": "INT8"
  },
  {
    "Accuracy": "acc: 76.078",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/SR675v3_H200_SXMx4_TRT/resnet50/Server",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Lenovo",
    "Platform": "SR675v3_H200_SXMx4_TRT",
    "Result": 304031,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "ThinkSystem SR675 V3 (4x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 4,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9655 96-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "uid": "b9e954b8810d4742",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Lenovo/results/SR675v3_H200_SXMx4_TRT/resnet50/Server",
    "version": "v5.0",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "acc: 76.078",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/H100-NVL-94GBx4_TRT/resnet50/Server",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Lenovo",
    "Platform": "H100-NVL-94GBx4_TRT",
    "Result": 265225,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "ThinkSystem SR650a V4 (4x H100-NVL-94GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 4,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 86,
    "host_processor_model_name": "Intel(R) Xeon(R) 6787P",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "uid": "fa9eab4f2ff54eb7",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Lenovo/results/H100-NVL-94GBx4_TRT/resnet50/Server",
    "version": "v5.0",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "acc: 76.078",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/SR780a_V3_H200SXMx8/resnet50/Server",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Lenovo",
    "Platform": "SR780a_V3_H200SXMx8",
    "Result": 670220,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "ThinkSystem SR780a V3(8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8568Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "uid": "fb0bfc413e6c4e4c",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Lenovo/results/SR780a_V3_H200SXMx8/resnet50/Server",
    "version": "v5.0",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "acc: 76.078",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/H200-SXM-141GBx8_TRT/resnet50/Server",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Lenovo",
    "Platform": "H200-SXM-141GBx8_TRT",
    "Result": 673220,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "ThinkSystem SR680a V3(8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8568Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "uid": "2b23d6be49d34556",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Lenovo/results/H200-SXM-141GBx8_TRT/resnet50/Server",
    "version": "v5.0",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "acc: 76.076",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680L_H200_SXM_141GBx8_TRT/resnet50/Server",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Dell",
    "Platform": "XE9680L_H200_SXM_141GBx8_TRT",
    "Result": 632200,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XE9680L (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 120,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "uid": "909a6c83aa18494d",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Dell/results/XE9680L_H200_SXM_141GBx8_TRT/resnet50/Server",
    "version": "v5.0",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "acc: 75.730",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/1-node-2S-GNR_86C/resnet50/Server",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Dell",
    "Platform": "1-node-2S-GNR_86C",
    "Result": 27987.9,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "1-node-2S-GNR_86C",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 0,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 86,
    "host_processor_model_name": "INTEL(R) XEON(R) 6787P",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Dell PowerEdge R670. INT4 for GPT-J, and INT8 for all other models",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04.1",
    "uid": "caab3d31ede347b4",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Dell/results/1-node-2S-GNR_86C/resnet50/Server",
    "version": "v5.0",
    "weight_data_types": "INT8"
  },
  {
    "Accuracy": "acc: 76.076",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE7745_L40Sx8_TRT/resnet50/Server",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Dell",
    "Platform": "XE7745_L40Sx8_TRT",
    "Result": 340047,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XE7745 (8x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 384,
    "host_processor_model_name": "AMD EPYC 9965 192-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "L40S TGP 350W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "uid": "2bfa129c5ac549c1",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Dell/results/XE7745_L40Sx8_TRT/resnet50/Server",
    "version": "v5.0",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "acc: 76.078",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/GATEOverflow/results/RTX4090x2-nvidia-gpu-TensorRT-default_config/resnet50/server",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "GATEOverflow",
    "Platform": "RTX4090x2-nvidia-gpu-TensorRT-default_config",
    "Result": 73725.3,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "GATE Overflow Intel Sapphire Rapids (2x RTX 4090)",
    "SystemType": "datacenter,edge",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "accelerators_per_node": 2,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04 (linux-6.8.0-52-generic-glibc2.31)",
    "uid": "84a711254ba643fe",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/GATEOverflow/results/RTX4090x2-nvidia-gpu-TensorRT-default_config/resnet50/server",
    "version": "v5.0",
    "weight_data_types": "int8"
  }
]
