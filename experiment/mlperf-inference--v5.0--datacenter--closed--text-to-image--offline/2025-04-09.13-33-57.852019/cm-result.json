[
  {
    "Accuracy": "CLIP_SCORE: 31.791159902513026  FID_SCORE: 23.522759479977594",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_HPE_VAST_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "HPE",
    "Platform": "HPE_Cray_XD670_H100_SXM_80GBx8_HPE_VAST_TRT",
    "Result": 18.0963,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "HPE Cray XD670 with HPE GreenLake for File Storage (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04.1 LTS",
    "uid": "6cf4a6a9c1114858",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_HPE_VAST_TRT/stable-diffusion-xl/Offline",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.799853138625622  FID_SCORE: 23.49218796720743",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_PROLIANT_DL380A_H200_NVL_141GBX8_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "HPE",
    "Platform": "HPE_PROLIANT_DL380A_H200_NVL_141GBX8_TRT",
    "Result": 16.3763,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "HPE ProLiant DL380a Compute Gen12 (8x H200-NVL-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-NVL-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 192,
    "host_processor_model_name": "Intel(R) Xeon(R) 6740E",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04.1 LTS",
    "uid": "570d3c3592b34ebd",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/HPE/results/HPE_PROLIANT_DL380A_H200_NVL_141GBX8_TRT/stable-diffusion-xl/Offline",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.797240511476993  FID_SCORE: 23.46331704962597",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "HPE",
    "Platform": "HPE_Cray_XD670_H100_SXM_80GBx8_TRT",
    "Result": 17.9889,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "HPE Cray XD670 with Cray ClusterStor (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04.1 LTS",
    "uid": "1d9ce136291044ce",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT/stable-diffusion-xl/Offline",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.782495045363902  FID_SCORE: 23.562617456980263",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "HPE",
    "Platform": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT",
    "Result": 2.46365,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "HPE ProLiant Compute DL384 Gen12 (1x GH200-144GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "accelerators_per_node": 1,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.7",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA GH200 144GB HBM3e",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04.1 LTS",
    "uid": "6cf45490dc7c42ce",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/HPE/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/stable-diffusion-xl/Offline",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.789734811782836  FID_SCORE: 23.550848825622325",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_ProLiant_DL380a_L40S_PCIe_48GBx8_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "HPE",
    "Platform": "HPE_ProLiant_DL380a_L40S_PCIe_48GBx8_TRT",
    "Result": 6.12586,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "HPE ProLiant Compute DL380a Gen12 (8x L40S-PCIe-48GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "Intel(R) Xeon(R) 6740E",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04.1 LTS",
    "uid": "a4f1e670b9b24eb4",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/HPE/results/HPE_ProLiant_DL380a_L40S_PCIe_48GBx8_TRT/stable-diffusion-xl/Offline",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.80175178319216  FID_SCORE: 23.46739030477937",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_Cray_XD670_H200_SXM_141GBx8_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "HPE",
    "Platform": "HPE_Cray_XD670_H200_SXM_141GBx8_TRT",
    "Result": 18.9944,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "HPE Cray XD670 with Cray ClusterStor (8x H200-SXM-141GB)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8562Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "RHEL 9.4",
    "uid": "3fcd0adcf30b40df",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/HPE/results/HPE_Cray_XD670_H200_SXM_141GBx8_TRT/stable-diffusion-xl/Offline",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.80902427881956  FID_SCORE: 23.69976192882052",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x2_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "HPE",
    "Platform": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x2_TRT",
    "Result": 5.02472,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "HPE ProLiant Compute DL384 Gen12 (2x GH200-144GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "accelerators_per_node": 2,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 144,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "NVIDIA GH200 144GB HBM3e",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04.1 LTS",
    "uid": "22d6ce2d35474099",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/HPE/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x2_TRT/stable-diffusion-xl/Offline",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.74227772563696  FID_SCORE: 23.448568676048012",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Google/results/trillium_x4_flax/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Google",
    "Platform": "trillium_x4_flax",
    "Result": 6.07925,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "tpu-v6e-4",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "TPU Trillium",
    "accelerators_per_node": 4,
    "compliance": 0,
    "errors": 0,
    "framework": "flax",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 180,
    "host_processor_model_name": "AMD EPYC 9B14",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Linux version 6.2.0-1019-gcp (buildd@lcy02-amd64-032) (x86_64-linux-gnu-gcc-12 (Ubuntu 12.3.0-1ubuntu1~22.04) 12.3.0, GNU ld (GNU Binutils for Ubuntu) 2.38) #21~22.04.1-Ubuntu SMP Thu Nov 16 18:18:34 UTC 2023",
    "uid": "87540ecfe66646e4",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Google/results/trillium_x4_flax/stable-diffusion-xl/Offline",
    "version": "v5.0",
    "weight_data_types": "bf16"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.802398339807986  FID_SCORE: 23.53225102301252",
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Google/results/B200-SXM-180GBx8_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Google",
    "Platform": "B200-SXM-180GBx8_TRT",
    "Result": 30.3057,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX B200 (8x B200-SXM-180GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA B200-SXM-180GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8570",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "B200 TGP 1000W",
    "number_of_nodes": 1,
    "operating_system": "Debian 12",
    "uid": "f9bea3aefed244ea",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Google/results/B200-SXM-180GBx8_TRT/stable-diffusion-xl/Offline",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.803722438812255  FID_SCORE: 23.54248239918644",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/S74G_2U_GH200_96GB_aarch64x1_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "S74G_2U_GH200_96GB_aarch64x1_TRT",
    "Result": 2.41908,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "QuantaGrid S74G-2U (1x GH200-96GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "accelerators_per_node": 1,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "QuantaGrid S74G-2U (1x NVIDIA GH200 96GB HBM3)",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.3",
    "uid": "253628941ffb4fee",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Quanta_Cloud_Technology/results/S74G_2U_GH200_96GB_aarch64x1_TRT/stable-diffusion-xl/Offline",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.804742647111414  FID_SCORE: 23.440996339050457",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/D74U_7U_H100_SXM_80GBx8_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "D74U_7U_H100_SXM_80GBx8_TRT",
    "Result": 18.3676,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "QuantaGrid D74H-7U (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.2",
    "uid": "a36ea96a138a42eb",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Quanta_Cloud_Technology/results/D74U_7U_H100_SXM_80GBx8_TRT/stable-diffusion-xl/Offline",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.810240924060345  FID_SCORE: 23.576431065002623",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/D54U_3U_H100_PCIe_80GBx4_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "D54U_3U_H100_PCIe_80GBx4_TRT",
    "Result": 5.34798,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "QuantaGrid D54U-3U (4x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8.0.43, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54U-3U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.2",
    "uid": "2df8dbc638dc47df",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Quanta_Cloud_Technology/results/D54U_3U_H100_PCIe_80GBx4_TRT/stable-diffusion-xl/Offline",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.80135320454836  FID_SCORE: 23.476230477547688",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "NVIDIA",
    "Platform": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT",
    "Result": 2.52,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "HPE ProLiant Compute DL384 Gen12 (1x GH200-144GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "accelerators_per_node": 1,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 144,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA GH200 144GB HBM3e",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "uid": "ef18c225b6684930",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/stable-diffusion-xl/Offline",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.79539393246174  FID_SCORE: 23.691262382725427",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/B200-SXM-180GBx8_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "NVIDIA",
    "Platform": "B200-SXM-180GBx8_TRT",
    "Result": 30.3752,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX B200 (8x B200-SXM-180GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA B200-SXM-180GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8570",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "B200 TGP 1000W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "uid": "8c575963dbc94607",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/NVIDIA/results/B200-SXM-180GBx8_TRT/stable-diffusion-xl/Offline",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.78876639187336  FID_SCORE: 23.792448566214148",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT",
    "Result": 18.989,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "uid": "a2f0fccd3a264547",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/NVIDIA/results/H200-SXM-141GBx8_TRT/stable-diffusion-xl/Offline",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.749402277171612  FID_SCORE: 23.813210898858188",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/AMD/results/8xMI325x_2xEPYC-9655/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "AMD",
    "Platform": "8xMI325x_2xEPYC-9655",
    "Result": 17.0963,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Quanta S7PA",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "AMD Instinct MI325X 256GB HBM3E",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "shark-ai 3.3.0",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": "N/A",
    "host_processor_model_name": "2xAMD EPYC 9655",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.5 LTS (Jammy Jellyfish)",
    "uid": "2489e0d7985e4fc9",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/AMD/results/8xMI325x_2xEPYC-9655/stable-diffusion-xl/Offline",
    "version": "v5.0",
    "weight_data_types": "fp8,fp16,int8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.802840944826603  FID_SCORE: 23.511360773911292",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC8000_H200_NVLx8_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "ASUSTeK",
    "Platform": "ESC8000_H200_NVLx8_TRT",
    "Result": 16.0315,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ASUSTeK ESC8000A-E13P (8x H200-NVL-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-NVL-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "AMD EPYC 9475F 48-Core Processo",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Data bandwidth for GPU-PCIe: 504 GB/s; PCIe-NIC: 126 GB/s",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "uid": "ada8b622e5b5448c",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/ASUSTeK/results/ESC8000_H200_NVLx8_TRT/stable-diffusion-xl/Offline",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.78671993792057  FID_SCORE: 23.582817623654137",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/GigaComputing/results/G893-SD1_H200-SXM-141GBx8_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "GigaComputing",
    "Platform": "G893-SD1_H200-SXM-141GBx8_TRT",
    "Result": 19.1766,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "G893-SD1",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "3bf0f9a4a9694347",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/GigaComputing/results/G893-SD1_H200-SXM-141GBx8_TRT/stable-diffusion-xl/Offline",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.78628176897764  FID_SCORE: 23.639919101794533",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/C885A_H100_SXMx8_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Cisco",
    "Platform": "C885A_H100_SXMx8_TRT",
    "Result": 18.375,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Cisco UCS C885A M8 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 9554 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "uid": "c1ae062ce3ee49f0",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Cisco/results/C885A_H100_SXMx8_TRT/stable-diffusion-xl/Offline",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.808587335050106  FID_SCORE: 23.335745536305694",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/L40Sx2_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Cisco",
    "Platform": "L40Sx2_TRT",
    "Result": 1.43813,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "UCS C245 M8 (2x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 2,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 9684X 128-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "uid": "13d24e5ee52e4baf",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Cisco/results/L40Sx2_TRT/stable-diffusion-xl/Offline",
    "version": "v5.0",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.805966468453406  FID_SCORE: 23.663120012461945",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_A21GE_NBRT_B200_SXM_180GBx8_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Supermicro",
    "Platform": "SYS_A21GE_NBRT_B200_SXM_180GBx8_TRT",
    "Result": 30.3449,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "SYS-A21GE-NBRT (8x B200-SXM-180GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA B200-SXM-180GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8568Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "B200 TGP 1000W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.5 LTS",
    "uid": "fd3033abe254497a",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Supermicro/results/SYS_A21GE_NBRT_B200_SXM_180GBx8_TRT/stable-diffusion-xl/Offline",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.796432983279228  FID_SCORE: 23.63745833910025",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_821GE_TNHR_H200_SXM_141GBX8_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Supermicro",
    "Platform": "SYS_821GE_TNHR_H200_SXM_141GBX8_TRT",
    "Result": 19.1502,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "SYS-821GE-TNHR (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8568Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "uid": "36df6759213f473b",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Supermicro/results/SYS_821GE_TNHR_H200_SXM_141GBX8_TRT/stable-diffusion-xl/Offline",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.80766055673361  FID_SCORE: 23.46626388405309",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H200_SXM_141GBX8_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Supermicro",
    "Platform": "AS_4125GS_TNHR2_LCC_H200_SXM_141GBX8_TRT",
    "Result": 19.445,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AS-4125GS-TNHR2-LCC (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "uid": "c543eca9faf243be",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H200_SXM_141GBX8_TRT/stable-diffusion-xl/Offline",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.782404944896697  FID_SCORE: 23.432135408638146",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS522GA_H200X8_NVL_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Supermicro",
    "Platform": "SYS522GA_H200X8_NVL_TRT",
    "Result": 16.7801,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "SYS-522GA-NRT(8x H200-NVL-141GB)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-NVL-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 120,
    "host_processor_model_name": "Intel(R) Xeon(R) 6979P",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "uid": "b464100c4da7474b",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Supermicro/results/SYS522GA_H200X8_NVL_TRT/stable-diffusion-xl/Offline",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.80031978905201  FID_SCORE: 23.555152410708388",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/SR675v3_H200_SXMx4_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Lenovo",
    "Platform": "SR675v3_H200_SXMx4_TRT",
    "Result": 9.56261,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ThinkSystem SR675 V3 (4x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 4,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9655 96-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "uid": "b6813c99862a4ab1",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Lenovo/results/SR675v3_H200_SXMx4_TRT/stable-diffusion-xl/Offline",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.802490544915198  FID_SCORE: 23.61380323296362",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/H100-NVL-94GBx4_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Lenovo",
    "Platform": "H100-NVL-94GBx4_TRT",
    "Result": 6.45611,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ThinkSystem SR650a V4 (4x H100-NVL-94GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 4,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 86,
    "host_processor_model_name": "Intel(R) Xeon(R) 6787P",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "uid": "3e9753b9f6a74d2e",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Lenovo/results/H100-NVL-94GBx4_TRT/stable-diffusion-xl/Offline",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.803141524493693  FID_SCORE: 23.47998876836482",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/SR780a_V3_H200SXMx8/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Lenovo",
    "Platform": "SR780a_V3_H200SXMx8",
    "Result": 19.2932,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ThinkSystem SR780a V3(8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8568Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "uid": "76258643a7424c15",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Lenovo/results/SR780a_V3_H200SXMx8/stable-diffusion-xl/Offline",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.81166176825762  FID_SCORE: 23.69056773380396",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/H200-SXM-141GBx8_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Lenovo",
    "Platform": "H200-SXM-141GBx8_TRT",
    "Result": 19.428,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ThinkSystem SR680a V3(8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8568Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "uid": "c3999d2d464547b5",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Lenovo/results/H200-SXM-141GBx8_TRT/stable-diffusion-xl/Offline",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.80854401320219  FID_SCORE: 23.59712165959388",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680L_H200_SXM_141GBx8_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Dell",
    "Platform": "XE9680L_H200_SXM_141GBx8_TRT",
    "Result": 19.2569,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE9680L (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 120,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "uid": "ba72deca4a504066",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Dell/results/XE9680L_H200_SXM_141GBx8_TRT/stable-diffusion-xl/Offline",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.80229423880577  FID_SCORE: 23.639097191271162",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_H200_SXM_141GBx8_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Dell",
    "Platform": "XE9680_H200_SXM_141GBx8_TRT",
    "Result": 18.9857,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE9680 (8xH200-SXM-141GBx8, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8568Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "uid": "5e70d49cebe6495c",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Dell/results/XE9680_H200_SXM_141GBx8_TRT/stable-diffusion-xl/Offline",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.805613597631453  FID_SCORE: 23.353711325667007",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE7745_L40Sx8_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Dell",
    "Platform": "XE7745_L40Sx8_TRT",
    "Result": 6.21681,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE7745 (8x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 384,
    "host_processor_model_name": "AMD EPYC 9965 192-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "L40S TGP 350W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "uid": "7c940ae57fdd4ee8",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Dell/results/XE7745_L40Sx8_TRT/stable-diffusion-xl/Offline",
    "version": "v5.0",
    "weight_data_types": "fp8"
  }
]
