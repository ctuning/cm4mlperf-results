[
  {
    "Accuracy": "CLIP_SCORE: 31.792714341282846  FID_SCORE: 23.604393871999378",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_HPE_VAST_TRT/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "HPE",
    "Platform": "HPE_Cray_XD670_H100_SXM_80GBx8_HPE_VAST_TRT",
    "Result": 16.0366,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "HPE Cray XD670 with HPE GreenLake for File Storage (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04.1 LTS",
    "uid": "d7067e34920f434c",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_HPE_VAST_TRT/stable-diffusion-xl/Server",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.804227357804777  FID_SCORE: 23.492989373854982",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_PROLIANT_DL380A_H200_NVL_141GBX8_TRT/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "HPE",
    "Platform": "HPE_PROLIANT_DL380A_H200_NVL_141GBX8_TRT",
    "Result": 15.4519,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "HPE ProLiant DL380a Compute Gen12 (8x H200-NVL-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H200-NVL-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 192,
    "host_processor_model_name": "Intel(R) Xeon(R) 6740E",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04.1 LTS",
    "uid": "d8002cd8e361445d",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/HPE/results/HPE_PROLIANT_DL380A_H200_NVL_141GBX8_TRT/stable-diffusion-xl/Server",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.803606552779673  FID_SCORE: 23.460299009604853",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "HPE",
    "Platform": "HPE_Cray_XD670_H100_SXM_80GBx8_TRT",
    "Result": 16.0365,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "HPE Cray XD670 with Cray ClusterStor (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04.1 LTS",
    "uid": "f561a6c793fd4382",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT/stable-diffusion-xl/Server",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.79840267509222  FID_SCORE: 23.684881500872052",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "HPE",
    "Platform": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT",
    "Result": 2.13661,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "HPE ProLiant Compute DL384 Gen12 (1x GH200-144GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "accelerators_per_node": 1,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.7",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA GH200 144GB HBM3e",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04.1 LTS",
    "uid": "2dafb09a5cde40a8",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/HPE/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/stable-diffusion-xl/Server",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.80472930520773  FID_SCORE: 23.513878979873425",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_ProLiant_DL380a_L40S_PCIe_48GBx8_TRT/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "HPE",
    "Platform": "HPE_ProLiant_DL380a_L40S_PCIe_48GBx8_TRT",
    "Result": 5.00725,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "HPE ProLiant Compute DL380a Gen12 (8x L40S-PCIe-48GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "Intel(R) Xeon(R) 6740E",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04.1 LTS",
    "uid": "cc56570795b54370",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/HPE/results/HPE_ProLiant_DL380a_L40S_PCIe_48GBx8_TRT/stable-diffusion-xl/Server",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.791932136416435  FID_SCORE: 23.41548334114583",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_Cray_XD670_H200_SXM_141GBx8_TRT/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "HPE",
    "Platform": "HPE_Cray_XD670_H200_SXM_141GBx8_TRT",
    "Result": 16.7592,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "HPE Cray XD670 with Cray ClusterStor (8x H200-SXM-141GB)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8562Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "RHEL 9.4",
    "uid": "1dd04a9aa8e4461a",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/HPE/results/HPE_Cray_XD670_H200_SXM_141GBx8_TRT/stable-diffusion-xl/Server",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.803023325204848  FID_SCORE: 23.56682904072005",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x2_TRT/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "HPE",
    "Platform": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x2_TRT",
    "Result": 4.33578,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "HPE ProLiant Compute DL384 Gen12 (2x GH200-144GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "accelerators_per_node": 2,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 144,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "NVIDIA GH200 144GB HBM3e",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04.1 LTS",
    "uid": "d061a642467247d1",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/HPE/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x2_TRT/stable-diffusion-xl/Server",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.745544374287128  FID_SCORE: 23.5750735160085",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Google/results/trillium_x4_flax/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Google",
    "Platform": "trillium_x4_flax",
    "Result": 5.47995,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "tpu-v6e-4",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "TPU Trillium",
    "accelerators_per_node": 4,
    "compliance": 0,
    "errors": 0,
    "framework": "flax",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 180,
    "host_processor_model_name": "AMD EPYC 9B14",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Linux version 6.2.0-1019-gcp (buildd@lcy02-amd64-032) (x86_64-linux-gnu-gcc-12 (Ubuntu 12.3.0-1ubuntu1~22.04) 12.3.0, GNU ld (GNU Binutils for Ubuntu) 2.38) #21~22.04.1-Ubuntu SMP Thu Nov 16 18:18:34 UTC 2023",
    "uid": "928503de5d5449bd",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Google/results/trillium_x4_flax/stable-diffusion-xl/Server",
    "version": "v5.0",
    "weight_data_types": "bf16"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.79837848931551  FID_SCORE: 23.706930005686615",
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Google/results/B200-SXM-180GBx8_TRT/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Google",
    "Platform": "B200-SXM-180GBx8_TRT",
    "Result": 28.4484,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NVIDIA DGX B200 (8x B200-SXM-180GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA B200-SXM-180GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8570",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "B200 TGP 1000W",
    "number_of_nodes": 1,
    "operating_system": "Debian 12",
    "uid": "12e59e39de664e95",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Google/results/B200-SXM-180GBx8_TRT/stable-diffusion-xl/Server",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.7980243691802  FID_SCORE: 23.831421912545295",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/S74G_2U_GH200_96GB_aarch64x1_TRT/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "S74G_2U_GH200_96GB_aarch64x1_TRT",
    "Result": 1.93745,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "QuantaGrid S74G-2U (1x GH200-96GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "accelerators_per_node": 1,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "QuantaGrid S74G-2U (1x NVIDIA GH200 96GB HBM3)",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.3",
    "uid": "111bb78b8a144a13",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Quanta_Cloud_Technology/results/S74G_2U_GH200_96GB_aarch64x1_TRT/stable-diffusion-xl/Server",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.813197127580644  FID_SCORE: 23.555730383376897",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/D74U_7U_H100_SXM_80GBx8_TRT/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "D74U_7U_H100_SXM_80GBx8_TRT",
    "Result": 16.0378,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "QuantaGrid D74H-7U (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.2",
    "uid": "95d9c6de26744a95",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Quanta_Cloud_Technology/results/D74U_7U_H100_SXM_80GBx8_TRT/stable-diffusion-xl/Server",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.811962921917438  FID_SCORE: 23.492023350926956",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/D54U_3U_H100_PCIe_80GBx4_TRT/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "D54U_3U_H100_PCIe_80GBx4_TRT",
    "Result": 4.22011,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "QuantaGrid D54U-3U (4x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8.0.43, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54U-3U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.2",
    "uid": "5de6a9f7e41a4cac",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Quanta_Cloud_Technology/results/D54U_3U_H100_PCIe_80GBx4_TRT/stable-diffusion-xl/Server",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.793544735312462  FID_SCORE: 23.58309966459666",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "NVIDIA",
    "Platform": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT",
    "Result": 2.27968,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "HPE ProLiant Compute DL384 Gen12 (1x GH200-144GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "accelerators_per_node": 1,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 144,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA GH200 144GB HBM3e",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "uid": "438393066fc14d9b",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/stable-diffusion-xl/Server",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.807248744666577  FID_SCORE: 23.519696025094674",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/B200-SXM-180GBx8_TRT/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "NVIDIA",
    "Platform": "B200-SXM-180GBx8_TRT",
    "Result": 28.4443,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NVIDIA DGX B200 (8x B200-SXM-180GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA B200-SXM-180GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8570",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "B200 TGP 1000W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "uid": "5bbb3a3e956c4607",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/NVIDIA/results/B200-SXM-180GBx8_TRT/stable-diffusion-xl/Server",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.79781420201063  FID_SCORE: 23.62683413159857",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT",
    "Result": 18.2995,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "uid": "bddd8eda88b64b99",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/NVIDIA/results/H200-SXM-141GBx8_TRT/stable-diffusion-xl/Server",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.730368359684945  FID_SCORE: 23.91373696288406",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/AMD/results/8xMI325x_2xEPYC-9655/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "AMD",
    "Platform": "8xMI325x_2xEPYC-9655",
    "Result": 16.1757,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Quanta S7PA",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "AMD Instinct MI325X 256GB HBM3E",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "shark-ai 3.3.0",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": "N/A",
    "host_processor_model_name": "2xAMD EPYC 9655",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.5 LTS (Jammy Jellyfish)",
    "uid": "42b5cf4674744590",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/AMD/results/8xMI325x_2xEPYC-9655/stable-diffusion-xl/Server",
    "version": "v5.0",
    "weight_data_types": "fp8,fp16,int8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.801456088721753  FID_SCORE: 23.56716557990319",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC8000_H200_NVLx8_TRT/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "ASUSTeK",
    "Platform": "ESC8000_H200_NVLx8_TRT",
    "Result": 14.8098,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "ASUSTeK ESC8000A-E13P (8x H200-NVL-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H200-NVL-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "AMD EPYC 9475F 48-Core Processo",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Data bandwidth for GPU-PCIe: 504 GB/s; PCIe-NIC: 126 GB/s",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "uid": "081bfaaeab134d4f",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/ASUSTeK/results/ESC8000_H200_NVLx8_TRT/stable-diffusion-xl/Server",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.7784531801939  FID_SCORE: 23.554837996792344",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/GigaComputing/results/G893-SD1_H200-SXM-141GBx8_TRT/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "GigaComputing",
    "Platform": "G893-SD1_H200-SXM-141GBx8_TRT",
    "Result": 16.7579,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "G893-SD1",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "ea525b4a26304bbc",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/GigaComputing/results/G893-SD1_H200-SXM-141GBx8_TRT/stable-diffusion-xl/Server",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.792985874712468  FID_SCORE: 23.588434173987707",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/C885A_H100_SXMx8_TRT/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Cisco",
    "Platform": "C885A_H100_SXMx8_TRT",
    "Result": 17.7917,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Cisco UCS C885A M8 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 9554 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "uid": "093e69e9d7d24364",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Cisco/results/C885A_H100_SXMx8_TRT/stable-diffusion-xl/Server",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.80504818171263  FID_SCORE: 23.24227488562292",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/L40Sx2_TRT/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Cisco",
    "Platform": "L40Sx2_TRT",
    "Result": 1.26862,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "UCS C245 M8 (2x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 2,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 9684X 128-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "uid": "2f126c2989e144c1",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Cisco/results/L40Sx2_TRT/stable-diffusion-xl/Server",
    "version": "v5.0",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.801023640334606  FID_SCORE: 23.791972314933673",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_A21GE_NBRT_B200_SXM_180GBx8_TRT/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Supermicro",
    "Platform": "SYS_A21GE_NBRT_B200_SXM_180GBx8_TRT",
    "Result": 28.9204,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "SYS-A21GE-NBRT (8x B200-SXM-180GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA B200-SXM-180GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8568Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "B200 TGP 1000W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.5 LTS",
    "uid": "c3d63f4220b348ad",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Supermicro/results/SYS_A21GE_NBRT_B200_SXM_180GBx8_TRT/stable-diffusion-xl/Server",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.800337046980857  FID_SCORE: 23.554725637033187",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_821GE_TNHR_H200_SXM_141GBX8_TRT/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Supermicro",
    "Platform": "SYS_821GE_TNHR_H200_SXM_141GBX8_TRT",
    "Result": 18.2986,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "SYS-821GE-TNHR (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8568Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "uid": "ebf9fc81969742f1",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Supermicro/results/SYS_821GE_TNHR_H200_SXM_141GBX8_TRT/stable-diffusion-xl/Server",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.793607643842698  FID_SCORE: 23.562609863230307",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H200_SXM_141GBX8_TRT/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Supermicro",
    "Platform": "AS_4125GS_TNHR2_LCC_H200_SXM_141GBX8_TRT",
    "Result": 18.3003,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "AS-4125GS-TNHR2-LCC (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "uid": "166f5dc789dc44d2",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H200_SXM_141GBX8_TRT/stable-diffusion-xl/Server",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.785902760326863  FID_SCORE: 23.351197923984955",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS522GA_H200X8_NVL_TRT/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Supermicro",
    "Platform": "SYS522GA_H200X8_NVL_TRT",
    "Result": 15.9458,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "SYS-522GA-NRT(8x H200-NVL-141GB)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H200-NVL-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 120,
    "host_processor_model_name": "Intel(R) Xeon(R) 6979P",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "uid": "05a1e9bc57ba4dd0",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Supermicro/results/SYS522GA_H200X8_NVL_TRT/stable-diffusion-xl/Server",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.79830046325922  FID_SCORE: 23.524099025220153",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/SR675v3_H200_SXMx4_TRT/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Lenovo",
    "Platform": "SR675v3_H200_SXMx4_TRT",
    "Result": 8.2719,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "ThinkSystem SR675 V3 (4x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 4,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9655 96-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "uid": "08e05314e9f243d3",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Lenovo/results/SR675v3_H200_SXMx4_TRT/stable-diffusion-xl/Server",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.810538924634457  FID_SCORE: 23.45221119431909",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/H100-NVL-94GBx4_TRT/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Lenovo",
    "Platform": "H100-NVL-94GBx4_TRT",
    "Result": 5.9023,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "ThinkSystem SR650a V4 (4x H100-NVL-94GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 4,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 86,
    "host_processor_model_name": "Intel(R) Xeon(R) 6787P",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "uid": "3174a05e55214c43",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Lenovo/results/H100-NVL-94GBx4_TRT/stable-diffusion-xl/Server",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.798954802751542  FID_SCORE: 23.50787933330622",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/SR780a_V3_H200SXMx8/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Lenovo",
    "Platform": "SR780a_V3_H200SXMx8",
    "Result": 16.676,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "ThinkSystem SR780a V3(8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8568Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "uid": "f6603e811b7f427d",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Lenovo/results/SR780a_V3_H200SXMx8/stable-diffusion-xl/Server",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.812579998373984  FID_SCORE: 23.70907615331413",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/H200-SXM-141GBx8_TRT/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Lenovo",
    "Platform": "H200-SXM-141GBx8_TRT",
    "Result": 16.6765,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "ThinkSystem SR680a V3(8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8568Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "uid": "ddea56ae18a34cbe",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Lenovo/results/H200-SXM-141GBx8_TRT/stable-diffusion-xl/Server",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.802012953162194  FID_SCORE: 23.633022521689668",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680L_H200_SXM_141GBx8_TRT/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Dell",
    "Platform": "XE9680L_H200_SXM_141GBx8_TRT",
    "Result": 16.676,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XE9680L (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 120,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "uid": "c68f92f349fb46a9",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Dell/results/XE9680L_H200_SXM_141GBx8_TRT/stable-diffusion-xl/Server",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.81307735443115  FID_SCORE: 23.72052571420187",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_H200_SXM_141GBx8_TRT/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Dell",
    "Platform": "XE9680_H200_SXM_141GBx8_TRT",
    "Result": 16.676,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XE9680 (8xH200-SXM-141GBx8, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8568Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "uid": "90772f8119524069",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Dell/results/XE9680_H200_SXM_141GBx8_TRT/stable-diffusion-xl/Server",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.80323361426592  FID_SCORE: 23.38498902670716",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE7745_L40Sx8_TRT/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Dell",
    "Platform": "XE7745_L40Sx8_TRT",
    "Result": 5.94506,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XE7745 (8x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 384,
    "host_processor_model_name": "AMD EPYC 9965 192-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "L40S TGP 350W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "uid": "e8406bf8f3e6426c",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Dell/results/XE7745_L40Sx8_TRT/stable-diffusion-xl/Server",
    "version": "v5.0",
    "weight_data_types": "fp8"
  }
]
