[
  {
    "Accuracy": "ROUGE1: 44.6821  ROUGE2: 22.2379  ROUGEL: 28.8722  TOKENS_PER_SAMPLE: 289.4",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/H100-NVL-94GBx8_TRT/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "Fujitsu",
    "Platform": "H100-NVL-94GBx8_TRT",
    "Result": 18084.9,
    "Result_Units": "Tokens/s",
    "Scenario": "Offline",
    "SystemName": "PRIMERGY CDI (8x H100NVL, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": true,
    "host_processor_core_count": 32,
    "host_processor_model_name": "INTEL(R) XEON(R) GOLD 6530",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "uid": "d0f7ca32394e4cce",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Fujitsu/results/H100-NVL-94GBx8_TRT/llama2-70b-99/Offline",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "ROUGE1: 44.6821  ROUGE2: 22.2379  ROUGEL: 28.8722  TOKENS_PER_SAMPLE: 289.4",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/H100-NVL-94GBx8_TRT/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "Fujitsu",
    "Platform": "H100-NVL-94GBx8_TRT",
    "Result": null,
    "Result_Power": 4952.046366279061,
    "Result_Units": "Watts",
    "Scenario": "Offline",
    "SystemName": "PRIMERGY CDI (8x H100NVL, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Watts",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": true,
    "host_processor_core_count": 32,
    "host_processor_model_name": "INTEL(R) XEON(R) GOLD 6530",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "uid": "038daa1bb03e48b5",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Fujitsu/results/H100-NVL-94GBx8_TRT/llama2-70b-99/Offline",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "ROUGE1: 43.1118  ROUGE2: 20.1071  ROUGEL: 29.9676  GEN_LEN: 4153194",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/H100-NVL-94GBx8_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "Fujitsu",
    "Platform": "H100-NVL-94GBx8_TRT",
    "Result": 14769.7,
    "Result_Units": "Tokens/s",
    "Scenario": "Offline",
    "SystemName": "PRIMERGY CDI (8x H100NVL, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": true,
    "host_processor_core_count": 32,
    "host_processor_model_name": "INTEL(R) XEON(R) GOLD 6530",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "uid": "e71fde87a2334997",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Fujitsu/results/H100-NVL-94GBx8_TRT/gptj-99.9/Offline",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "ROUGE1: 43.1118  ROUGE2: 20.1071  ROUGEL: 29.9676  GEN_LEN: 4153194",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/H100-NVL-94GBx8_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "Fujitsu",
    "Platform": "H100-NVL-94GBx8_TRT",
    "Result": null,
    "Result_Power": 4972.457389162564,
    "Result_Units": "Watts",
    "Scenario": "Offline",
    "SystemName": "PRIMERGY CDI (8x H100NVL, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Watts",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": true,
    "host_processor_core_count": 32,
    "host_processor_model_name": "INTEL(R) XEON(R) GOLD 6530",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "uid": "02c08585545d44e3",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Fujitsu/results/H100-NVL-94GBx8_TRT/gptj-99.9/Offline",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "ROUGE1: 43.1118  ROUGE2: 20.1071  ROUGEL: 29.9676  GEN_LEN: 4153194",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/H100-NVL-94GBx8_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Fujitsu",
    "Platform": "H100-NVL-94GBx8_TRT",
    "Result": 14769.7,
    "Result_Units": "Tokens/s",
    "Scenario": "Offline",
    "SystemName": "PRIMERGY CDI (8x H100NVL, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": true,
    "host_processor_core_count": 32,
    "host_processor_model_name": "INTEL(R) XEON(R) GOLD 6530",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "uid": "0dc0a0201c9c45d8",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Fujitsu/results/H100-NVL-94GBx8_TRT/gptj-99/Offline",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "ROUGE1: 43.1118  ROUGE2: 20.1071  ROUGEL: 29.9676  GEN_LEN: 4153194",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/H100-NVL-94GBx8_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Fujitsu",
    "Platform": "H100-NVL-94GBx8_TRT",
    "Result": null,
    "Result_Power": 4972.457389162564,
    "Result_Units": "Watts",
    "Scenario": "Offline",
    "SystemName": "PRIMERGY CDI (8x H100NVL, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Watts",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": true,
    "host_processor_core_count": 32,
    "host_processor_model_name": "INTEL(R) XEON(R) GOLD 6530",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "uid": "a9b434dd44e44bf1",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Fujitsu/results/H100-NVL-94GBx8_TRT/gptj-99/Offline",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "ROUGE1: 44.6743  ROUGE2: 22.2269  ROUGEL: 28.8649  TOKENS_PER_SAMPLE: 289.3",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/H100-NVL-94GBx8_TRT/llama2-70b-interactive-99/Offline",
    "MlperfModel": "llama2-70b-interactive-99",
    "Model": "llama2-70b-interactive-99",
    "Organization": "Fujitsu",
    "Platform": "H100-NVL-94GBx8_TRT",
    "Result": 15553.3,
    "Result_Units": "Tokens/s",
    "Scenario": "Offline",
    "SystemName": "PRIMERGY CDI (8x H100NVL, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": true,
    "host_processor_core_count": 32,
    "host_processor_model_name": "INTEL(R) XEON(R) GOLD 6530",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "uid": "0a628808660b4d7c",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Fujitsu/results/H100-NVL-94GBx8_TRT/llama2-70b-interactive-99/Offline",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "ROUGE1: 44.6743  ROUGE2: 22.2269  ROUGEL: 28.8649  TOKENS_PER_SAMPLE: 289.3",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/H100-NVL-94GBx8_TRT/llama2-70b-interactive-99/Offline",
    "MlperfModel": "llama2-70b-interactive-99",
    "Model": "llama2-70b-interactive-99",
    "Organization": "Fujitsu",
    "Platform": "H100-NVL-94GBx8_TRT",
    "Result": null,
    "Result_Power": 4852.332482683189,
    "Result_Units": "Watts",
    "Scenario": "Offline",
    "SystemName": "PRIMERGY CDI (8x H100NVL, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Watts",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": true,
    "host_processor_core_count": 32,
    "host_processor_model_name": "INTEL(R) XEON(R) GOLD 6530",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "uid": "5c1c868c168943f3",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Fujitsu/results/H100-NVL-94GBx8_TRT/llama2-70b-interactive-99/Offline",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "ROUGE1: 44.6743  ROUGE2: 22.2269  ROUGEL: 28.8649  TOKENS_PER_SAMPLE: 289.3",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/H100-NVL-94GBx8_TRT/llama2-70b-interactive-99.9/Offline",
    "MlperfModel": "llama2-70b-interactive-99.9",
    "Model": "llama2-70b-interactive-99.9",
    "Organization": "Fujitsu",
    "Platform": "H100-NVL-94GBx8_TRT",
    "Result": 15553.3,
    "Result_Units": "Tokens/s",
    "Scenario": "Offline",
    "SystemName": "PRIMERGY CDI (8x H100NVL, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": true,
    "host_processor_core_count": 32,
    "host_processor_model_name": "INTEL(R) XEON(R) GOLD 6530",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "uid": "1f901315ad9d4aec",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Fujitsu/results/H100-NVL-94GBx8_TRT/llama2-70b-interactive-99.9/Offline",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "ROUGE1: 44.6743  ROUGE2: 22.2269  ROUGEL: 28.8649  TOKENS_PER_SAMPLE: 289.3",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/H100-NVL-94GBx8_TRT/llama2-70b-interactive-99.9/Offline",
    "MlperfModel": "llama2-70b-interactive-99.9",
    "Model": "llama2-70b-interactive-99.9",
    "Organization": "Fujitsu",
    "Platform": "H100-NVL-94GBx8_TRT",
    "Result": null,
    "Result_Power": 4852.332482683189,
    "Result_Units": "Watts",
    "Scenario": "Offline",
    "SystemName": "PRIMERGY CDI (8x H100NVL, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Watts",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": true,
    "host_processor_core_count": 32,
    "host_processor_model_name": "INTEL(R) XEON(R) GOLD 6530",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "uid": "9b645464409246db",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Fujitsu/results/H100-NVL-94GBx8_TRT/llama2-70b-interactive-99.9/Offline",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "ROUGE1: 44.6821  ROUGE2: 22.2379  ROUGEL: 28.8722  TOKENS_PER_SAMPLE: 289.4",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/H100-NVL-94GBx8_TRT/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "Fujitsu",
    "Platform": "H100-NVL-94GBx8_TRT",
    "Result": 18084.9,
    "Result_Units": "Tokens/s",
    "Scenario": "Offline",
    "SystemName": "PRIMERGY CDI (8x H100NVL, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": true,
    "host_processor_core_count": 32,
    "host_processor_model_name": "INTEL(R) XEON(R) GOLD 6530",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "uid": "7392a21baf754f74",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Fujitsu/results/H100-NVL-94GBx8_TRT/llama2-70b-99.9/Offline",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "ROUGE1: 44.6821  ROUGE2: 22.2379  ROUGEL: 28.8722  TOKENS_PER_SAMPLE: 289.4",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/H100-NVL-94GBx8_TRT/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "Fujitsu",
    "Platform": "H100-NVL-94GBx8_TRT",
    "Result": null,
    "Result_Power": 4952.046366279061,
    "Result_Units": "Watts",
    "Scenario": "Offline",
    "SystemName": "PRIMERGY CDI (8x H100NVL, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Watts",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": true,
    "host_processor_core_count": 32,
    "host_processor_model_name": "INTEL(R) XEON(R) GOLD 6530",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "uid": "3a6cda20f8584cf9",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/closed/Fujitsu/results/H100-NVL-94GBx8_TRT/llama2-70b-99.9/Offline",
    "version": "v5.0",
    "weight_data_types": "fp8"
  }
]
