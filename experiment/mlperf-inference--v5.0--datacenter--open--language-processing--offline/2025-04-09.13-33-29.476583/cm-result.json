[
  {
    "Accuracy": "ROUGE1: 44.8294  ROUGE2: 22.3814  ROUGEL: 29.1878  TOKENS_PER_SAMPLE: 271.8",
    "Availability": "preview",
    "Division": "open",
    "Location": "open/NVIDIA/results/Thor_TRT/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "NVIDIA",
    "Platform": "Thor_TRT",
    "Result": 573.765,
    "Result_Units": "Tokens/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA Jetson AGX Thor Developer Kit 128G (TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA Jetson AGX Thor 128G",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 14,
    "host_processor_model_name": "14-core ARM Poseidon-AE CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Jetson L4T",
    "uid": "d03b4ce2bcf84ba7",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/open/NVIDIA/results/Thor_TRT/llama2-70b-99/Offline",
    "version": "v5.0",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.8294  ROUGE2: 22.3814  ROUGEL: 29.1878  TOKENS_PER_SAMPLE: 271.8",
    "Availability": "preview",
    "Division": "open",
    "Location": "open/NVIDIA/results/Thor_TRT/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "NVIDIA",
    "Platform": "Thor_TRT",
    "Result": 573.765,
    "Result_Units": "Tokens/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA Jetson AGX Thor Developer Kit 128G (TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA Jetson AGX Thor 128G",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 14,
    "host_processor_model_name": "14-core ARM Poseidon-AE CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Jetson L4T",
    "uid": "08ee3231dd8145ed",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/open/NVIDIA/results/Thor_TRT/llama2-70b-99.9/Offline",
    "version": "v5.0",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 47.6186  ROUGE2: 25.2204  ROUGEL: 31.4595  TOKENS_PER_SAMPLE: 296.9",
    "Availability": "available",
    "Division": "open",
    "Location": "open/Krai/results/xe9680_mi300x_x8_sglang/llama3_1-70b-fp8_dyn/offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama3_1-70b-fp8_dyn",
    "Organization": "Krai",
    "Platform": "xe9680_mi300x_x8_sglang",
    "Result": 16162.8,
    "Result_Units": "Tokens/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE9680 (8x MI300X-192GB, SGLang v0.4.3)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "AMD Instinct MI300X 192GB HBM3",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "SGLang v0.4.3",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8460Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Powered by the KRAI X automation technology",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS (Jammy Jellyfish)",
    "uid": "a3c5eb2164d24b96",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/open/Krai/results/xe9680_mi300x_x8_sglang/llama3_1-70b-fp8_dyn/offline",
    "version": "v5.0",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.5375  ROUGE2: 22.202  ROUGEL: 28.7796  TOKENS_PER_SAMPLE: 299.2",
    "Availability": "available",
    "Division": "open",
    "Location": "open/Krai/results/xd670_h200_x8_vllm_073/llama2-70b-fp8_dyn/offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-fp8_dyn",
    "Organization": "Krai",
    "Platform": "xd670_h200_x8_vllm_073",
    "Result": 16229,
    "Result_Units": "Tokens/s",
    "Scenario": "Offline",
    "SystemName": "HPE Cray XD670 (8x H200-SXM-141GB, vLLM v0.7.3)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "vLLM v0.7.3",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8562Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Powered by the KRAI X automation technology",
    "number_of_nodes": 1,
    "operating_system": "RHEL 9.4",
    "uid": "bd852a4de85f4861",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/open/Krai/results/xd670_h200_x8_vllm_073/llama2-70b-fp8_dyn/offline",
    "version": "v5.0",
    "weight_data_types": "UNSET"
  },
  {
    "Accuracy": "ROUGE1: 44.4974  ROUGE2: 22.1155  ROUGEL: 28.7195  TOKENS_PER_SAMPLE: 298.1",
    "Availability": "available",
    "Division": "open",
    "Location": "open/Krai/results/xe9680_mi300x_x8_vllm_073/llama2-70b-fp8_dyn/offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-fp8_dyn",
    "Organization": "Krai",
    "Platform": "xe9680_mi300x_x8_vllm_073",
    "Result": 17128.9,
    "Result_Units": "Tokens/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE9680 (8x MI300X-192GB, vLLM v0.7.3)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "AMD Instinct MI300X 192GB HBM3",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "vLLM v0.7.3",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8460Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Powered by the KRAI X automation technology",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS (Jammy Jellyfish)",
    "uid": "3b67464bcd2442fb",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/open/Krai/results/xe9680_mi300x_x8_vllm_073/llama2-70b-fp8_dyn/offline",
    "version": "v5.0",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.5183  ROUGE2: 22.1357  ROUGEL: 28.7267  TOKENS_PER_SAMPLE: 297.0",
    "Availability": "available",
    "Division": "open",
    "Location": "open/Krai/results/xd670_h200_x8_vllm_064_flashinfer/llama2-70b-fp8_dyn/offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-fp8_dyn",
    "Organization": "Krai",
    "Platform": "xd670_h200_x8_vllm_064_flashinfer",
    "Result": 21372.3,
    "Result_Units": "Tokens/s",
    "Scenario": "Offline",
    "SystemName": "HPE Cray XD670 (8x H200-SXM-141GB, vLLM v0.6.4)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "vLLM v0.6.4 FlashInfer",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8562Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Powered by the KRAI X automation technology",
    "number_of_nodes": 1,
    "operating_system": "RHEL 9.4",
    "uid": "bb6866ff88a843f6",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/open/Krai/results/xd670_h200_x8_vllm_064_flashinfer/llama2-70b-fp8_dyn/offline",
    "version": "v5.0",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.5823  ROUGE2: 22.2287  ROUGEL: 28.8178  TOKENS_PER_SAMPLE: 296.5",
    "Availability": "available",
    "Division": "open",
    "Location": "open/Krai/results/xd670_h200_x8_vllm_064/llama2-70b-fp8_dyn/offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-fp8_dyn",
    "Organization": "Krai",
    "Platform": "xd670_h200_x8_vllm_064",
    "Result": 15906.1,
    "Result_Units": "Tokens/s",
    "Scenario": "Offline",
    "SystemName": "HPE Cray XD670 (8x H200-SXM-141GB, vLLM v0.6.4)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "vLLM v0.6.4",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8562Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Powered by the KRAI X automation technology",
    "number_of_nodes": 1,
    "operating_system": "RHEL 9.4",
    "uid": "70f2ff26fefa4a9f",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/open/Krai/results/xd670_h200_x8_vllm_064/llama2-70b-fp8_dyn/offline",
    "version": "v5.0",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.4973  ROUGE2: 22.1394  ROUGEL: 28.7255  TOKENS_PER_SAMPLE: 301.3",
    "Availability": "available",
    "Division": "open",
    "Location": "open/Krai/results/xe9680_mi300x_x8_vllm_064/llama2-70b-fp8_dyn/offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-fp8_dyn",
    "Organization": "Krai",
    "Platform": "xe9680_mi300x_x8_vllm_064",
    "Result": 18561.4,
    "Result_Units": "Tokens/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE9680 (8x MI300X-192GB, vLLM v0.6.4)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "AMD Instinct MI300X 192GB HBM3",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "vLLM v0.6.4",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8460Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Powered by the KRAI X automation technology",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS (Jammy Jellyfish)",
    "uid": "faa88876ecfd41cf",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/open/Krai/results/xe9680_mi300x_x8_vllm_064/llama2-70b-fp8_dyn/offline",
    "version": "v5.0",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 47.5723  ROUGE2: 25.2003  ROUGEL: 31.4338  TOKENS_PER_SAMPLE: 299.6",
    "Availability": "available",
    "Division": "open",
    "Location": "open/Krai/results/xd670_h200_x8_sglang/llama3_1-70b-fp8_dyn/offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama3_1-70b-fp8_dyn",
    "Organization": "Krai",
    "Platform": "xd670_h200_x8_sglang",
    "Result": 24624.1,
    "Result_Units": "Tokens/s",
    "Scenario": "Offline",
    "SystemName": "HPE Cray XD670 (8x H200-SXM-141GB, SGLang v0.4.3)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "SGLang v0.4.3",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8562Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Powered by the KRAI X automation technology",
    "number_of_nodes": 1,
    "operating_system": "RHEL 9.4",
    "uid": "ea16ba262b6d4ec3",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/open/Krai/results/xd670_h200_x8_sglang/llama3_1-70b-fp8_dyn/offline",
    "version": "v5.0",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 47.589  ROUGE2: 25.2681  ROUGEL: 31.545  TOKENS_PER_SAMPLE: 292.1",
    "Availability": "available",
    "Division": "open",
    "Location": "open/Krai/results/xd670_h200_x8_sglang/llama3_1-70b-fp8_pre/offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama3_1-70b-fp8_pre",
    "Organization": "Krai",
    "Platform": "xd670_h200_x8_sglang",
    "Result": 27687.9,
    "Result_Units": "Tokens/s",
    "Scenario": "Offline",
    "SystemName": "HPE Cray XD670 (8x H200-SXM-141GB, SGLang v0.4.3)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "SGLang v0.4.3",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8562Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Powered by the KRAI X automation technology",
    "number_of_nodes": 1,
    "operating_system": "RHEL 9.4",
    "uid": "d8380437ede64f0e",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/open/Krai/results/xd670_h200_x8_sglang/llama3_1-70b-fp8_pre/offline",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "ROUGE1: 47.5684  ROUGE2: 25.2712  ROUGEL: 31.533  TOKENS_PER_SAMPLE: 292.8",
    "Availability": "available",
    "Division": "open",
    "Location": "open/Krai/results/xd670_h200_x8_sglang/llama3_1-70b-interactive-fp8_pre/offline",
    "MlperfModel": "llama2-70b-interactive-99.9",
    "Model": "llama3_1-70b-interactive-fp8_pre",
    "Organization": "Krai",
    "Platform": "xd670_h200_x8_sglang",
    "Result": 27949.8,
    "Result_Units": "Tokens/s",
    "Scenario": "Offline",
    "SystemName": "HPE Cray XD670 (8x H200-SXM-141GB, SGLang v0.4.3)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "SGLang v0.4.3",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8562Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Powered by the KRAI X automation technology",
    "number_of_nodes": 1,
    "operating_system": "RHEL 9.4",
    "uid": "95122d6931854624",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/open/Krai/results/xd670_h200_x8_sglang/llama3_1-70b-interactive-fp8_pre/offline",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "ROUGE1: 46.5248  ROUGE2: 24.2311  ROUGEL: 30.2319  TOKENS_PER_SAMPLE: 323.9",
    "Availability": "available",
    "Division": "open",
    "Location": "open/Krai/results/xd670_h200_x8_nim/llama3_1-70b-interactive-fp8_nim/offline",
    "MlperfModel": "llama2-70b-interactive-99.9",
    "Model": "llama3_1-70b-interactive-fp8_nim",
    "Organization": "Krai",
    "Platform": "xd670_h200_x8_nim",
    "Result": 30530.1,
    "Result_Units": "Tokens/s",
    "Scenario": "Offline",
    "SystemName": "HPE Cray XD670 (8x H200-SXM-141GB, NIM v1.5.0)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "NIM v1.5.0",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8562Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Powered by the KRAI X automation technology",
    "number_of_nodes": 1,
    "operating_system": "RHEL 9.4",
    "uid": "94a6c86f93e34fc8",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/open/Krai/results/xd670_h200_x8_nim/llama3_1-70b-interactive-fp8_nim/offline",
    "version": "v5.0",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 46.5273  ROUGE2: 24.2307  ROUGEL: 30.2329  TOKENS_PER_SAMPLE: 323.8",
    "Availability": "available",
    "Division": "open",
    "Location": "open/Krai/results/xd670_h200_x8_nim/llama3_1-70b-fp8_nim/offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama3_1-70b-fp8_nim",
    "Organization": "Krai",
    "Platform": "xd670_h200_x8_nim",
    "Result": 30042.8,
    "Result_Units": "Tokens/s",
    "Scenario": "Offline",
    "SystemName": "HPE Cray XD670 (8x H200-SXM-141GB, NIM v1.5.0)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "NIM v1.5.0",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8562Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Powered by the KRAI X automation technology",
    "number_of_nodes": 1,
    "operating_system": "RHEL 9.4",
    "uid": "d9625c3ddd5f4f63",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/open/Krai/results/xd670_h200_x8_nim/llama3_1-70b-fp8_nim/offline",
    "version": "v5.0",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.7869  ROUGE2: 22.383  ROUGEL: 29.1434  TOKENS_PER_SAMPLE: 272.9",
    "Availability": "available",
    "Division": "open",
    "Location": "open/Lambda/results/B200-SXM-180GBx8_TRT/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "Lambda",
    "Platform": "B200-SXM-180GBx8_TRT",
    "Result": 97403.4,
    "Result_Units": "Tokens/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX B200 (8x B200-SXM-180GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA B200-SXM-180GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8570",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "B200 TGP 1000W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "uid": "279b4189e7fa4490",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/open/Lambda/results/B200-SXM-180GBx8_TRT/llama2-70b-99/Offline",
    "version": "v5.0",
    "weight_data_types": "fp4"
  },
  {
    "Accuracy": "ROUGE1: 44.7869  ROUGE2: 22.383  ROUGEL: 29.1434  TOKENS_PER_SAMPLE: 272.9",
    "Availability": "available",
    "Division": "open",
    "Location": "open/Lambda/results/B200-SXM-180GBx8_TRT/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "Lambda",
    "Platform": "B200-SXM-180GBx8_TRT",
    "Result": 97403.4,
    "Result_Units": "Tokens/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX B200 (8x B200-SXM-180GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA B200-SXM-180GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8570",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "B200 TGP 1000W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "uid": "32c049aaa88341d9",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/open/Lambda/results/B200-SXM-180GBx8_TRT/llama2-70b-99.9/Offline",
    "version": "v5.0",
    "weight_data_types": "fp4"
  },
  {
    "Accuracy": "ROUGE1: 43.1186  ROUGE2: 20.1722  ROUGEL: 30.0185  GEN_LEN: 4156655",
    "Availability": "available",
    "Division": "open",
    "Location": "open/Supermicro/results/ARS_111GL_NHR_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "Supermicro",
    "Platform": "ARS_111GL_NHR_TRT",
    "Result": 2791.38,
    "Result_Units": "Tokens/s",
    "Scenario": "Offline",
    "SystemName": "ARS-111GL-NHR (1x GH200-96GB_aarch64)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA GH200 96GB HBM3",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "uid": "d708d04b6d004752",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/open/Supermicro/results/ARS_111GL_NHR_TRT/gptj-99.9/Offline",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "ROUGE1: 43.1186  ROUGE2: 20.1722  ROUGEL: 30.0185  GEN_LEN: 4156655",
    "Availability": "available",
    "Division": "open",
    "Location": "open/Supermicro/results/ARS_111GL_NHR_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Supermicro",
    "Platform": "ARS_111GL_NHR_TRT",
    "Result": 2791.38,
    "Result_Units": "Tokens/s",
    "Scenario": "Offline",
    "SystemName": "ARS-111GL-NHR (1x GH200-96GB_aarch64)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA GH200 96GB HBM3",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "uid": "06ae5efe435d4a12",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/open/Supermicro/results/ARS_111GL_NHR_TRT/gptj-99/Offline",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "ROUGE1: 44.5498  ROUGE2: 22.134  ROUGEL: 28.7842  TOKENS_PER_SAMPLE: 291.4",
    "Availability": "available",
    "Division": "open",
    "Location": "open/Supermicro/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x2_TRT/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "Supermicro",
    "Platform": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x2_TRT",
    "Result": 8231.9,
    "Result_Units": "Tokens/s",
    "Scenario": "Offline",
    "SystemName": "ARS-221GL-NHIR (2x GH200-144GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 144,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "NVIDIA GH200 144GB HBM3e",
    "number_of_nodes": 1,
    "operating_system": "Red Hat 9.4 + OpenShift 4.15",
    "uid": "9b8937e75f7a4a0f",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/open/Supermicro/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x2_TRT/llama2-70b-99/Offline",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "ROUGE1: 44.5498  ROUGE2: 22.134  ROUGEL: 28.7842  TOKENS_PER_SAMPLE: 291.4",
    "Availability": "available",
    "Division": "open",
    "Location": "open/Supermicro/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x2_TRT/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "Supermicro",
    "Platform": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x2_TRT",
    "Result": 8231.9,
    "Result_Units": "Tokens/s",
    "Scenario": "Offline",
    "SystemName": "ARS-221GL-NHIR (2x GH200-144GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 144,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "NVIDIA GH200 144GB HBM3e",
    "number_of_nodes": 1,
    "operating_system": "Red Hat 9.4 + OpenShift 4.15",
    "uid": "7f1cc736cb654dc2",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/open/Supermicro/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x2_TRT/llama2-70b-99.9/Offline",
    "version": "v5.0",
    "weight_data_types": "fp8"
  }
]
