[
  {
    "Accuracy": "ROUGE1: 30.6202  ROUGE2: 13.9221  ROUGEL: 18.9101  TOKENS_PER_SAMPLE: 581.8",
    "Availability": "available",
    "Division": "open",
    "Location": "open/FlexAI/results/cmx-flexbench-cuda-1xH100-vllm-0.7.3-pytorch-2.5.1-huggingface-16d94432c8704c14/DeepSeek-R1-Distill-Llama-8B/Server",
    "MlperfModel": "llama2-70b-99",
    "Model": "DeepSeek-R1-Distill-Llama-8B",
    "Organization": "FlexAI",
    "Platform": "cmx-flexbench-cuda-1xH100-vllm-0.7.3-pytorch-2.5.1-huggingface-16d94432c8704c14",
    "Result": 2631.93,
    "Result_Units": "Tokens/s",
    "Scenario": "Server",
    "SystemName": "flexbench test node 0ef307db09d34a91 with 8xH100",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100 80GB HBM3",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "vLLM v0.7.3",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel Xeon Processor (SapphireRapids)",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.5 LTS (5.15.0-131-generic)",
    "uid": "f0333fb054474799",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/open/FlexAI/results/cmx-flexbench-cuda-1xH100-vllm-0.7.3-pytorch-2.5.1-huggingface-16d94432c8704c14/DeepSeek-R1-Distill-Llama-8B/Server",
    "version": "v5.0",
    "weight_data_types": "bfloat16"
  },
  {
    "Accuracy": "ROUGE1: 44.246  ROUGE2: 22.4512  ROUGEL: 27.9398  TOKENS_PER_SAMPLE: 335.5",
    "Availability": "available",
    "Division": "open",
    "Location": "open/FlexAI/results/cmx-flexbench-cuda-1xH100-vllm-0.7.3-pytorch-2.5.1-huggingface-36d94432c8704c14/Llama-3.3-70B-Instruct-FP8-dynamic/Server",
    "MlperfModel": "llama2-70b-99",
    "Model": "Llama-3.3-70B-Instruct-FP8-dynamic",
    "Organization": "FlexAI",
    "Platform": "cmx-flexbench-cuda-1xH100-vllm-0.7.3-pytorch-2.5.1-huggingface-36d94432c8704c14",
    "Result": 134.714,
    "Result_Units": "Tokens/s",
    "Scenario": "Server",
    "SystemName": "flexbench test node 0ef307db09d34a91 with 8xH100",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100 80GB HBM3",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "vLLM v0.7.3",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel Xeon Processor (SapphireRapids)",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.5 LTS (5.15.0-131-generic)",
    "uid": "d15912fbd4ce495d",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/open/FlexAI/results/cmx-flexbench-cuda-1xH100-vllm-0.7.3-pytorch-2.5.1-huggingface-36d94432c8704c14/Llama-3.3-70B-Instruct-FP8-dynamic/Server",
    "version": "v5.0",
    "weight_data_types": "bfloat16"
  },
  {
    "Accuracy": "ROUGE1: 44.4619  ROUGE2: 22.0574  ROUGEL: 28.6452  TOKENS_PER_SAMPLE: 295.9",
    "Availability": "available",
    "Division": "open",
    "Location": "open/FlexAI/results/cmx-flexbench-cuda-4xH100-vllm-0.7.3-pytorch-2.5.1-huggingface-46d94432c8704c14/Llama-2-70b-chat-hf-FP8/Server",
    "MlperfModel": "llama2-70b-99",
    "Model": "Llama-2-70b-chat-hf-FP8",
    "Organization": "FlexAI",
    "Platform": "cmx-flexbench-cuda-4xH100-vllm-0.7.3-pytorch-2.5.1-huggingface-46d94432c8704c14",
    "Result": 1482.31,
    "Result_Units": "Tokens/s",
    "Scenario": "Server",
    "SystemName": "flexbench test node 0ef307db09d34a91 with 8xH100",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100 80GB HBM3",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "vLLM v0.7.3",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel Xeon Processor (SapphireRapids)",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.5 LTS (5.15.0-131-generic)",
    "uid": "cc6ea142d0ef4702",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/open/FlexAI/results/cmx-flexbench-cuda-4xH100-vllm-0.7.3-pytorch-2.5.1-huggingface-46d94432c8704c14/Llama-2-70b-chat-hf-FP8/Server",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "ROUGE1: 44.6113  ROUGE2: 22.2456  ROUGEL: 28.8393  TOKENS_PER_SAMPLE: 298.1",
    "Availability": "available",
    "Division": "open",
    "Location": "open/Krai/results/xd670_h200_x8_vllm_073/llama2-70b-fp8_dyn/server",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-fp8_dyn",
    "Organization": "Krai",
    "Platform": "xd670_h200_x8_vllm_073",
    "Result": 14426.4,
    "Result_Units": "Tokens/s",
    "Scenario": "Server",
    "SystemName": "HPE Cray XD670 (8x H200-SXM-141GB, vLLM v0.7.3)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "vLLM v0.7.3",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8562Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Powered by the KRAI X automation technology",
    "number_of_nodes": 1,
    "operating_system": "RHEL 9.4",
    "uid": "e7811afddd304373",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/open/Krai/results/xd670_h200_x8_vllm_073/llama2-70b-fp8_dyn/server",
    "version": "v5.0",
    "weight_data_types": "UNSET"
  },
  {
    "Accuracy": "ROUGE1: 44.5066  ROUGE2: 22.1409  ROUGEL: 28.7316  TOKENS_PER_SAMPLE: 297.1",
    "Availability": "available",
    "Division": "open",
    "Location": "open/Krai/results/xe9680_mi300x_x8_vllm_073/llama2-70b-fp8_dyn/server",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-fp8_dyn",
    "Organization": "Krai",
    "Platform": "xe9680_mi300x_x8_vllm_073",
    "Result": 12989,
    "Result_Units": "Tokens/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XE9680 (8x MI300X-192GB, vLLM v0.7.3)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "AMD Instinct MI300X 192GB HBM3",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "vLLM v0.7.3",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8460Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Powered by the KRAI X automation technology",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS (Jammy Jellyfish)",
    "uid": "b879ed29117947c6",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/open/Krai/results/xe9680_mi300x_x8_vllm_073/llama2-70b-fp8_dyn/server",
    "version": "v5.0",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.5421  ROUGE2: 22.1749  ROUGEL: 28.8061  TOKENS_PER_SAMPLE: 295.1",
    "Availability": "available",
    "Division": "open",
    "Location": "open/Krai/results/xd670_h200_x8_vllm_064_flashinfer/llama2-70b-fp8_dyn/server",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-fp8_dyn",
    "Organization": "Krai",
    "Platform": "xd670_h200_x8_vllm_064_flashinfer",
    "Result": 19618.1,
    "Result_Units": "Tokens/s",
    "Scenario": "Server",
    "SystemName": "HPE Cray XD670 (8x H200-SXM-141GB, vLLM v0.6.4)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "vLLM v0.6.4 FlashInfer",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8562Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Powered by the KRAI X automation technology",
    "number_of_nodes": 1,
    "operating_system": "RHEL 9.4",
    "uid": "546377c5979447d5",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/open/Krai/results/xd670_h200_x8_vllm_064_flashinfer/llama2-70b-fp8_dyn/server",
    "version": "v5.0",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.5362  ROUGE2: 22.176  ROUGEL: 28.773  TOKENS_PER_SAMPLE: 295.7",
    "Availability": "available",
    "Division": "open",
    "Location": "open/Krai/results/xd670_h200_x8_vllm_064/llama2-70b-fp8_dyn/server",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-fp8_dyn",
    "Organization": "Krai",
    "Platform": "xd670_h200_x8_vllm_064",
    "Result": 13716.7,
    "Result_Units": "Tokens/s",
    "Scenario": "Server",
    "SystemName": "HPE Cray XD670 (8x H200-SXM-141GB, vLLM v0.6.4)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "vLLM v0.6.4",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8562Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Powered by the KRAI X automation technology",
    "number_of_nodes": 1,
    "operating_system": "RHEL 9.4",
    "uid": "c6fd5624b3794e40",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/open/Krai/results/xd670_h200_x8_vllm_064/llama2-70b-fp8_dyn/server",
    "version": "v5.0",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.5398  ROUGE2: 22.1484  ROUGEL: 28.725  TOKENS_PER_SAMPLE: 299.5",
    "Availability": "available",
    "Division": "open",
    "Location": "open/Krai/results/xe9680_mi300x_x8_vllm_064/llama2-70b-fp8_dyn/server",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-fp8_dyn",
    "Organization": "Krai",
    "Platform": "xe9680_mi300x_x8_vllm_064",
    "Result": 13916.2,
    "Result_Units": "Tokens/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XE9680 (8x MI300X-192GB, vLLM v0.6.4)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "AMD Instinct MI300X 192GB HBM3",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "vLLM v0.6.4",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8460Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Powered by the KRAI X automation technology",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS (Jammy Jellyfish)",
    "uid": "be78825c60fe4730",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/open/Krai/results/xe9680_mi300x_x8_vllm_064/llama2-70b-fp8_dyn/server",
    "version": "v5.0",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 47.6531  ROUGE2: 25.2981  ROUGEL: 31.5596  TOKENS_PER_SAMPLE: 291.3",
    "Availability": "available",
    "Division": "open",
    "Location": "open/Krai/results/xd670_h200_x8_sglang/llama3_1-70b-fp8_pre/server",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama3_1-70b-fp8_pre",
    "Organization": "Krai",
    "Platform": "xd670_h200_x8_sglang",
    "Result": 26074.4,
    "Result_Units": "Tokens/s",
    "Scenario": "Server",
    "SystemName": "HPE Cray XD670 (8x H200-SXM-141GB, SGLang v0.4.3)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "SGLang v0.4.3",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8562Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Powered by the KRAI X automation technology",
    "number_of_nodes": 1,
    "operating_system": "RHEL 9.4",
    "uid": "72243f6e541e4e13",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/open/Krai/results/xd670_h200_x8_sglang/llama3_1-70b-fp8_pre/server",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "ROUGE1: 47.6193  ROUGE2: 25.2818  ROUGEL: 31.5351  TOKENS_PER_SAMPLE: 291.8",
    "Availability": "available",
    "Division": "open",
    "Location": "open/Krai/results/xd670_h200_x8_sglang/llama3_1-70b-interactive-fp8_pre/server",
    "MlperfModel": "llama2-70b-interactive-99.9",
    "Model": "llama3_1-70b-interactive-fp8_pre",
    "Organization": "Krai",
    "Platform": "xd670_h200_x8_sglang",
    "Result": 12192.4,
    "Result_Units": "Tokens/s",
    "Scenario": "Server",
    "SystemName": "HPE Cray XD670 (8x H200-SXM-141GB, SGLang v0.4.3)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "SGLang v0.4.3",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8562Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Powered by the KRAI X automation technology",
    "number_of_nodes": 1,
    "operating_system": "RHEL 9.4",
    "uid": "ae863b578cab4c82",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/open/Krai/results/xd670_h200_x8_sglang/llama3_1-70b-interactive-fp8_pre/server",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "ROUGE1: 46.5348  ROUGE2: 24.2605  ROUGEL: 30.246  TOKENS_PER_SAMPLE: 324.7",
    "Availability": "available",
    "Division": "open",
    "Location": "open/Krai/results/xd670_h200_x8_nim/llama3_1-70b-interactive-fp8_nim/server",
    "MlperfModel": "llama2-70b-interactive-99.9",
    "Model": "llama3_1-70b-interactive-fp8_nim",
    "Organization": "Krai",
    "Platform": "xd670_h200_x8_nim",
    "Result": 15960.1,
    "Result_Units": "Tokens/s",
    "Scenario": "Server",
    "SystemName": "HPE Cray XD670 (8x H200-SXM-141GB, NIM v1.5.0)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "NIM v1.5.0",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8562Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Powered by the KRAI X automation technology",
    "number_of_nodes": 1,
    "operating_system": "RHEL 9.4",
    "uid": "d7f2e2b12e71423e",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/open/Krai/results/xd670_h200_x8_nim/llama3_1-70b-interactive-fp8_nim/server",
    "version": "v5.0",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 46.5201  ROUGE2: 24.2273  ROUGEL: 30.2319  TOKENS_PER_SAMPLE: 323.9",
    "Availability": "available",
    "Division": "open",
    "Location": "open/Krai/results/xd670_h200_x8_nim/llama3_1-70b-fp8_nim/server",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama3_1-70b-fp8_nim",
    "Organization": "Krai",
    "Platform": "xd670_h200_x8_nim",
    "Result": 28421,
    "Result_Units": "Tokens/s",
    "Scenario": "Server",
    "SystemName": "HPE Cray XD670 (8x H200-SXM-141GB, NIM v1.5.0)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "NIM v1.5.0",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8562Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Powered by the KRAI X automation technology",
    "number_of_nodes": 1,
    "operating_system": "RHEL 9.4",
    "uid": "9f2393d300c34231",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/open/Krai/results/xd670_h200_x8_nim/llama3_1-70b-fp8_nim/server",
    "version": "v5.0",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.5491  ROUGE2: 22.1346  ROUGEL: 28.7871  TOKENS_PER_SAMPLE: 292.3",
    "Availability": "available",
    "Division": "open",
    "Location": "open/Supermicro/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x2_TRT/llama2-70b-99/Server",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "Supermicro",
    "Platform": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x2_TRT",
    "Result": 7538.8,
    "Result_Units": "Tokens/s",
    "Scenario": "Server",
    "SystemName": "ARS-221GL-NHIR (2x GH200-144GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 144,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "NVIDIA GH200 144GB HBM3e",
    "number_of_nodes": 1,
    "operating_system": "Red Hat 9.4 + OpenShift 4.15",
    "uid": "21e219890e4b40f2",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/open/Supermicro/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x2_TRT/llama2-70b-99/Server",
    "version": "v5.0",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "ROUGE1: 44.5491  ROUGE2: 22.1346  ROUGEL: 28.7871  TOKENS_PER_SAMPLE: 292.3",
    "Availability": "available",
    "Division": "open",
    "Location": "open/Supermicro/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x2_TRT/llama2-70b-99.9/Server",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "Supermicro",
    "Platform": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x2_TRT",
    "Result": 7538.8,
    "Result_Units": "Tokens/s",
    "Scenario": "Server",
    "SystemName": "ARS-221GL-NHIR (2x GH200-144GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 10.8, CUDA 12.8",
    "git_url": "https://github.com/mlcommons/inference_results_v5.0",
    "has_power": false,
    "host_processor_core_count": 144,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "NVIDIA GH200 144GB HBM3e",
    "number_of_nodes": 1,
    "operating_system": "Red Hat 9.4 + OpenShift 4.15",
    "uid": "164f2f01e64e47f6",
    "url": "https://github.com/mlcommons/inference_results_v5.0/tree/master/open/Supermicro/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x2_TRT/llama2-70b-99.9/Server",
    "version": "v5.0",
    "weight_data_types": "fp8"
  }
]
